{"title":"Empirical Methods in Finance","markdown":{"yaml":{"title":"Empirical Methods in Finance","subtitle":"Practicing 1","author":"Henrique C. Martins","format":{"revealjs":{"slide-number":true,"theme":"simple","chalkboard":true,"preview-links":"auto","logo":"figs/background8.png","css":"logo.css","footer":"**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  ","multiplex":true,"scrollable":true}},"title-slide-attributes":{"data-background-color":"#b1cafa"},"include-after":"<script type=\"text/javascript\">\n  Reveal.on('ready', event => {\n    if (event.indexh === 0) {\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n    }\n  });\n  Reveal.addEventListener('slidechanged', (event) => {\n    if (event.indexh === 0) {\n      Reveal.configure({ slideNumber: null });\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n    }\n    if (event.indexh === 1) {\n      Reveal.configure({ slideNumber: 'c' });\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = null;\n    }\n  });\n</script>\n"},"headingText":"library(reticulate)","containsRefs":false,"markdown":"\n\n```{r setup}\n#| include: false\n#| warning: false\n\n# use_python(\"C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe\")\nlibrary(reticulate)\nlibrary(Statamarkdown)\n#reticulate::py_install(\"matplotlib\")\n#reticulate::py_install(\"seaborn\")\n#reticulate::py_install(\"pyfinance\")\n#reticulate::py_install(\"xlrd\")\n#reticulate::py_install(\"quandl\")\n#reticulate::py_install(\"linearmodels\")\n#reticulate::py_install(\"causalml\")\n\n```\n\n\n\n\n\n\n\n\n# Basic Statistics {.smaller}\n\n## Basic stats {.smaller }\n\nThe following are simple examples of how to compute basic statistics using R. We will start importing the data. Let's use the free dataset `iris`, available in R.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\niris <- iris \n```\n\n\nFirst, explore the dataset.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nstr(iris) \n```\n\n\n- We have 5 variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width e Species. The first four are numeric while the last is a string with three groups: setosa, versicolor, and virginica. The dataset contains 150 observations\n\n\n\n\n\n\n\n## Basic stats {.smaller }\n\nLet's take a look at the first 10 observations in the dataset.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nhead(iris, 10) \n```\n\n\n## Basic stats {.smaller }\n\n\nNow, let's take a look at the first 5 observations of each species.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nby(iris,iris[\"Species\"],head,n=5)\n```\n\n\n\n\n\n\n\n## Mean and Median {.smaller }\n\nNow, let's find the means and the medians of the four numeric variables. The most intuitive way is as follows.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmean(iris$Sepal.Length)\nmean(iris$Sepal.Width)\nmean(iris$Petal.Length)\nmean(iris$Petal.Width)\n \nmedian(iris$Sepal.Length)\nmedian(iris$Sepal.Width)\nmedian(iris$Petal.Length)\nmedian(iris$Petal.Width)\n```\n\n\n\n## Mean and Median {.smaller }\n\nBut this is the easiest way.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nsummary(iris)\n```\n\n\n\n## Mean and Median {.smaller }\n\nSee that in the code above you also have the number of observations of each species. If you wanted to know how many observations you have in the dataset, you could use the following line. This might be important in the future.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlength(iris$Species)\n```\n\n\n## Mean and Median {.smaller }\n\nIf you want the same thing by group, do as follows:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nby(iris, iris$Species, summary)\n```\n\n\n\n\n\n\n\n## Minimum and maximum  {.smaller }\n\nThe function `summary`already gives you the minimum and maximum of all variables. But sometimes you need to find only these values. You could use the following lines.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmin(iris$Sepal.Length)\nmax(iris$Sepal.Length)\n```\n      \nYou could also find the range of values to find the extreme values of a variable.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nrange(iris$Sepal.Length)\n```\n\n\n\n\n\n## Minimum and maximum  {.smaller }\n\nIf you need the distance between the extreme values, you can use:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmax(iris$Sepal.Length) - min(iris$Sepal.Length)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n## Standard-deviation and Variance {.smaller }\n\nFinally, you can also compute the Standard-deviation and Variance of one variable as follows.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nsd(iris$Sepal.Length)\nvar(iris$Sepal.Length) \n```\n\nIf you want the standard deviation of all variables:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlapply(iris[, 1:4], sd)\n```\n\n\n\n\n\n\n\n\n\n\n \n## Correlation {.smaller }\n\nThe following lines will show you a correlation table. First, you need to create a new dataframe with only the numeric variables. This is an extremely important table to your academic paper.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(dplyr)\niris_num <- select(iris,-Species)\ncor(iris_num)\n```\n\n\n\n\n\n\n\n## Frequence table {.smaller }\n\nHere is another important table you might use in your paper: the frequency of observations by group.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\ntable(iris$Species)\n```\n\n\n\n\n\n\n## T-test {.smaller }\n\nLet's create now a t-test of the difference in means. For that, we will use another dataset: `mtcars`. The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles. You can find the description of the variables [here](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars).\n\nYou will find that there is one variable that is binary: either the cars are automatic (1) or are manual (0).\n\nWhen you have binary variables, it is always a good idea to test if the means of the variables are different between the two groups of the binary variable.\n\nThis is a big thing and you will use a lot in your academic research. In fact, in many articles, the authors explore and compare two groups. So, be ready to create such an analysis.  \n\n\n\n\n\n\n\n## T-test {.smaller }\n\nFirst, import the new dataset. Then, repeat the first steps and inspect this dataset (I will not inspect the dataset here, but you should inspect as a way to practice it). \n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmtcars <- mtcars\n```\n\n\n\n## T-test {.smaller }\n\nThen, use the binary variable to see if other variables have similar means. The following case compares the average of `mpg` (miles p/ gas) of automatic vs. manual car.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nt.test(mpg ~ am, data=mtcars)\n```\n\n- We see that the average in the automatic car is around 17.1 while the average of manual cars is 24.3.\n- These averages are statistically different, since the t-stat is high (-3.76).\n- So, we can learn that automatic cars consume more gas than manual cars.\n- This type of test will be very  important in your research.\n\n\n\n\n\n\n\n## Dispersion {.smaller}\n\nThese measures show how *spread out* the data are around the mean.  \n\nThe coefficient of variation (CV) compares variability relative to the mean ‚Äî useful in finance for comparing volatility across assets.\n\nInterquartile Range = $Q_3 - Q_1$\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nrange_x <- range(x)\niqr_x   <- IQR(x)\ncv_x    <- sd(x) / mean(x)\n\nlist(\n  range = diff(range_x),\n  IQR = iqr_x,\n  CV = cv_x\n)\n```\n\n\n\n\n\n\n\n## Quantiles & Percentiles {.smaller}\n\nQuantiles divide the data into equal parts (e.g., quartiles, percentiles).\n\nThey are often used to identify thresholds or outliers.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nquantile(iris$Sepal.Length, probs = c(.01,.05,.25,.50,.75,.95,.99))\n```\n\n\n\n\n\n## Distributions {.smaller}\n\nVisualizing the distribution helps you see its shape ‚Äî whether symmetric, skewed, or concentrated.\n\nEmpirical Cumulative Distribution Function (ECDF) = y-axis shows the accumulated proportion of observations below the x-value.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\npar(mfrow = c(1,3))\nhist(iris$Sepal.Length, breaks = 10, main = \"Histogram\", xlab = \"Sepal.Length\")\nplot(density(iris$Sepal.Length), main = \"Kernel Density\", xlab = \"Sepal.Length\")\nplot(ecdf(iris$Sepal.Length), main = \"ECDF\", xlab = \"Sepal.Length\")\npar(mfrow = c(1,1))\n```\n\n\n\n\n\n## Shape: Skewness & Kurtosis {.smaller}\n\nThese measures describe the *shape* of a distribution.  \n- **Skewness:** measures symmetry (right- or left-tailed).  \n- **Kurtosis:** measures tail heaviness (fat tails ‚Üí more extreme events).  \n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nset.seed(123)\nx_sym  <- rnorm(1000, mean = 0, sd = 1)        # symmetric (normal)\nx_right <- rexp(1000, rate = 1) - 1            # right-skewed\nx_fat  <- rt(1000, df = 3)                     # heavy tails (t-distribution)\n\npar(mfrow = c(1,3))\nhist(x_sym, breaks = 25, main = \"Symmetric (Normal)\", col = \"lightgray\", xlab = \"\")\nhist(x_right, breaks = 25, main = \"Right-Skewed (Exponential)\", col = \"lightgray\", xlab = \"\")\nhist(x_fat, breaks = 25, main = \"Fat Tails (t, df=3)\", col = \"lightgray\", xlab = \"\")\npar(mfrow = c(1,1))\n```\n\n\n## Shape: Skewness & Kurtosis {.smaller}\n\nNow, let's compute skewness and kurtosis for our actual data.\n\n\n- Skewness > 0 ‚Üí right tail longer (positive skew).\n- Skewness < 0 ‚Üí left tail longer (negative skew).\n- Kurtosis > 0 ‚Üí heavier tails than normal (leptokurtic).\n- Kurtosis < 0 ‚Üí lighter tails than normal (platykurtic).\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nskewness <- function(v){\n  m <- mean(v); s <- sd(v)\n  mean(((v - m)/s)^3)\n}\nkurtosis_excess <- function(v){\n  m <- mean(v); s <- sd(v)\n  mean(((v - m)/s)^4) - 3\n}\nc(\n  skewness = skewness(iris$Sepal.Length),\n  excess_kurtosis = kurtosis_excess(iris$Sepal.Length)\n)\n```\n\n\n\n## Outliers via IQR Rule {.smaller}\n\nOutliers are points far from most observations. The IQR rule defines them as values beyond 1.5 √ó IQR from the quartiles.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nQ1 <- quantile(x, .25); Q3 <- quantile(x, .75); I <- IQR(x)\nlower <- Q1 - 1.5*I; upper <- Q3 + 1.5*I\nout_idx <- which(x < lower | x > upper)\nlist(\n  thresholds = c(lower = lower, upper = upper),\n  n_outliers = length(out_idx),\n  example_values  = head(x[out_idx], 5)\n)\n\n```\n\n\n\n\n## Transformations: log & z-score {.smaller}\n\nTransformations help stabilize variance and make variables comparable.\n\n- log(x) reduces skewness.\n- z-score standardizes scale.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx     <- iris$Sepal.Length\nx_log <- log(x)\nx_z   <- as.numeric(scale(x))\npar(mfrow = c(1,3))\nhist(x, main=\"Original\", xlab=\"Sepal.Length\")\nhist(x_log, main=\"log(x)\", xlab=\"log(Sepal.Length)\")\nhist(x_z, main=\"z-score\", xlab=\"Standardized\")\npar(mfrow = c(1,1))\n```\n\n\n\n\n\n\n\n\n# Confidence Intervals {.smaller}\n\n## What is a Confidence Interval? {.smaller}\n\nA confidence interval reflects the *uncertainty* around an estimate.  \nIf we repeat the experiment many times, most intervals will capture the true mean, but some will miss it just by chance.\n\nBelow, we simulate **100 random samples** (each with 30 observations from a true mean of 5).  \nEach horizontal line shows a 95% confidence interval for one sample mean.  \nThe **red line** marks the *true mean (Œº = 5)*.  \n\n- Gray dots: sample means  \n- Gray bars: confidence intervals  \n- Intervals that **miss** the red line show random sampling error  \n- About **5 out of 100** intervals are expected to miss (‚âà5%)\n\nüëâ A 95% CI means: *if we repeated the experiment many times, 95% of the intervals would contain the true mean.*\n\n\n\n\n\n## Visual Intuition {.smaller}\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4.5\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nset.seed(123)\nn <- 30\nNrep <- 100\nmu <- 5; sigma <- 1\nsamples <- replicate(Nrep, rnorm(n, mu, sigma))\nmeans <- colMeans(samples)\nses <- apply(samples, 2, sd) / sqrt(n)\nlower <- means - qt(0.975, df = n-1) * ses\nupper <- means + qt(0.975, df = n-1) * ses\n\nplot(1:Nrep, means, ylim = c(4,6), pch = 19, col = \"gray40\",\n     ylab = \"Mean estimate\", xlab = \"Sample\",\n     main = \"100 simulated 95% Confidence Intervals\")\nsegments(1:Nrep, lower, 1:Nrep, upper, col = \"gray60\")\nabline(h = mu, col = \"red\", lwd = 2)\nlegend(\"topright\", legend=\"True mean\", col=\"red\", lwd=2, bty=\"n\")\n```\n\n\n\n\n\n\n\n\n\n## Confidence Interval for Iris Data {.smaller}\n\nCompute a real example for Sepal.Length.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nt.test(iris$Sepal.Length)\n```\n\nüëâ The output shows:\n\n- Sample mean\n- Confidence limits\n- t-statistic and p-value\n\nYou can visualize the result below.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nm <- mean(x)\nse <- sd(x)/sqrt(length(x))\nci <- m + c(-1,1)*qt(0.975, df=length(x)-1)*se\n\nhist(x, breaks = 15, col = \"lightgray\",\n     main = \"95% Confidence Interval for Sepal.Length\",\n     xlab = \"Sepal.Length\")\nabline(v = m, col = \"blue\", lwd = 2)\nabline(v = ci, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend=c(\"Mean\", \"95% CI limits\"), \n       col=c(\"blue\",\"red\"), lwd=2, lty=c(1,2), bty=\"n\")\n\n```\n\n\n\n\n\n\n\n\n\n\n\n## üôãÔ∏è **Any Questions?**{ .smaller  background=\"#fdf6e3\"}\n\n::: columns\n::: {.column width=\"50%\"}\n### Thank You!\n\n![](figs/qa2.png){width=\"110%\" style=\"box-shadow: none;\"}\n\n:::\n\n::: {.column width=\"50%\"}\n<div style=\"text-align:right;\">\n  <img src=\"figs/avatar.jpg\" width=\"120px\" style=\"border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,.25);\" />\n</div>\n\n### **Henrique C. Martins**\n\n- üåê [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)  \n- üíº [LinkedIn](https://www.linkedin.com/in/henriquecastror/)  \n- üß† [Google Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)  \n- üìÑ [Lattes CV](http://lattes.cnpq.br/6076997472159785)  \n- üè† [Personal Website](https://henriquemartins.net/)  \n:::\n:::\n\n","srcMarkdownNoYaml":"\n\n```{r setup}\n#| include: false\n#| warning: false\n\n# library(reticulate)\n# use_python(\"C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe\")\nlibrary(reticulate)\nlibrary(Statamarkdown)\n#reticulate::py_install(\"matplotlib\")\n#reticulate::py_install(\"seaborn\")\n#reticulate::py_install(\"pyfinance\")\n#reticulate::py_install(\"xlrd\")\n#reticulate::py_install(\"quandl\")\n#reticulate::py_install(\"linearmodels\")\n#reticulate::py_install(\"causalml\")\n\n```\n\n\n\n\n\n\n\n\n# Basic Statistics {.smaller}\n\n## Basic stats {.smaller }\n\nThe following are simple examples of how to compute basic statistics using R. We will start importing the data. Let's use the free dataset `iris`, available in R.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\niris <- iris \n```\n\n\nFirst, explore the dataset.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nstr(iris) \n```\n\n\n- We have 5 variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width e Species. The first four are numeric while the last is a string with three groups: setosa, versicolor, and virginica. The dataset contains 150 observations\n\n\n\n\n\n\n\n## Basic stats {.smaller }\n\nLet's take a look at the first 10 observations in the dataset.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nhead(iris, 10) \n```\n\n\n## Basic stats {.smaller }\n\n\nNow, let's take a look at the first 5 observations of each species.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nby(iris,iris[\"Species\"],head,n=5)\n```\n\n\n\n\n\n\n\n## Mean and Median {.smaller }\n\nNow, let's find the means and the medians of the four numeric variables. The most intuitive way is as follows.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmean(iris$Sepal.Length)\nmean(iris$Sepal.Width)\nmean(iris$Petal.Length)\nmean(iris$Petal.Width)\n \nmedian(iris$Sepal.Length)\nmedian(iris$Sepal.Width)\nmedian(iris$Petal.Length)\nmedian(iris$Petal.Width)\n```\n\n\n\n## Mean and Median {.smaller }\n\nBut this is the easiest way.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nsummary(iris)\n```\n\n\n\n## Mean and Median {.smaller }\n\nSee that in the code above you also have the number of observations of each species. If you wanted to know how many observations you have in the dataset, you could use the following line. This might be important in the future.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlength(iris$Species)\n```\n\n\n## Mean and Median {.smaller }\n\nIf you want the same thing by group, do as follows:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nby(iris, iris$Species, summary)\n```\n\n\n\n\n\n\n\n## Minimum and maximum  {.smaller }\n\nThe function `summary`already gives you the minimum and maximum of all variables. But sometimes you need to find only these values. You could use the following lines.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmin(iris$Sepal.Length)\nmax(iris$Sepal.Length)\n```\n      \nYou could also find the range of values to find the extreme values of a variable.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nrange(iris$Sepal.Length)\n```\n\n\n\n\n\n## Minimum and maximum  {.smaller }\n\nIf you need the distance between the extreme values, you can use:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmax(iris$Sepal.Length) - min(iris$Sepal.Length)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n## Standard-deviation and Variance {.smaller }\n\nFinally, you can also compute the Standard-deviation and Variance of one variable as follows.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nsd(iris$Sepal.Length)\nvar(iris$Sepal.Length) \n```\n\nIf you want the standard deviation of all variables:\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlapply(iris[, 1:4], sd)\n```\n\n\n\n\n\n\n\n\n\n\n \n## Correlation {.smaller }\n\nThe following lines will show you a correlation table. First, you need to create a new dataframe with only the numeric variables. This is an extremely important table to your academic paper.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(dplyr)\niris_num <- select(iris,-Species)\ncor(iris_num)\n```\n\n\n\n\n\n\n\n## Frequence table {.smaller }\n\nHere is another important table you might use in your paper: the frequency of observations by group.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\ntable(iris$Species)\n```\n\n\n\n\n\n\n## T-test {.smaller }\n\nLet's create now a t-test of the difference in means. For that, we will use another dataset: `mtcars`. The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles. You can find the description of the variables [here](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars).\n\nYou will find that there is one variable that is binary: either the cars are automatic (1) or are manual (0).\n\nWhen you have binary variables, it is always a good idea to test if the means of the variables are different between the two groups of the binary variable.\n\nThis is a big thing and you will use a lot in your academic research. In fact, in many articles, the authors explore and compare two groups. So, be ready to create such an analysis.  \n\n\n\n\n\n\n\n## T-test {.smaller }\n\nFirst, import the new dataset. Then, repeat the first steps and inspect this dataset (I will not inspect the dataset here, but you should inspect as a way to practice it). \n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmtcars <- mtcars\n```\n\n\n\n## T-test {.smaller }\n\nThen, use the binary variable to see if other variables have similar means. The following case compares the average of `mpg` (miles p/ gas) of automatic vs. manual car.\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nt.test(mpg ~ am, data=mtcars)\n```\n\n- We see that the average in the automatic car is around 17.1 while the average of manual cars is 24.3.\n- These averages are statistically different, since the t-stat is high (-3.76).\n- So, we can learn that automatic cars consume more gas than manual cars.\n- This type of test will be very  important in your research.\n\n\n\n\n\n\n\n## Dispersion {.smaller}\n\nThese measures show how *spread out* the data are around the mean.  \n\nThe coefficient of variation (CV) compares variability relative to the mean ‚Äî useful in finance for comparing volatility across assets.\n\nInterquartile Range = $Q_3 - Q_1$\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nrange_x <- range(x)\niqr_x   <- IQR(x)\ncv_x    <- sd(x) / mean(x)\n\nlist(\n  range = diff(range_x),\n  IQR = iqr_x,\n  CV = cv_x\n)\n```\n\n\n\n\n\n\n\n## Quantiles & Percentiles {.smaller}\n\nQuantiles divide the data into equal parts (e.g., quartiles, percentiles).\n\nThey are often used to identify thresholds or outliers.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nquantile(iris$Sepal.Length, probs = c(.01,.05,.25,.50,.75,.95,.99))\n```\n\n\n\n\n\n## Distributions {.smaller}\n\nVisualizing the distribution helps you see its shape ‚Äî whether symmetric, skewed, or concentrated.\n\nEmpirical Cumulative Distribution Function (ECDF) = y-axis shows the accumulated proportion of observations below the x-value.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\npar(mfrow = c(1,3))\nhist(iris$Sepal.Length, breaks = 10, main = \"Histogram\", xlab = \"Sepal.Length\")\nplot(density(iris$Sepal.Length), main = \"Kernel Density\", xlab = \"Sepal.Length\")\nplot(ecdf(iris$Sepal.Length), main = \"ECDF\", xlab = \"Sepal.Length\")\npar(mfrow = c(1,1))\n```\n\n\n\n\n\n## Shape: Skewness & Kurtosis {.smaller}\n\nThese measures describe the *shape* of a distribution.  \n- **Skewness:** measures symmetry (right- or left-tailed).  \n- **Kurtosis:** measures tail heaviness (fat tails ‚Üí more extreme events).  \n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nset.seed(123)\nx_sym  <- rnorm(1000, mean = 0, sd = 1)        # symmetric (normal)\nx_right <- rexp(1000, rate = 1) - 1            # right-skewed\nx_fat  <- rt(1000, df = 3)                     # heavy tails (t-distribution)\n\npar(mfrow = c(1,3))\nhist(x_sym, breaks = 25, main = \"Symmetric (Normal)\", col = \"lightgray\", xlab = \"\")\nhist(x_right, breaks = 25, main = \"Right-Skewed (Exponential)\", col = \"lightgray\", xlab = \"\")\nhist(x_fat, breaks = 25, main = \"Fat Tails (t, df=3)\", col = \"lightgray\", xlab = \"\")\npar(mfrow = c(1,1))\n```\n\n\n## Shape: Skewness & Kurtosis {.smaller}\n\nNow, let's compute skewness and kurtosis for our actual data.\n\n\n- Skewness > 0 ‚Üí right tail longer (positive skew).\n- Skewness < 0 ‚Üí left tail longer (negative skew).\n- Kurtosis > 0 ‚Üí heavier tails than normal (leptokurtic).\n- Kurtosis < 0 ‚Üí lighter tails than normal (platykurtic).\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nskewness <- function(v){\n  m <- mean(v); s <- sd(v)\n  mean(((v - m)/s)^3)\n}\nkurtosis_excess <- function(v){\n  m <- mean(v); s <- sd(v)\n  mean(((v - m)/s)^4) - 3\n}\nc(\n  skewness = skewness(iris$Sepal.Length),\n  excess_kurtosis = kurtosis_excess(iris$Sepal.Length)\n)\n```\n\n\n\n## Outliers via IQR Rule {.smaller}\n\nOutliers are points far from most observations. The IQR rule defines them as values beyond 1.5 √ó IQR from the quartiles.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nQ1 <- quantile(x, .25); Q3 <- quantile(x, .75); I <- IQR(x)\nlower <- Q1 - 1.5*I; upper <- Q3 + 1.5*I\nout_idx <- which(x < lower | x > upper)\nlist(\n  thresholds = c(lower = lower, upper = upper),\n  n_outliers = length(out_idx),\n  example_values  = head(x[out_idx], 5)\n)\n\n```\n\n\n\n\n## Transformations: log & z-score {.smaller}\n\nTransformations help stabilize variance and make variables comparable.\n\n- log(x) reduces skewness.\n- z-score standardizes scale.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx     <- iris$Sepal.Length\nx_log <- log(x)\nx_z   <- as.numeric(scale(x))\npar(mfrow = c(1,3))\nhist(x, main=\"Original\", xlab=\"Sepal.Length\")\nhist(x_log, main=\"log(x)\", xlab=\"log(Sepal.Length)\")\nhist(x_z, main=\"z-score\", xlab=\"Standardized\")\npar(mfrow = c(1,1))\n```\n\n\n\n\n\n\n\n\n# Confidence Intervals {.smaller}\n\n## What is a Confidence Interval? {.smaller}\n\nA confidence interval reflects the *uncertainty* around an estimate.  \nIf we repeat the experiment many times, most intervals will capture the true mean, but some will miss it just by chance.\n\nBelow, we simulate **100 random samples** (each with 30 observations from a true mean of 5).  \nEach horizontal line shows a 95% confidence interval for one sample mean.  \nThe **red line** marks the *true mean (Œº = 5)*.  \n\n- Gray dots: sample means  \n- Gray bars: confidence intervals  \n- Intervals that **miss** the red line show random sampling error  \n- About **5 out of 100** intervals are expected to miss (‚âà5%)\n\nüëâ A 95% CI means: *if we repeated the experiment many times, 95% of the intervals would contain the true mean.*\n\n\n\n\n\n## Visual Intuition {.smaller}\n\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4.5\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nset.seed(123)\nn <- 30\nNrep <- 100\nmu <- 5; sigma <- 1\nsamples <- replicate(Nrep, rnorm(n, mu, sigma))\nmeans <- colMeans(samples)\nses <- apply(samples, 2, sd) / sqrt(n)\nlower <- means - qt(0.975, df = n-1) * ses\nupper <- means + qt(0.975, df = n-1) * ses\n\nplot(1:Nrep, means, ylim = c(4,6), pch = 19, col = \"gray40\",\n     ylab = \"Mean estimate\", xlab = \"Sample\",\n     main = \"100 simulated 95% Confidence Intervals\")\nsegments(1:Nrep, lower, 1:Nrep, upper, col = \"gray60\")\nabline(h = mu, col = \"red\", lwd = 2)\nlegend(\"topright\", legend=\"True mean\", col=\"red\", lwd=2, bty=\"n\")\n```\n\n\n\n\n\n\n\n\n\n## Confidence Interval for Iris Data {.smaller}\n\nCompute a real example for Sepal.Length.\n\n```{r}\n#| warning: false\n#| message: false\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nt.test(iris$Sepal.Length)\n```\n\nüëâ The output shows:\n\n- Sample mean\n- Confidence limits\n- t-statistic and p-value\n\nYou can visualize the result below.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| fig-height: 4\n#| echo: true\n#| code-line-numbers: true\n#| eval: true\nx <- iris$Sepal.Length\nm <- mean(x)\nse <- sd(x)/sqrt(length(x))\nci <- m + c(-1,1)*qt(0.975, df=length(x)-1)*se\n\nhist(x, breaks = 15, col = \"lightgray\",\n     main = \"95% Confidence Interval for Sepal.Length\",\n     xlab = \"Sepal.Length\")\nabline(v = m, col = \"blue\", lwd = 2)\nabline(v = ci, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend=c(\"Mean\", \"95% CI limits\"), \n       col=c(\"blue\",\"red\"), lwd=2, lty=c(1,2), bty=\"n\")\n\n```\n\n\n\n\n\n\n\n\n\n\n\n## üôãÔ∏è **Any Questions?**{ .smaller  background=\"#fdf6e3\"}\n\n::: columns\n::: {.column width=\"50%\"}\n### Thank You!\n\n![](figs/qa2.png){width=\"110%\" style=\"box-shadow: none;\"}\n\n:::\n\n::: {.column width=\"50%\"}\n<div style=\"text-align:right;\">\n  <img src=\"figs/avatar.jpg\" width=\"120px\" style=\"border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,.25);\" />\n</div>\n\n### **Henrique C. Martins**\n\n- üåê [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)  \n- üíº [LinkedIn](https://www.linkedin.com/in/henriquecastror/)  \n- üß† [Google Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)  \n- üìÑ [Lattes CV](http://lattes.cnpq.br/6076997472159785)  \n- üè† [Personal Website](https://henriquemartins.net/)  \n:::\n:::\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["logo.css"],"output-file":"part_O1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.549","auto-stretch":true,"html":{"css":"webex.css","include-after-body":"webex.js"},"editor":"visual","title":"Empirical Methods in Finance","subtitle":"Practicing 1","author":"Henrique C. Martins","title-slide-attributes":{"data-background-color":"#b1cafa"},"include-after":["<script type=\"text/javascript\">\n  Reveal.on('ready', event => {\n    if (event.indexh === 0) {\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n    }\n  });\n  Reveal.addEventListener('slidechanged', (event) => {\n    if (event.indexh === 0) {\n      Reveal.configure({ slideNumber: null });\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n    }\n    if (event.indexh === 1) {\n      Reveal.configure({ slideNumber: 'c' });\n      document.querySelector(\"div.has-logo > img.slide-logo\").style.display = null;\n    }\n  });\n</script>\n"],"slideNumber":true,"theme":"simple","chalkboard":true,"previewLinks":"auto","logo":"figs/background8.png","footer":"**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  ","multiplex":true,"scrollable":true}}},"projectFormats":["html"]}
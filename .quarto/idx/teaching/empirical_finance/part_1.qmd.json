{"title":"Infer√™ncia Causal","markdown":{"yaml":{"title":"Infer√™ncia Causal","subtitle":"Part 1","author":"Henrique C. Martins","format":{"revealjs":{"slide-number":true,"theme":"simple","chalkboard":true,"preview-links":"auto","logo":"figs/background2.png","css":"styles.css","footer":"<https://eaesp.fgv.br/>","multiplex":true}}},"headingText":"library(reticulate)","containsRefs":false,"markdown":"\n\n\n\n```{r setup}\n#| include: false\n#| warning: false\n\n\n# use_python(\"C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe\")\nlibrary(reticulate)\nlibrary(Statamarkdown)\n#reticulate::py_install(\"matplotlib\")\n#reticulate::py_install(\"seaborn\")\n#reticulate::py_install(\"pyfinance\")\n#reticulate::py_install(\"xlrd\")\n#reticulate::py_install(\"quandl\")\n\n```\n\n\n# Agenda\n\n## Agenda {.smaller}\n\n- Apresenta√ß√£o do syllabus do curso\n  - Apresenta√ß√£o dos crit√©rios de avalia√ß√£o\n  \n. . .\n\n- Breve apresenta√ß√£o dos temas de pesquisa e discuss√£o inicial sobre a entrega final\n\n. . .\n\n- In√≠cio do conte√∫do\n  - Revis√£o\n  - Introdu√ß√£o a causalidade\n\n\n\n\n\n## Avalia√ß√£o {.smaller}\n\n- Apresenta√ß√£o/Discuss√£o de artigos: **25%** (n√∫mero de artigos a combinar)\n\n- Quizzes e exerc√≠cios: **30%** (n√∫mero aleat√≥rio, sem pr√©vio aviso)\n\n- Projeto final de pesquisa: **35%** (indicar tema at√© o 2o dia de aula)\n\n- Participa√ß√£o em aula: **10%** (intera√ß√µes, perguntas, coment√°rios, etc.)\n\n**(Nota para aprova√ß√£o √© >=6,0)**\n\n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller}\n\n- Formato letter\n  - Entre 2k e 2.5k palavras a depender do journal.\n  \n*The objective of a letter is to facilitate the rapid dissemination of important research that contains an insight, new data, or discuss current important topic.*\n  \n- Ir√° requerer todas as etapas da pesquisa (com √™nfase na an√°lise dos dados, i.e., regress√µes).\n\n- Idealmente, ser√° submetida com o/a orientador/a. Leia-se, sua miss√£o √© \"convencer\" de que o trabalho final √© submet√≠vel a uma revista. \n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller}\n\n- Op√ß√µes de revistas que aceitam letter (checar se refer√™ncias e tabelas fazem parte do word count):\n\n  - [Economic Letters](https://www.sciencedirect.com/journal/economics-letters) (ABS3): 2k palavras\n  - [Journal of Accounting and Public Policy](https://www.sciencedirect.com/journal/journal-of-accounting-and-public-policy) (ABS3): 3k palavras\n  - [Finance Research Letters](https://www.sciencedirect.com/journal/finance-research-letters) (ABS2): 2.5k palavras\n  - [Applied Economic Letters](https://www.tandfonline.com/journals/rael20) (ABS1): 2k palavras\n  - [Brazilian Review of Finance](https://periodicos.fgv.br/rbfin) (A4): [4k palavras](https://periodicos.fgv.br/rbfin/libraryFiles/downloadPublic/140) \n  \n* Voc√™ √© bem-vindo/a para propor outro journal que aceite letter, sob condi√ß√£o de valida√ß√£o junto ao instrutor. \n  \n\n\n\n\n## Sobre a letter  {.smaller}\n\nEm toda a aula, voc√™ far√° o report da situa√ß√£o do seu documento em at√© 1 slide e em at√© 2 minutos.\n\nProvidenciar inclus√£o dos slides no monitor da sala no in√≠cio da aula. \n\n\n\n\n\n\n\n## Stata {.smaller}\n\n**Providenciar programa instalado semana que vem**.\n\nPara instala√ß√£o do Stata, seguir instru√ß√µes da TI. \n\n\n\n\n\n\n\n## R {.smaller}\n\n**Providenciar programa instalado semana que vem**.\n\n\nInstall R [here Win](https://cran.r-project.org/bin/windows/base/)\n\nInstall R [here Mac](https://cran.r-project.org/bin/macosx/)\n\nInstall R Studio [here](https://posit.co/download/rstudio-desktop/)\n\n. . .\n\nPara instalar e carregar os pacotes voc√™ precisa rodar as duas linhas abaixo.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: false\n\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n\n\n\n## Python {.smaller}\n\n**I might show some code in python, but I cannot offer you support on it.**\n\n\n\n\n\n\n# Selection bias  {.smaller background=\"#fadea7\"} \n\n##  {.smaller background=\"#fadea7\"} \n\n\n![](figs/slides4-airplane.png)\n\n\n\n\n\n\n##  {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path1.jpg)\n\n\n**Voc√™ nunca sabe o resultado do caminho que n√£o toma.**\n\n\n\n\n\n\n\n\n\n\n\n\n## Quais as aplica√ß√µes do que vamos discutir? {.smaller background=\"#fadea7\"} \n\nH√° uma s√©rie de **quest√µes de pesquisa** que poderiam ser investigadas com as ferramentas que vamos discutir hoje.\n\n::: incremental\n\n1) Vale mais a pena estudar em escola particular ou p√∫blica?\n\n2) Qual o efeito de investimentos de marketing t√™m na lucratividade?\n\n3) Qual o efeito que jornadas de 4 dias semanais t√™m na produtividade?\n\n4) Qual efeito que educa√ß√£o tem na remunera√ß√£o futura?\n\n5) E diversas outras semelhantes...\n\n:::\n\n\n\n\n\n\n## Antes de come√ßar: Nossa agenda {.smaller background=\"#fadea7\"} \n\n\n::: incremental \n\n1) Introdu√ß√£o a **pesquisa quantitativa**\n\n2) Validade **Externa** vs. Validade **Interna**\n\n3) **Problemas** em pesquisa quantitativa inferencial\n\n4) **Rem√©dios**\n\n:::\n\n\n\n\n\n\n        \n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n::: incremental\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato)\n\n- Hip√≥teses\n\n- Modelo emp√≠rico\n\n- Coleta de dados \n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n  \n:::\n\n\n\n\n\n\n\n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato): **Aqui √© onde a matem√°tica √© necess√°ria**\n\n- Hip√≥teses\n\n- Modelo emp√≠rico: **Estat√≠stica e econometria necess√°rias**\n\n- Coleta de dados: **Geralmente secund√°rios**\n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n\n\n\n\n\n\n\n. . .\n\n## Defini√ß√£o {.smaller background=\"#fadea7\"} \n\n**_Pesquisa quantitativa busca testar hip√≥teses..._**\n\n. . .\n\n**_...a partir da defini√ß√£o de modelos formais (abstratos)..._**\n\n. . .\n\n**_...de onde se estimam modelos emp√≠ricos utilizando a estat√≠stica e a econometria como mecanismos/instrumentos._**\n\n. . .\n\n\nNo fim do dia, buscamos **entender as rela√ß√µes** (que tenham **validade interna** e que ofere√ßam **validade externa**) entre diferentes **vari√°veis de interesse.**\n\n\n\n\n\n\n\n\n\n\n\n## Quais as vantagens? {.smaller background=\"#fadea7\"} \n\n1) **Validade externa:** \n\n. . .\n\n- Conceito de que, se a pesquisa tem validade externa, os seus **achados s√£o representativos**.\n\n. . .\n\n- I.e., s√£o **v√°lidos al√©m do seu modelo**. Resultados \"valem externamente\".\n\n. . .\n\n- Idealmente, buscamos resultados que valem externamente para **acumular conhecimento**...\n\n. . .\n\n- ...naturalmente, nem toda pesquisa quantitativa oferece validade externa. A pesquisa √≥tima sim. **A pesquisa excelente tem validade externa para al√©m do seu tempo**.\n\n. . .\n\n- Pesquisa qualitativa dificilmente oferece **validade externa**.\n\n\n\n\n\n\n\n\n\n\n## Quais as armadilhas? {.smaller background=\"#fadea7\"} \n\n\n2) **Validade interna:** \n\n. . .\n\n- Conceito de que a pesquisa precisa de validade interna para que seus **resultados sejam cr√≠veis**.\n\n. . .\n\n- I.e., os **resultados n√£o podem conter erros**, vieses, problemas de estima√ß√£o, problemas nos dados, etc..\n\n. . .\n\n- √â aqui que a gente separa a pesquisa ruim da pesquisa boa. Para ser levada a s√©rio, a pesquisa **PRECISA** ter validade interna.\n\n. . .\n\n- Mas isso, nem sempre √© trivial. Muitas pesquisas que vemos publicadas, mesmo em top journals, **n√£o t√™m validade interna** (seja por erro do pesquisador, por m√©todo incorreto, por falta de dados...)\n\n. . .\n\n- Mas cada vez mais, **avaliadores est√£o de olho** em problemas e em modelos  **Trash-in-Trash-out**\n\n\n\n\n\n\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\nExemplo de modelo emp√≠rico:\n\n$Y_{i} = Œ± + ùú∑_{1} √ó X_i + Controls + error$\n\n. . .\n\n<img src=\"figs/slides4-ols.jpg\" width=\"30%\" align=\"right\" />\n\n. . .\n\nUma vez que estimemos esse modelo, temos o **valor**, o **sinal** e a **signific√¢ncia** do $ùú∑$.\n\n. . .\n\nSe o Beta for **significativamente diferente de zero** e **positivo** --> X e Y est√£o positivamente correlacionados.\n\n. . .\n\n**O problema?** Os pacotes estat√≠sticos que utilizamos **sempre \"cospem\" um beta**. Seja ele com ou sem vi√©s.\n\n. . .\n\nCabe ao pesquisador ter um **design emp√≠rico** que garanta que o beta estimado tenha validade interna.\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\n\n<img src=\"figs/slides4-table.png\" width=\"110%\" align=\"center\" />\n\nA decis√£o final √© baseada na signific√¢ncia do Beta estimado. Se **significativo**, as vari√°veis s√£o relacionadas e fazemos infer√™ncias em cima disso.\n\nContudo, **sem um design emp√≠rico inteligente**, o beta encontrado pode ter literalmente qualquer sinal e signific√¢ncia.\n\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius1.png\" width=\"100%\" align=\"center\" />\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius2.png\" width=\"110%\" align=\"center\" />\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see I {.smaller background=\"#fadea7\"} \n\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(data.table)\nlibrary(ggplot2)\n# Generate Data\nn = 10000\nset.seed(100)\nx <- rnorm(n)\ny <- rnorm(n)\ndata1 <- 1/(1+exp( 2 - x  -  y))\ngroup  <- rbinom(n, 1, data1)\n\n# Data Together\ndata_we_see     <- subset(data.table(x, y, group), group==1)\ndata_all        <- data.table(x, y, group)\n\n# Graphs\nggplot(data_we_see, aes(x = x, y = y)) + \n      geom_point(aes(colour = factor(-group)), size = 1) +\n      geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n      labs( y = \"\", x=\"\", title = \"The observations we see\")+\n      xlim(-3,4)+ ylim(-3,4)+ \n      theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n            panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n            axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n            axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n            legend.position = \"none\")\n```       \n\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(7, 5))\nplt.scatter(data_we_see['x'], data_we_see['y'], c=-data_we_see['group'], cmap='viridis', s=20)\nsns.regplot(x='x', y='y', data=data_we_see, scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"The observations we see\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()\n\n```       \n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\ntwoway (scatter x y if group == 1, mcolor(black) msize(small))    (lfit y x if group == 1, color(blue)),title(\"The observations we see\", size(large) ) xtitle(\"\") ytitle(\"\")\nquietly graph export figs/graph1.svg, replace\n```       \n\n![](figs/graph1.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see II  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\n# Fit a linear regression model\nmodel <- lm(y ~ x, data = data_we_see)\n# Print the summary of the regression model\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_we_see['x']  \nX = sm.add_constant(X)\ny = data_we_see['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x if group ==1\n\n```    \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nggplot(data_all, aes(x = x, y = y,  colour=group)) + \n  geom_point(aes(colour = factor(-group)), size = 1) +\n  geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n  labs( y = \"\", x=\"\", title = \"All observations\")+\n  xlim(-3,4)+ ylim(-3,4)+ \n  theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n      panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n      axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n      axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n      legend.position = \"none\")\n``` \n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(6, 4))\nsns.scatterplot(data=data_all, x='x', y='y', hue='group', palette=['blue', 'red'], s=20)\nsns.regplot(data=data_all, x='x', y='y', scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"All observations\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.legend(title=\"Group\", labels=[\"0\", \"1\"], loc=\"upper left\")\n\nplt.gca().get_legend().remove()\nplt.show()\n```       \n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: false\n#| output: true\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\ntwoway (scatter x y if group == 1, mcolor(red) msize(small))   (scatter x y if group == 0, mcolor(blue) msize(small))   (lfit y x , color(blue)),  title(\"All observations\", size(large))    legend(order(1 \"Group 0\" 2 \"Group 1\")) \nquietly graph export figs/graph2.svg, replace\n\n```  \n\n![](figs/graph2.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nmodel2 <- lm(y ~ x, data = data_all)\nsummary(model2)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_all['x']  \nX = sm.add_constant(X)\ny = data_all['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x \n\n```    \n\n\n:::\n\n\n\n\n\n\n\n\n\n## Selection bias {.smaller background=\"#fadea7\"} \n\nSelection bias n√£o √© o √∫nico dos nossos problemas, mas √© um **importante**.\n\nVeja que suas conclus√µes mudaram significativamente.\n\nN√£o seria dif√≠cil criar um exemplo em que o **coeficiente verdadeiro** fosse positivo.\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path2b.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=iPBV3BlV7jk)\n\n**N√£o podemos pegar dois caminhos.**\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-matching.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=6YrIDhaUQOE)\n\n**N√£o podemos comparar pessoas que n√£o s√£o compar√°veis.**\n\n\n\n\n\n\n\n\n## O que precisamos fazer? {.smaller background=\"#fadea7\"} \n\n. . .\n\nDefinir um bom **_Design emp√≠rico_**\n\n. . .\n\nNo mundo ideal: ter√≠amos **universos paralelos.** Ter√≠amos **dois clones**, em que cada um escolhe um caminho. Todo o resto √© igual.\n\n- Obviamente, isso n√£o existe.\n\n. . .\n\nSegunda melhor solu√ß√£o: **experimentos**\n\n. . .\n\n**Mas o que √© um experimento?**\n\n- Grupo de tratamento vs. Grupo de controle\n\n- Igualdade entre os grupos (i.e., aleatoriedade no sampling)\n\n    - Nada diferencia os grupos a n√£o ser o fato de que um indiv√≠duo recebe tratamento e o outro n√£o\n    - Estamos comparando ma√ßas com ma√ßas e laranjas com laranjas\n      \n- Testes placebo/falsifica√ß√£o.\n\n\n\n\n\n\n\n\n\n\n\n\n\n# The challenge {.smaller background=\"#b0aeae\"}\n\n## Correlation & Causality {.smaller background=\"#b0aeae\"}\n\n\nIt is very common these days to hear someone say ‚Äú*correlation does not mean causality*.‚Äù \n\nIn essence, that is true.\n\n- *The killer struck during daylight. Had the sun not been out that day, the victim would have been safe.*\n\n. . .\n\n- There is a correlation, but it is clear there is no causation.\n\n\n\n\n\n\n\n## Correlation & Causality  {.smaller background=\"#b0aeae\"}\n\nSometimes, there is causality even when we do not observe correlation.\n\n*The sailor is adjusting the rudder on a windy day to align the boat with the wind, but the boat is not changing direction.* ([Source: The Mixtape](https://mixtape.scunning.com/01-introduction#do-not-confuse-correlation-with-causality))\n\n\n```{=html}\n<iframe width=\"1000\" height=\"450\" src=\"https://mixtape.scunning.com/01-introduction#do-not-confuse-correlation-with-causality\" title=\"The Mixtape\"></iframe>\n```\n\n. . .\n\nIn this example, the sailor is *endogenously* adjusting the course to balance the unobserved wind.\n\n\n\n\n## The challenge  {.smaller background=\"#b0aeae\"}\n\n- I will discuss some issues in using plain OLS models in Finance Research (mainly with panel data).\n\n. . .\n\n- I will avoid the word ‚Äúendogeneity‚Äù as much as I can\n\n. . .\n\n- I will also avoid the word ‚Äúidentification‚Äù because identification does not guarantee causality and vice-versa (Kahn and Whited 2017)\n\n. . .\n\n- The discussion is based on [Atanasov and Black (2016)](https://www.nowpublishers.com/article/Details/CFR-0036)\n\n![](figs/slides1-empiricalissues-paper.png)\n\n\n\n\n\n\n\n\n## The challenge  {.smaller background=\"#b0aeae\"}\n\n- Imagine that you want to investigate the effect of Governance on Q\n\n    - You may have more covariates explaining Q (omitted  from slides)\n  \n $ùë∏_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$\n\n. . . \n\n All the issues in the next slides will make it not possible to infer that __changing Gov will _CAUSE_ a change in Q__ \n \n That is, cannot infer causality\n \n![](figs/slides1-empiricalissues-wrong.jpg)\n\n\n\n\n\n\n\n\n## 1) Reverse causation   {.smaller background=\"#b0aeae\"}\n\n_One source of bias is: reverse causation_\n\n- Perhaps it is Q that causes Gov\n\n- OLS based methods do not tell the difference between these two betas:\n\n$ùëÑ_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$\n\n$Gov_{i} = Œ± + ùú∑_{i} √ó Q + Controls + error$\n\n- If one Beta is significant, the other will most likely be significant too\n\n- You need a sound theory!\n\n\n\n\n\n\n\n\n\n\n\n\n## 2) Omitted variable bias (OVB)  {.smaller background=\"#b0aeae\"}\n\n_The second source of bias is: OVB_\n\n- Imagine that you do not include an important ‚Äútrue‚Äù predictor of Q\n\n- Let's say, long is:  $ùë∏_{i} = ùú∂_{long} + ùú∑_{long}* gov_{i} + Œ¥ * omitted + error$\n\n- But you estimate short:  $ùë∏_{i} = ùú∂_{short} + ùú∑_{short}* gov_{i} + error$\n\n- $ùú∑_{short}$ will be: \n\n    - $ùú∑_{short} = ùú∑_{long}$ +  bias\n\n    - $ùú∑_{short} = ùú∑_{long}$ +  relationship between omitted (omitted) and included (Gov) * effect of omitted in long (Œ¥)\n\n        - Where: relationship between omitted (omitted) and included (Gov) is: $Omitted = ùú∂ + œï *gov_{i} + u$\n\n- Thus, OVB is: $ùú∑_{short} ‚Äì ùú∑_{long} = œï * Œ¥$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 3) Specification error  {.smaller background=\"#b0aeae\"}\n\n_The third source of bias is: Specification error_\n\n- Even if we could perfectly measure gov and all relevant covariates, we would not know for sure the functional form through which each influences q\n\n    - Functional form: linear? Quadratic? Log-log? Semi-log?\n\n- Misspecification of x‚Äôs is similar to OVB\n\n\n\n\n\n\n\n\n## 4) Signaling   {.smaller background=\"#b0aeae\"}\n\n_The fourth source of bias is: Signaling_\n\n- Perhaps, some individuals are signaling the existence of an X without truly having it:\n\n    - For instance: firms signaling they have good governance without having it\n\n- This is similar to the OVB because you cannot observe the full story\n\n\n\n\n\n\n\n\n\n## 5) Simultaneity  {.smaller background=\"#b0aeae\"}\n\n_The fifth source of bias is: Simultaneity_\n\n- Perhaps gov and some other variable x are determined simultaneously\n\n- Perhaps there is bidirectional causation, with q causing gov and gov also causing q \n\n- In both cases, OLS regression will provide a biased estimate of the effect\n\n- Also, the sign might be wrong\n\n\n\n\n\n\n\n\n\n\n## 6) Heterogeneous effects   {.smaller background=\"#b0aeae\"}\n\n_The sixth source of bias is: Heterogeneous effects_\n\n- Maybe the causal effect of gov on q depends on observed and unobserved firm characteristics:\n\n    - Let's assume that firms seek to maximize q\n    - Different firms have different optimal gov\n    - Firms know their optimal gov\n    - If we observed all factors that affect q, each firm would be at its own optimum and OLS regression would give a non-significant coefficient\n\n- In such case, we may find a positive or negative relationship.\n\n- Neither is the true causal relationship\n\n\n\n\n\n## 7) Construct validity  {.smaller background=\"#b0aeae\"}\n\n_The seventh source of bias is: Construct validity_\n\n- Some constructs (e.g. Corporate governance) are complex, and sometimes have conflicting mechanisms\n\n- We usually don‚Äôt know for sure what ‚Äúgood‚Äù governance is, for instance\n\n- It is common that we use imperfect proxies\n\n- They may poorly fit the underlying concept\n\n\n\n\n\n\n\n## 8) Measurement error   {.smaller background=\"#b0aeae\"}\n\n_The eighth source of bias is: Measurement error_\n\n- \"Classical\" random measurement error for the outcome will inflate standard errors but will not lead to biased coefficients. \n\n    - $y^{*} = y + \\sigma_{1}$\n    - If you estimante $y^{*} = f(x)$, you have $y + \\sigma_{1} = x + \\epsilon$ \n    - $y = x + u$ \n        - where $u = \\epsilon + \\sigma_{1}$ \n\n- \"Classical\" random measurement error in x‚Äôs will bias coefficient estimates toward zero\n\n    - $x^{*} = x + \\sigma_{2}$\n    - Imagine that $x^{*}$ is a bunch of noise\n    - It would not explain anything\n    - Thus, your results are biased toward zero\n\n\n<!-- https://web.stanford.edu/class/polisci100a/regress5.pdf  --> \n\n\n\n\n\n\n\n\n\n## 9) Observation bias   {.smaller background=\"#b0aeae\"}\n\n_The ninth source of bias is: Observation bias_\n\n- This is analogous to the Hawthorne effect, in which observed subjects behave differently because they are observed\n\n- Firms which change gov may behave differently because their managers or employees think the change in gov matters, when in fact it has no direct effect\n\n\n\n\n\n\n\n\n\n\n## 10) Interdependent effects   {.smaller background=\"#b0aeae\"}\n\n_The tenth source of bias is: Interdependent effects_\n\n- Imagine that a governance reform that will not affect share prices for a single firm might be effective if several firms adopt\n\n- Conversely, a reform that improves efficiency for a single firm might not improve profitability if adopted widely because the gains will be competed away\n\n- \"One swallow doesn't make a summer\" \n\n\n\n\n\n\n## 11) Selection bias   {.smaller background=\"#b0aeae\"}\n\n_The eleventh source of bias is: Selection bias_\n\n- If you run a regression with two types of companies\n\n    - High gov (let's say they are the treated group)\n    - Low gov (let's say they are the control group)\n\n    \n- Without any matching method, these companies are likely not comparable\n\n- Thus, the estimated beta will contain selection bias\n\n- The bias can be either be positive or negative\n\n- It is similar to OVB\n\n\n  \n\n## 12) Self-Selection  {.smaller background=\"#b0aeae\"}\n\n_The twelfth source of bias is: Self-Selection_\n\n- Self-selection is a type of selection bias\n\n- Usually, firms decide which level of governance they adopt\n\n- There are reasons why firms adopt high governance\n\n    - If observable, you need to control for\n    - If unobservable, you have a problem\n\n- It is like they \"self-select\" into the treatment.\n\n    - Units decide whether they receive the treatment of not\n\n- Your coefficients will be biased.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Conclus√£o  {.smaller background=\"#b0aeae\"}\n\n**Pesquisa quantitativa tem a parte _quanti (m√©todos, modelos, etc.)_...**\n\n**... Mas talvez a parte mais importante seja o desenho da pesquisa (design emp√≠rico)!**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Preocupa√ß√µes recentes em pesquisa   {.smaller background=\"#b0aeae\"}\n\n**P-Hacking**\n\n![](figs/slides4-phacking.png) \n\nArtigo original [aqui](https://doi.org/10.1111/jofi.12530).\n\n\n\n\n\n\n\n\n\n\n## Preocupa√ß√µes recentes em pesquisa  {.smaller background=\"#b0aeae\"}\n\n**Publication bias**\n\n![](figs/slides4-Harvey-2017.png) \n\n\nArtigo original [aqui](https://doi.org/10.1111/jofi.12530).\n\n\n\n\n\n\n\n \n\n## Preocupa√ß√µes recentes em pesquisa   {.smaller background=\"#b0aeae\"}\n\n**Crise de replica√ß√£o**\n\n\n![](figs/slides4-aguinis.png) \n\n\nArtigo original [aqui](https://link.springer.com/article/10.1057/s41267-017-0081-0).\n\n\n\n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n![](figs/selection bias.png) \n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n![](figs/fig1.jpg) \n\n\n\n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n\n![](figs/hypothesis2.png) \n\n\n\n\n\n\n## Some fun stuff {.smaller background=\"#b0aeae\"}\n\n\n![](figs/confounding variables.png) \n\n\n\n\n\n\n\n\n\n## Some fun stuff {.smaller background=\"#b0aeae\"}\n\n![](figs/proxy variable.png) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Conterfactuals {.smaller background=\"#b3eafc\"}\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n-   Imagine that John and Mary are moving to the north of Canada.\n\n-   John has a history of respiratory disease and decide to buy insurance.\n\n-   Mary does not have a history of respiratory disease and decide not to buy insurance.\n\n-   What is the causal effect of buying insurance?\n\n| Default                     | John   |   Mary |\n|-----------------------------|:-------|-------:|\n| State of insurance          | 1      |      0 |\n| Situation without insurance | `n.o.` |      5 |\n| Situation with insurance    | 4      | `n.o.` |\n| Observed                    | 4      |      5 |\n| Effect                      | ?      |      ? |\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n\n\n\n\n\n\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n**Na√Øve calculation: comparing John com Mary**\n\n$$Y_{john} - Y_{Mary} = 4 - 5 = -1$$\n\nConclusion: buying insurance has a negative effect on health.\n\n. . .\n\n**This is wrong!**\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n| Default                     | John | Mary |\n|-----------------------------|:-----|-----:|\n| State of insurance          | 1    |    0 |\n| Situation without insurance | `3`  |    5 |\n| Situation with insurance    | 4    |  `5` |\n| Observed                    | 4    |    5 |\n| Effect                      | ?    |    ? |\n\n$$(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5$$\n\n**Conclusion:** buying insurance has a positive effect of 1 in John's health and average effect of 0.5 in the sample's health (i.e. averages conditional on insurance status).\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Regressions {.smaller background=\"#dfe3f7\"}\n\n## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n**Let's see how a regression could solve the problem.** Imagine that you have the following data on students' application. (**Decisions in bold**)\n\n| Student | Private   | Private   | Private   | Public    | Public    | Public    | Earnings |\n|---------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n|         | Ivy       | Leafy     | Smart     | State     | Tall      | Altered   | 110,000  |\n| 1       |           | Reject    | **Admit** |           | Admit     |           | 110,000  |\n| 2       |           | Reject    | **Admit** |           | Admit     |           | 100,000  |\n| 3       |           | Reject    | Admit     |           | **Admit** |           | 110,000  |\n| 4       | **Admit** |           | Admit     |           | Admit     | Admit     | 60,000   |\n| 5       | Admit     |           | Admit     |           | Admit     | **Admit** | 30,000   |\n| 6       |           | **Admit** |           |           |           |           | 115,000  |\n| 7       |           | **Admit** |           |           |           |           | 75,000   |\n| 8       | Reject    |           |           | **Admit** | Admit     |           | 90,000   |\n| 9       | Reject    |           |           | Admit     | **Admit** |           | 60,000   |\n\n\n\n\n\n\n\n\n## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n**We can see from the table that:**\n\n-   Some students earn high salary, in both situations\n\n-   Some students earn low salary, in both situations\n\n-   There are clusters of students that applied for the same universities\n\n    -   How likely are they to be similar? Can we benefit from the fact they believe they are similar?\n\n. . .\n\n-   If we compare earnings from the first three individuals:\n\n    -   ((110 + 100)/ 2 - 11000) = -5.000\n\n-   If we compare earnings from individuals 4 and 5:\n\n    -   (60 - 30) = 30.000\n\n-   The average is:\n\n    -   25.000/2 = 12.500\n\n\n\n\n\n\n\n\n\n\n\n## Regression [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\nLet's create a dataframe to run regressions with the previous student's data.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Create the data frame\ndata <- data.frame(\n  id = 1:9,\n  earnings = c(110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000),\n  school = c(\"private\", \"private\", \"public\", \"private\", \"public\", \"private\", \"private\", \"public\", \"public\"),\n  private = c(1, 1, 0, 1, 0, 1, 1, 0, 0),\n  group = c(1, 1, 1, 2, 2, 3, 3, 4, 4)\n)\nprint(data)\n\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport pandas as pd\ndata = pd.DataFrame({\n    'id': range(1, 10),\n    'earnings': [110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000],\n    'school': [\"private\", \"private\", \"public\", \"private\", \"public\", \"private\", \"private\", \"public\", \"public\"],\n    'private': [1, 1, 0, 1, 0, 1, 1, 0, 0],\n    'group': [1, 1, 1, 2, 2, 3, 3, 4, 4]\n})\nprint(data)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\ninput id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\nlist\n```\n:::\n\n\n\n\n\n\n\n\n## \"Naive\" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon$$ **What is the benefit of private education here?**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Create the data frame\nmodel <- lm(earnings ~ private, data = data)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\nimport statsmodels.api as sm\nX = sm.add_constant(data['private'])  \ny = data['earnings']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\n\nreg earnings private \n```\n:::\n\n\n\n\n\n\n\n\n## \"Naive\" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon$$ **What is the benefit of private education here?**\n\nThe coefficient of `private` is 19500, meaning that those that have private education earn 19500 more.\n\n. . . \n\nThe problem with this design is that 1) we are including all students, even those that do not bring any \"information\", and 2) we are not controlling for the differences in students' profiles. \n\n\nLet's fix the first problem first. \n\n**What students should we not include in the model?**\n\n\n\n\n\n## Students id\\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon \\;,\\; if\\; i <=5$$ **What is the benefit of private education here?**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nmodel2 <- lm(earnings ~ private , data = subset(data,id<=5))\nsummary(model2)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\n\nsubset_data = data[data['id'] <= 5]\nX = sm.add_constant(subset_data['private']) \ny = subset_data['earnings']\nmodel2 = sm.OLS(y, X).fit()\nprint(model2.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\nreg earnings private if id<=5\n```\n:::\n\n\n\n\n\n## Students id\\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon \\;,\\; if\\; i <=5$$ **What is the benefit of private education here?**\n\nStudents 6 and 7 only applied to Private, while students 8 and 9 did not really had a choice. So we should exclude them.\n\n. . .\n\nThe benefit of private is now 20000.\n\nThe coefficient did not change much, but the design improved partially.\n\n. . .\n\nWe still have an uncontrolled \"heterogeneity\" in the groups of students. **Students 1 to 3 seem to earn more no matter their decisions**.\n\n\n\n\n\n\n\n## Apples-to-Apples [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group+ \\epsilon \\;,\\; if\\; i <=5$$ **This is the best we can do.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\ndata$dummy <- ifelse(data$group == 1, 1, 0)\ndata$dummy[data$group == 2] <- 0\nmodel3 <- lm(earnings ~ private + dummy, data = subset(data,id<=5))\nsummary(model3)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\n\ndata['dummy'] = 1\ndata.loc[data['group'] == 2, 'dummy'] = 0\nsubset_data = data[data['id'] <= 5]\nX = sm.add_constant(subset_data[['private', 'dummy']])\ny = subset_data['earnings']\nmodel3 = sm.OLS(y, X).fit()\nprint(model3.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\ngen \tdummy = 1 if group == 1\nreplace dummy = 0 if group == 2\nreg earnings private dummy if id<=5 \n```\n:::\n\n\n\n\n## Regression {.smaller background=\"#dfe3f7\"}\n\nThe previous regression assumes that students 1 to 3 are different that students 4 and 5. \n\nWe will find many instances like that in empirical research. E.g., industry. \n\n. . .\n\nThe private school coefficient, in this case 10,000, implies a private-public earnings differential of this value.\n\n. . .\n\n::: callout-important\nThe Y above is used in monetary values.\n\nUsing a logged y, ln(Y) or ln(earnings), allows estimates to be interpreted as a percent change.\n\nFor instance if $\\beta=0.05$, it means that the earnings differential is 5% for those studying in private schools (conditional on the controls included in the model). \n:::\n\n\n\n\n\n\n\n\n\n\n\n# OVB again {.smaller background=\"#f5caae\"}\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n\n\nRegression is a way to make other things equal (ceteris paribus), but equality  is generated only for variables included in the model as controls on the right-hand sided of the model.\n\nFailure to include enough controls of the right controls still leave us with selection bias.\n\nThe regression version of the selection bias generated by the inadequate controls is called **Omitted Variable Bias (OVB)**. \n\nThe inclusion of a control that should not be included is called \"**Bad Controls**\" problem.\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**How could we calculate the OVB in this example?**\n\n\n$$earnings_i = 70.000 + 20.000\\times Private_i  \\epsilon $$\n\n$$earnings_i = 40.000 + 10.000 \\times Private_i + 60.000 \\times Group+ \\epsilon$$ \n\n\n- $\\beta$ (1st regression) - $\\beta$ (second regression).\n- The OVB here is 20.000 - 10.000 = 10.000.\n- Meaning that the $\\beta$ (1st regression) is 10.000 higher than what it should be.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**How could we calculate the OVB in this example?**\n\n\nWe could calculate the bias by estimating:\n\n$$Private=\\alpha + \\beta_{omitted} \\times Group + \\epsilon$$\n\nThen,\n\n$$\\beta_{omitted} \\times \\beta_{missing} = 0.1667 * 60.000 = 10.000$$\n\nThe OVB is 10.000, meaning that the first model (the one with the omitted variable) estimates a Beta that is 10.000 higher than it should be. \n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmodel4 <- lm(private ~ dummy , data = subset(data,id<=5))\nsummary(model4)\nmatrix2<- summary(model4)$coefficients\nsum(0.1667 * 60000 )\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nsubset_data = data[data['id'] <= 5]\nmodel4 = sm.OLS(subset_data['private'], sm.add_constant(subset_data[['dummy']])).fit()\nprint(model4.summary())\nbias = 0.1667 * 60000\nprint(bias)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\ngen \tdummy = 1 if group == 1\nreplace dummy = 0 if group == 2\nreg private dummy if id<=5\ndi .1666667 *  60000 \n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**So what?**\n\n- Anticipating the effect of the omitted variable on the non-omitted variable can tell you the sign of the bias.\n\n- Then you can know if the bias is attenuating or increasing the effect you are investigating.\n\n- If attenuating, the problem is smaller than if it is increasing\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**Regressions**\n\n-   The previous examples show that we can run **regressions and find correlations** ...\n\n-   ... And we can run regressions and find **causal effects**.\n\n-   But we need to control for all relevant variables, otherwise we have the *OVB problem*.\n\n-   Should you not look careful to your data, you'd miss the inclusion of the variable `group`.\n\n-   The results show that you may estimate a spurious coefficient twice the size of the \"true\" coefficient.\n\n\n\n\n\n\n\n# Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\n\n## Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\n**Bad controls** are variables that are **also outcome of the treatment** being studied.\n\nA **Bad control** could very well be a **dependent variable** of the treatment as well. \n\n**Good controls** are variables that **you can think as being fixed** at the time of the treatment. \n\n. . .\n\nLet's return to the model.\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group+ \\epsilon \\;,\\; if\\; i <=5$$ \n\n\nAssuming you also have the occupation of the students at the time of earnings. Should you include `occupation` in the model?\n\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group + \\beta_3 Occupation + \\epsilon \\;,\\; if\\; i <=5$$ \n\nReasoning: \"*We should use occupation as control because it would be wise to look at the effect of education on earnings only for those within an occupation*\".\n\nWhat is the problem with this reasoning?\n\n\n\n\n\n\n\n\n## Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\nThe problem is that studying in private would increase the chances of getting a white-collar occupation, i.e., *private education (treatment) affects the occupation (bad control)*.\n\nIn this case, should you include occupation as control, the coefficient of interest no longer has a causal interpretation.\n\n\n. . .\n\n**This is a very common problem in empirical research**.\n\nIt is not hard to come up with stories of why a control is a bad control.\n\n\n\n\n\n\n# Randomization {.smaller background=\"#ff9c6b\"}\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Now I want to discuss the idea of randomization**\n\nSuppose you have developed a treatment (e.g., a program) that you believe will increase the 'motivation' of employees of a factory.\n\nYou have 100 employees to use in an experiment to test your claim that the treatment will increase motivation.\n\n. . .\n\n- You randomly allocate 50 employees to receive the treatment. The other 50 are part of the control group.\n\n. . .\n\n- You treat all employees in the same manner, except for the treatment.\n\n\n\n. . .\n\nUsing the data available, this is the **difference in motivation between the treatment and control groups (next slide):**\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(dplyr)\ndata  <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\n# Box plot control vs treatment groups\nggplot(data, aes(y=motivation, fill=group)) +   \n  geom_boxplot()+\n  theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n        axis.text.x = element_blank(),\n        legend.title = element_blank(),\n        legend.key.size = unit(3, \"cm\"))\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read data from Excel file\ndata = pd.read_excel(\"files/part_3_data.xlsx\")\n\n# Create a box plot of control vs treatment groups using seaborn\nplt.figure(figsize=(7, 5))\nsns.set(style='whitegrid')\nsns.boxplot(x='group', y='motivation', data=data, palette='Set2')\nplt.title(\"Box Plot of Control vs Treatment Groups\", fontsize=18)\nplt.xlabel(\"Group\", fontsize=14)\nplt.ylabel(\"Motivation\", fontsize=14)\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\n\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\ngraph box motivation , over(group) box(1, color(black)) \tytitle(\"Motivation\")  \n\nquietly graph export \"files/graph3_5.svg\", replace\n```       \n\n![](files/graph3_5.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\nThe calculated means are below. And they are statistically different.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\ndata  <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\ntapply(data$motivation, data$group, summary)\nt.test(motivation ~ group, data = data)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\ndata = pd.read_excel(\"files/part_3_data.xlsx\")\ngroup_summary = data.groupby('group')['motivation'].describe()\nprint(group_summary)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\nbys group  : sum motivation\nestpost ttest motivation , by(group)\n```\n:::\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Is there evidence that the program has increased motivation?**\n\n. . .\n\n- well, if you randomly split a group of 100 people into two groups of 50, you certainly wouldn't get the same mean motivation in both groups even if you treated them exactly alike. \n\n- Maybe the difference that we see is just such a difference?\n\n**How can we test this hypothesis?**\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Solution**: \n\n- Suppose the treatment had no effect, and the employees developed their motivation  independently of the treatment. \n\n- What is the chance that the 50 employees randomly assigned to the treatment group would have an average at least 1.47 (22.27 - 20.80)  points higher than the average motivation of the employees randomly assigned to the control group?\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Steps**\n\n1) Randomly split the 100 employees that we observed in this experiment into two groups of 50.\n\n2) Note the difference in the mean motivation  between the two groups.\n\n3) Repeat 1 and 2 a total of 10,000 times.\n\n4) Note the proportion of times the difference is at least 1.47 (22.27 - 20.80).\n\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary libraries\ndata <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\ncomb <- 10000\ndf <- data.frame(matrix(ncol = 2, nrow = comb))\ncolnames(df) <- c(\"order\" ,\"diff\")\n# Create the loop for randomization:\nfor (i in seq(from = 1, to = comb)) {\n  set.seed(i)                               \n  data$temp <- runif(100, min = 0, max = 1)  # Creating 100 random numbers 0 to 1\n  data <- data[order(data$temp),]            # Sorting data by the random numbers generated in the previous row\n  data$rank <- rank(data$temp)               # Ranking by the random numbers\n# The row below defines the treatment group based on the random numbers generated. This is where we guarantee randomization\ndata$status_rank <- case_when(data$rank <= 50 ~ \"Control_rand\", data$rank > 50 ~ \"Treated_rand\")\n# Calculate the new means of the new groups. Need to transpose data.\nmeans <- t(as.data.frame(tapply(data$motivation, data$status_rank, mean)))\n# Moving the new means to df. Each row is the difference of means\ndf[i, 1] <- i\ndf[i, 2] <- means[1, 2] - means[1, 1]\nrm(means) # Deleting value\ndata = subset(data, select = -c(temp, rank, status_rank)) # Deleting variables\n}\n# Calculate a suitable binwidth for the histogram\nbinwidth <- (max(df$diff) - min(df$diff)) / sqrt(length(df$diff))\n# Create a histogram of the differences with the calculated binwidth\nggplot(df, aes(x = diff)) +\n  geom_histogram(binwidth = binwidth, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Differences\", x = \"Difference\", y = \"Frequency\")\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\nset seed 472195 \t\t\nsort group\t\t \nset obs 10000 \t\t\t\t \negen fin_order = seq() \nsort fin_order \t\t\t\t \nsummarize \t\t\t\t\t\ngen av_diff=.\n\nlocal i = 1\nwhile `i'<=10000 {\n\n\tsort fin_order\n\tgen rand_num`i' = uniform() if !missing(motivation)\n\tegen ordering`i' = rank(rand_num`i')\n\tsort ordering`i'\n\n\tgen group`i' = \"\"\n\treplace group`i' = \"T\" if ordering <= 50\n\treplace group`i' = \"C\" if ordering > 50 & ordering<=100\n\t\n\tqui summ motivation if group`i'==\"T\"\n\tscalar avT = `r(mean)'\n\tqui summ motivation if group`i'==\"C\"\n\tscalar avC = `r(mean)'\n\t\n\tsort fin_order\n\treplace av_diff = avT-avC in `i'\n\t\n\tdrop rand_num`i' ordering`i' group`i'\n\tlocal i = `i' + 1\n}\nhistogram av_diff, frequency kdensity  \ngraph export \"files/graph3_6.png\" , replace\n\n```       \n\n![](files/graph3_6.png){ width=800px height=450px }\n:::\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\nThe mean difference was as far from 0 as 1.5 for only a few out of the 10,000 random divisions of the data into two groups of 50.\n\n- Thus, **the difference between the mean motivation would almost always be less than the observed difference of 1.47 (22.27 - 20.80) if the treatment had no effect.**\n\n- It seems reasonable to believe that the treatment caused the difference in motivation.\n\n\n\n\n\n\n\n\n\n# Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\nThe measurement error problem has a similar statistical structure to the omitted variable bias (OVB).\n\n- \"Classical\" random measurement error for the $y$ will inflate standard errors but will not lead to biased coefficients. \n\n    - $y^{*} = y + \\sigma_{1}$\n    - If you estimante $y^{*} = f(x)$, you have $y + \\sigma_{1} = x + \\epsilon$ \n    - $y = x + u$ \n        - where $u = \\epsilon - \\sigma_{1}$ \n\n\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\n- \"Classical‚Äù random measurement error in x‚Äôs will bias coefficient estimates toward zero.\n\n- $x^*=x+\\sigma_2$\n\n- Imagine that $x^*$ is a bunch of noise. It would not explain anything. Thus, your results are biased toward zero.\n\n\n\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\nA example using one of the Wooldridge's datasets.\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) \nlibrary(jtools)\ndata <- read.dta(\"files/CEOSAL1.dta\")\nset.seed(2)\ndata$salary_noise <- data$salary + runif(length((data$salary)), min=-100, max= 100)\ndata$roe_noise <- data$roe + runif(length((data$roe)), min=-100, max= 100)\n# OLS model \nmodel1 <- lm(data$salary ~ data$roe)\nmodel2 <- lm(data$salary ~ data$roe_noise)\nmodel3 <- lm(data$salary_noise ~ data$roe)\n#summary(model1)\n#summary(model2)\n#summary(model3)\nexport_summs(model1, model2, model3, digits = 3 , model.names = c(\"Roe\", \"Roe (X) with noise\", \"Salary (y) with noise\") )\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.iolib.summary2 import summary_col\n\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nnp.random.seed(2)\n# Add noise to the 'salary' and 'roe' columns\ndata['salary_noise'] = data['salary'] + np.random.uniform(-100, 100, len(data))\ndata['roe_noise'] = data['roe'] + np.random.uniform(-100, 100, len(data))\n# OLS model\nmodel1 = smf.ols(formula='salary ~ roe', data=data).fit()\nmodel2 = smf.ols(formula='salary ~ roe_noise', data=data).fit()\nmodel3 = smf.ols(formula='salary_noise ~ roe', data=data).fit()\n# Create a summary table for all regressions\nresults = summary_col([model1, model2, model3], \n                      model_names=['Reg 1', 'Reg 2', 'Reg 3'],\n                      stars=True,\n                      float_format='%0.2f')\n# Print the summary table\nprint(results)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.dta\", clear\nset seed 2\ngen salary_noise = salary + runiform() * 200 - 100\ngen roe_noise = roe + runiform() * 200 - 100\neststo: qui reg salary roe\neststo: qui reg salary roe_noise\neststo: qui reg salary_noise roe\nesttab\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# More about Regressions {.smaller background=\"#454343\"}\n\n## Regression {.smaller background=\"#454343\"}\n\nLinear regressions are the workhorse tool in econometrics\n\n-   **Simplicity**: straightforward to understand, implement, and visualize.\n\n. . .\n\n-   **Interpretability**: coefficients have clear interpretations.\n    -   represents the change in the Y for a one-unit change in the X, holding all other variables constant.\n\n. . .\n\n-   **Versatility**: simple linear regression or *multiple linear regression*.\n\n. . .\n\n-   **Assumptions**: linearity, independence of errors, homoscedasticity, and normality of errors.\n\n. . .\n\n-   **Baseline Model**: You can compare the performance of more advanced models to linear regression.\n\n. . .\n\n-   **Estimation**: provides clear estimates of the coefficients' confidence intervals and hypothesis testing.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nIn this setting, the variables $y$ and $x$ can have several names.\n\n| Y                  | X                    |\n|--------------------|----------------------|\n| Dependent variable | Independent variable |\n| Explained variable | Explanatory variable |\n| Response variable  | Control variable     |\n| Predicted variable | Predictor variable   |\n| Regressand         | Regressor            |\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nBroadly, we are interested in how y is explained by x?\n\n-   $y_i = \\alpha + \\beta_1 x_i + \\epsilon$\n\n. . .\n\nPerhaps $\\epsilon$ is the most important part of a regression.\n\nThe interpretation is \"*everything that is not explained by X and that explains Y*\".\n\n. . .\n\nA comment\n\n-   Usually, the literature uses $\\epsilon$ for the \"estimated\" residual.\n\n-   And $\\mu$ for the \"true\" residual, which necessarily implies that the assumptions hold.\n\n-   At the end od the day, you don't need to worry to much with the notation of this term because we are always in the \"estimated world\", and almost never in the \"true world\".\n\n-   The \"true world\" implies that you are studying the population or that you have a true random sample of the population\n\n    -   $y_i = \\alpha + \\beta_1 x_i + \\mu$\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Remember**\n\n- $y, x$, and $\\mu$ are random variables\n- $y and x$ are observable\n- $\\mu$ and $\\beta$ are unobservable\n- $\\mu$ captures everything that determines y after accounting for x \n\nOur goal is to estimate Œ≤\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nThere are some assumptions/requirements about $\\mu$ in a OLS\n\n**First assumption**\n\n-   E($\\mu$) = 0\n\n    -   This is a simple assumption, not strong at all.\n    -   It simply assumes that the average of $\\mu$ is zero in the population.\n    -   Basically, any non-zero mean is absorbed by the intercept\n        -   Say that E($\\mu$) = k\n        -   We could rewrite $\\mu = k + w$, where E(w)=0\n        -   Then, model becomes $y=(\\alpha +ùëò) + \\betaùë•+ùë§$\n        -   Intercept is now just (Œ± + k), and error, w, is mean zero\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Second assumption**\n\n-   E($\\mu$\\|x) = E($\\mu$) for all values of x\n    -   It says that the average value of $\\mu$ does not depend on the value of x (i.e., the slice of the population you are looking at).\n    -   We say that $\\mu$ is mean-independent of x.\n    -   This is true if the X and the $\\mu$ are independent to each other.\n    -   Implies that x and $\\mu$ are *uncorrelated*.\n    -   **Conditional Mean Independence (CMI)**.\n    -   This is one of the keys assumption to *causal inference*.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Second assumption**\n\n**Example**\n\nLet's say the model is:\n\n$$wage = \\alpha + \\beta Schooling_{years} + \\epsilon$$\n\n-   where $\\epsilon$ represents *unobserved ability*.\n\nDoes CMI hold?\n\nThat is E(ability\\|x=8)=E(ability\\|x=10)=E(ability\\|x=12)?\n\n. . .\n\n**Probably not**, because the unobserved ability should depend on the years of schooling.\n\nThe solution (not trivial) would be to include ability as a new X.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Another example**\n\nConsider the following model (with only one X)\n\n$$Leverage_i = \\alpha + \\beta_1 Profitability_i + \\mu_i$$\n\n-   CMI says that, to every firm *i*, $\\mu$ is the same, even when firms have different profitability.\n\n-   Can you think on examples when this assumption may not hold in this model?\n\n. . .\n\n1)  unprofitable firms have higher bankruptcy risk, which should make them to have lower leverage (tradeoff theory).\n\n2)  unprofitable firms have low cash, which should make them to have more leverage (pecking order theory).\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**The discussion of whether the CMI holds is the origin of the \"endogeneity\" problem.**\n\nYou will face reviewers arguing reasons of why the CMI might not hold in your case.\n\n- Many  will criticize a model by saying it has an ‚Äúendogeneity problem‚Äù, whithout explaining more.\n\n  - This is very generic. **Don't do that!**\n\n. . .\n\nThey should explain what is the source of the problem that is making the model violate CMI.\n\n - OVB, selection bias, reverse causality, simultaneity, etc?\n\n. . . \n\nGenerally speaking, endogeneity refers to a violation of CMI, meaning that $x$ and $\\mu$ are correlated.\n\nThis is always a plausible possibility, since $\\mu$ carries a lot of stuff (something must be correlated with X).\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Third assumption**\n\nCombining 1 and 2 leads to\n\n-   E($\\mu$\\|x) = 0\n    -   This is a very important assumption called **zero conditional mean assumption**.\n\n## Ordinary Least Squares {.smaller background=\"#454343\"}\n\nOur focus is to find estimates for $\\alpha$ and $\\beta$. Should we have access to the population, it would be easy. We could write:\n\n$$y_i= \\alpha + \\beta_1x_i + \\mu$$\n\n. . .\n\nBut remember that,\n\n$$E(u) = 0$$ $$E(u|x) = 0$$\n\nThe second bullet implies that the correlation between x and $\\mu$ is zero (we can write that as E(x,u) = 0).\n\n. . .\n\n::: callout-important\nRemember: $\\alpha$ and $\\beta$ are parameters to be estimated (i.e., constants), while $X$ and $Y$ are variables\n:::\n\n\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nSo we can write that (in the **population**)\n\n$E(y - \\alpha - \\beta_1x ) = 0$\n\n$(x[y - \\alpha - \\beta_1x ]) = 0$\n\n. . .\n\nSo we can write that (in the **sample**)\n\n$\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ) = 0$ , We will use this to find $\\alpha$:\n\n$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ]) = 0$ , We will use this to find $\\beta$:\n\n\n\n\n\n\n\n## Finding $\\alpha$ {.smaller background=\"#454343\"}\n\nFrom before:\n\n$$\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ) =0$$\n\n. . .\n\nPassing the sum operator through\n\n$$\\frac{1}{n}\\sum_{i=1}^n(y_i) - \\frac{1}{n}\\sum_{i=1}^n(\\hat{\\alpha})  - \\frac{1}{n} \\sum_{i=1}^n(\\hat{\\beta_1} x_i )=0$$\n\n. . .\n\nCoefficients are constants, so we can get rid of the sum operator.\n\n$$\\frac{1}{n}\\sum_{i=1}^n(y_i) - \\hat{\\alpha}  - \\hat{\\beta_1} \\frac{1}{n}  \\sum_{i=1}^n(\\ x_i )=0$$\n\n\n\n\n\n\n\n\n## Finding $\\alpha$ {.smaller background=\"#454343\"}\n\n-   We know that $\\frac{1}{n}\\sum_{i=1}^n(y_i)$ is $\\bar{y_i}$ (the mean)\n\n$$\\bar{y_i} - \\hat{\\alpha}  - \\hat{\\beta_1}  \\bar{x_i}=0$$\n\n. . .\n\nSo we write:\n\n$$\\hat{\\alpha}  = \\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}$$\n\n. . .\n\n**Easy Peasy** üòÄ\n\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\nFrom before:\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ]) = 0$$\n\n. . .\n\nBut now we have:\n\n$$\\hat{\\alpha}  = \\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}$$\n\n. . .\n\nThus,\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - (\\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}) - \\hat{\\beta_1} x_i ]) = 0$$\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\nTurning into\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\bar{y_i} ])  -  \\frac{1}{n} \\sum_{i=1}^n (x_i [\\hat{\\beta_1} x_i - \\hat{\\beta_1} \\bar{x_i} ]) = 0$$\n\n. . .\n\nOr\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\bar{y_i} ])  =  \\hat{\\beta_1} \\frac{1}{n} \\sum_{i=1}^n (x_i [ x_i  - \\bar{x_i} ]) $$\n\n. . . \n\nLast step (I am skipping some steps here)\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x} )(y_i - \\bar{y_i} )  =  \\hat{\\beta_1} \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x_i} )^2 $$\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\n\nIf the variance of x is not zero, we can write $\\beta$ as\n\n$$\\hat{\\beta_1} = \\frac{\\sum_i^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_i^n (x_i - \\bar{x})^2} = \\frac{Covariance(x_i,y_i)}{Variance(x_i)}$$\n\n\n\n## Finding $\\mu$  {.smaller background=\"#454343\"}\n\nNow that we have $\\hat{Y_i}=\\hat{\\alpha} + \\hat{\\beta_1} X_i$, we can estimate the residual $\\mu$\n\n$$\\hat{\\mu} = Y_i - \\hat{Y_i}$$\n\n\nWhich is the same as:\n\n$$\\hat{\\mu} = Y_i - \\hat{\\alpha} - \\hat{\\beta_1}x_i$$\n\nMost residuals will not be 0, meaning they do not lie on the best fitting line. \n\n\n\n\n\n\n## Finding $\\mu$  {.smaller background=\"#454343\"}\n\nThe job of an OLS model is find the parameters to minimize the squared error (i.e., to find the best fitting line).\n\n$$\\sum_{i=1}^n \\hat{\\mu}^2 = \\sum_{i=1}^n(Y_i - \\hat{Y_i})^2$$\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nAnother example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \nsummary(reg_tb)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nnp.random.seed(1)\n\nobs = 10000\ndata = pd.DataFrame({\n    'x': np.random.normal(size=obs),\n    'u': np.random.normal(size=obs),\n})\ndata['y'] = 5.5 * data['x'] + 12 * data['u']\n\nX = sm.add_constant(data['x'])\nmodel = sm.OLS(data['y'], X).fit()\n\nprint(model.summary())\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nreg y x \n```\n:::\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nAnother example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb %>% \n  lm(y ~ x, .) %>% \n  ggplot(aes(x=x, y=y)) + \n  ggtitle(\"OLS Regression Line\") +\n  geom_point(size = 0.05, color = \"black\", alpha = 0.5) +\n  geom_smooth(method = lm, color = \"black\") +\n  annotate(\"text\", x = -1.5, y = 30, color = \"red\", \n           label = paste(\"Intercept = \", reg_tb$coefficients[1])) +\n  annotate(\"text\", x = 1.5, y = -30, color = \"blue\", \n           label = paste(\"Slope =\", reg_tb$coefficients[2]))\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a scatterplot with the OLS regression line using Seaborn\nsns.set(style='whitegrid')\nplt.figure(figsize=(7, 5))\nsns.scatterplot(x='x', y='y', data=data, color='black', alpha=0.5, s=5)\nsns.regplot(x='x', y='y', data=data, color='black', scatter=False, line_kws={'color':'black'})\nplt.title('OLS Regression Line')\nplt.annotate(f'Intercept = {model.params[0]:.2f}', xy=(-1.5, 30), color='red')\nplt.annotate(f'Slope = {model.params[1]:.2f}', xy=(1.5, -30), color='blue')\nplt.show()\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nreg y x \npredict yhat1 \ngen yhat2 = -0.0750109  + 5.598296*x \npredict uhat1, residual \ngen uhat2=y-yhat2 \nqui sum uhat* \ntwoway (lfit y x, lcolor(black) lwidth(medium)) (scatter y x, mcolor(black) msize(tiny) msymbol(point)), title(OLS Regression Line) \nqui graph export \"files/graph3.svg\", replace\n```  \n\n![](files/graph3.svg) \n\n:::\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nUsing the previous regressions, we can show  that:\n\n1)  $\\hat{y_i} = \\hat{\\alpha} + \\hat{\\beta_1} x_i$\n\n2)  $\\hat{\\mu_i} = y_i - \\hat{y_i}$\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \n\ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\nsummary(tb[-1:-3])\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\n\nprint(tb[['yhat1','yhat2', 'uhat1','uhat2']].describe())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nclear \nqui set obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict uhat1, residual \npredict yhat1 \ngen yhat2 = -0.0750109  + 5.598296*x \ngen uhat2=y-yhat2 \nsum yhat*  uhat* \n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nWe can easily show that (remember from before) \n\n$$\\sum_i^n(y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i) = 0$$\n\nAnd that \n\n$$\\sum_i^n \\hat{\\mu}  = 0$$\n\nThe graphs next slide shows a spherical figure, suggesting that the residual is not correlated with the the fitted values ($\\hat{y_i}$)\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\ntb %>% \n  lm(uhat1 ~ yhat1 , .) %>% \n  ggplot(aes(x=yhat1, y=uhat1)) + \n  geom_point(size = 0.1, color = \"black\") +\n  geom_smooth(method = lm, color = \"black\")\n```\n\n\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\nmodel = sm.OLS(tb['uhat1'], sm.add_constant(tb['yhat1'])).fit()\n# Create a scatter plot with a regression line\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(7, 4.5))\nsns.scatterplot(x='yhat1', y='uhat1', data=tb, size=0.05, color='black', alpha=0.5)\nsns.regplot(x='yhat1', y='uhat1', data=tb, scatter=False, color='black')\nplt.xlabel('yhat1')\nplt.ylabel('uhat1')\nplt.title('Scatter Plot of uhat1 vs. yhat1')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict yhat1 \npredict uhat1, residual \ntwoway (lfit uhat1 yhat1 , lcolor(black) lwidth(large)) (scatter uhat1 yhat1 , mcolor(black)  msymbol(point))\nqui graph export \"files/graph4.svg\", replace\n```  \n\n![](files/graph4.svg) \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nSimilarly, we can easily show that \n\n$$\\sum_i^nx_i(y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i) = 0$$\n \nAnd that\n \n$$\\sum_i^nx_i\\hat{\\mu}  = 0$$\n\n \nMeaning that the sample covariance between the X and the residual will be always zero.\n\n\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\ntb %>% \n  lm(uhat1 ~ x , .) %>% \n  ggplot(aes(x=x, y=uhat1)) + \n  geom_point(size = 0.1, color = \"black\") +\n  geom_smooth(method = lm, color = \"black\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\nmodel = sm.OLS(tb['uhat1'], sm.add_constant(tb['yhat1'])).fit()\n# Create a scatter plot with a regression line\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(7, 4.5))\nsns.scatterplot(x='x', y='uhat1', data=tb, size=0.05, color='black', alpha=0.5)\nsns.regplot(x='x', y='uhat1', data=tb, scatter=False, color='black')\nplt.xlabel('x')\nplt.ylabel('uhat1')\nplt.title('Scatter Plot of uhat1 vs. x')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict yhat1 \npredict uhat1, residual \ntwoway (lfit uhat1 x , lcolor(black) lwidth(large)) (scatter uhat1 x , mcolor(black) msymbol(point))\nqui graph export \"files/graph5.svg\", replace\n```  \n\n![](files/graph5.svg) \n\n:::\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nLet's say you estimate a model and find the $\\hat{\\mu}$.\n\nIf you calculate the correlation between the X and $\\hat{\\mu}$, you will find zero.\n\n**This is by construction!** It is not an evidence that CMI is nos violated.\n\nIn fact, the OLS \"assumes\" and \"forces\" zero correlation.\n\n**It is intuitive: if you are \"forcing\" zero correlation when the correlation is not in fact zero, your coefficients will be biased.**\n\nThe previous graphs actually show zero correlation. But that is expected and does not suggest the model is not violating CMI.\n\n**At the end of the day, CMI is untestable and unverifiable**.\n\n\n\n\n\n\n\n\n\n# Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n**Understanding what SSR, SSE and SST mean** \n\n- SSE = Sum of Squares Explained = $\\sum_i^n(\\hat{y_i}-\\bar{y})^2$\n- SSR = Sum of Squares Residuals = $\\sum_i^n\\hat{\\mu}^2$\n- SST = Sum of Squares Total = SSE + SSR = $\\sum_i^n(y_i-\\hat{y_i})^2$ \n\n\nR-squared is simply the ratio of portion explained over the total that could be explained.\n\n\n$$R^2 = \\frac{SSE}{SST} = 1-\\frac{SSR}{SST}$$\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n![](figs/R2.jpg)\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\nYou can think this way:\n\n1) If X does not explain Y, then the best predictor of Y is $\\bar{y}$. In that case, your model does not explain anything of Y, thus $R^2$ is zero, and $\\hat{y_i}=\\bar{y}$\n\n. . .\n\n2) If X partially explains Y, then $\\hat{y_i} \\neq \\bar{y}$, meaning that $\\hat{y_i}$ has some inclination (like the figure next slide). This means that $SSE>0$ and your $R^2>0$ but $R^2<1$\n\n. . .\n\n3) Whatever is not explained by $\\hat{y_i}$ is left to $\\sum_i^2\\hat{\\mu}^2$, meaning that SSR will be non-zero.\n\n. . .\n\n4) The ratio of the portion that you can explain by  $\\hat{y_i}$ over the total that is to be explained  $y_i-\\hat{y_i}$ if the $R^2$.\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# Statistics of salary \nmean(salary)\n# OLS model\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nprint(data['salary'].mean())\n# OLS model\nX = data['roe']\nX = sm.add_constant(X)\ny = data['salary']\n\nmodel = sm.OLS(y, X).fit()  # Fit the linear regression model\nsalaryhat = model.fittedvalues  # Predicted values for the dependent variable\nuhat = model.resid  # Predict regression residuals\nsalarymean = pd.Series([y.mean()] * len(y))  # Generating the mean of salary\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nsum salary \nreg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\nmydata <- read.dta(\"files/CEOSAL1.dta\")\nattach(mydata)\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \n# r-squared is simply the ratio of portion explained over total that could be explained - Understanding what SSR, SSE and SST mean \nplot(salary ~ roe)\nabline(lm(salary ~ roe), col = \"blue\")\nabline(lm(salarymean ~ roe), col = \"red\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data[['roe']]\ny = data['salary']\nsalarymean = np.repeat(y.mean(), len(y))\nX_mean = X.mean()\ny_mean = y.mean()\nslope = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\nintercept = y_mean - slope * X_mean\nsalaryhat = slope * X + intercept\n# Plotting the data and regression lines\nplt.scatter(X, y,  alpha=0.7)\nplt.plot(X, salaryhat,  color='blue', linewidth=2)\nplt.plot(X, salarymean, color='red',  linewidth=2)\nplt.xlabel('roe')\nplt.ylabel('salary')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nsum salary , d\nreg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\n\ntwoway (scatter salary roe) (lfit salary roe) (lfit salarymean roe) \nqui graph export \"files/graph4_6.svg\", replace\n```  \n\n![](files/graph4_6.svg) \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\nManually calculating $R^2$\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\nmydata <- read.dta(\"files/CEOSAL1.dta\")\nattach(mydata)\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \n\n# r-squared is simply the ratio of portion explained over total that could be explained\nssr  <- sum(uhat^2)\nssrB <- sum((salary    - salaryhat)^2)\nsst  <- sum((salary    - salarymean)^2)\nsse  <- sum((salaryhat - salarymean)^2)\nsse / sst\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data['roe']\ny = data['salary']\nX = sm.add_constant(X)  # Add a constant term (intercept)\nmodel = sm.OLS(y, X).fit()\nsalaryhat = model.fittedvalues\nuhat = model.resid\nsalarymean = np.repeat(y.mean(), len(y))\n# Calculate R-squared\nssr = np.sum(uhat**2)\nssrB = np.sum((y - salaryhat)**2)\nsst = np.sum((y - salarymean)**2)\nsse = np.sum((salaryhat - salarymean)**2)\nrsquared = sse / sst\nprint(rsquared)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\negen sst  = total((salary    - salarymean)^2)  \negen ssr  = total((salary    - salaryhat)^2)\negen ssrB = total(uhat^2)\t\t\t\t\t\negen sse  = total((salaryhat - salarymean)^2)\t\ndi sse / sst\n```  \n\n:::\n\n\n\n\n\n\n\n# Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nWhen we estimate coefficients we have some \"error of estimation\".\n\n- Basically, you are searching the \"true\" coefficient using a sample, which should be representative of the population but it is not the population itself.\n\n- This means that the coefficient estimated is estimated with error.\n\n- We would like (e.g., we will need) to impose some \"structure\" to that error.\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Standard error and T-stat**\n\nTo assess if the variables are significantly related, you need to assess the significance of $\\beta$ coefficients.\n\nUsing the example from Wooldridge, we know that the Beta of ROE is `18.591`, while the standard error of ROE is `11.123`.\n\n. . .\n\n- The standard error is a measure of the accuracy of your estimate. If you find a large standard error, your estimate does not have good accuracy. \n\n- Ideally, you would find small standard errors, meaning that your coefficient is accurately estimated. \n\n- However, you do not have good control over the magnitude of the standard errors. \n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Standard error and T-stat**\n\nIf you have a large standard error, probably you coefficient will not be significantly different from zero. You can test whether your coefficient is significantly different from zero computing the t-statistics as follows:\n\n$$t_{\\beta} = \\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$$\n\nIf $t_{\\beta}$ is large enough, you can say that $\\beta$ is significantly different from zero. Usually, $t_{\\beta}$ larger than 2 is enough to be significant. \n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nIn the previous example, you can find the t-stat manually as follows ($t_{\\beta} =\\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$):\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# OLS model\nmodel <- lm(salary ~ roe)\nsummary(model)$coefficients[2,1] / summary(model)$coefficients[2,2] \nsummary(model)$coefficients[2,3]\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\n# OLS model\nX = data['roe']\nX = sm.add_constant(X)\ny = data['salary']\nmodel = sm.OLS(y, X).fit()  \n# Extract and calculate specific coefficients\ncoef_beta = model.params['roe']\ncoef_std_error = model.bse['roe']\n# Calculate t-value\nt_value = coef_beta / coef_std_error\n# Print the coefficient and t-value\nprint(\"Coefficient (beta):\", coef_beta)\nprint(\"Standard Error:\", coef_std_error)\nprint(\"t-value:\", t_value)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \nlocal beta = _b[roe]\nlocal std_error = _se[roe]\nlocal t_value = `beta' / `std_error'\ndisplay \"Coefficient (beta): \" `beta'\ndisplay \"Standard Error: \" `std_error'\ndisplay \"t-value: \" `t_value'\n```  \n\n:::\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nNaturally, the previous analysis requires an estimate of $\\beta$ and an estimate of the $\\beta$'s standard error.\n\n\nThe standard error can be defined as:\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n- Where $\\hat{\\sigma}$ is the standard deviation of the error term in the regression, which can be calculated as:\n\n$$\\hat{\\sigma} = \\sqrt{\\frac{SSR}{n-2}}$$\n\n    - The $n-2$ here is an adjustment for the degrees of freedom in the regression.\n\n- SST is defined as before $\\sum_i^n(y_i-\\hat{y_i})^2$ \n\n\n\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# OLS model\nmodel <- lm(salary ~ roe)\n# Extract the standard error of the coefficient for 'roe'\nsummary(model)$coefficients[\"roe\", \"Std. Error\"]\n\n#calculating manually\n# Extract the residuals\nresiduals <- resid(model)\n# Number of observations (n)\nn <- length(residuals)\n# Calculate the mean of the independent variable (roe)\nroe_mean <- mean(roe)\n# Calculate the sum of squared deviations of roe from its mean (SXX)\nSST <- sum((roe - roe_mean)^2)\n# Calculate the sum of squared errors (SSE)\nSSR <- sum(residuals^2)\n# Calculate the standard error of beta\nSd_beta <- sqrt(SSR / ((n - 2)))\n# Calculate S.E\nSe_beta <- Sd_beta / sqrt(SST)\n# Print the standard error of beta\nprint(Se_beta)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data['roe']\ny = data['salary']\nX = sm.add_constant(X)  \nmodel = sm.OLS(y, X).fit()\n# Extract the standard error of the coefficient for 'roe'\nbeta_se_summary = model.bse['roe']\nprint(\"Standard Error (from summary):\", beta_se_summary)\n# Calculate it manually\n# Extract the residuals\nresiduals = model.resid\n# Number of observations (n)\nn = len(residuals)\n# Calculate the mean of the independent variable (roe)\nroe_mean = X['roe'].mean()\n# Calculate the sum of squared deviations of roe from its mean (SST)\nSST = np.sum((X['roe'] - roe_mean) ** 2)\n# Calculate the sum of squared errors (SSE)\nSSE = np.sum(residuals ** 2)\n# Calculate the standard error of beta (Sd_beta)\nSd_beta = np.sqrt(SSE / (n - 2))\n# Calculate SE_beta\nSE_beta = Sd_beta / np.sqrt(SST)\nprint(\"Standard Error (manually calculated):\", SE_beta)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \ngen beta_se_summary = _se[roe]\ngen n = _N\npredict residuals, residuals\nsum roe, meanonly\ngen roe_diff = roe - r(mean)\negen roe_diff_sq = total(roe_diff^2)\ngen residuals_sq = residuals^2\negen residuals_sq_sum = total(residuals_sq)\ngen Sd_beta = sqrt(residuals_sq_sum / (n - 2))\ngen SE_beta = Sd_beta / sqrt(roe_diff_sq)\ndisplay \"Standard Error (from summary): \" sum(beta_se_summary)\ndisplay \"Standard Error (manually calculated): \" sum(SE_beta)\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Another comment:**\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n1) The larger $\\hat{\\sigma}$ is, the larger the variance of $\\beta$. That is, the more \"noise\" in the association between x and Y, the harder it is to learn something about $\\beta$.\n\n2) However, more variation in x, the larger the SST, so the smaller is the variance of $\\beta$.\n\n\n\n\n\n\n\n\n\n# Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\nLooking at both equations below:\n\n$$t_{\\beta} = \\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$$\n\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n\n**What happens if $\\hat{\\sigma}$ is not constant (for the values of x)?**\n\n**In other words, how realistic is to assume that the variance in the errors is the same for all slices of x?**\n\n**Can you think of an example where that may happen?**\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Earnings = f(education)**\n\nPhD have a higher variance of earnings than non-educated people.\n\n. . .\n\n**Leveragge=f(Size)**\n\nIt is quite possible that small firms will have less options of leverage than large companies. \n\nThis means that a sub-sample of large companies will have higher variance in the leverage decisions (and thus the error terms) than the sub-sample of small firms\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\nOne of the key assumptions in OLS estimators is homoscedasticity \n\nThat is, the assumption is that the variance of the errors is homoscedastic (constant variance in all slices of X). \n\nIt means that throughout all observations, the error term shows the **same variance**. \n\nIf errors are not homoscedastic, we have the heteroscedasticity problem.\n\n\n. . . \n\nHeteroskedasticity **does not cause bias or inconsistency in the OLS estimators** of the $\\beta$ like the OVB would. \n\nIt also does not affect the $R^2$. \n\n**What Heteroscedasticity does is to bias the standard errors of the estimates.**\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n![](files/homoscedasticity.png)\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\n\n![](files/heteroscedasticity.png)\n\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Homoskedascticity** = Constant $\\hat{\\sigma}$ to all slices of X.\n\n**Heteroskedascticity** = Non-constant $\\hat{\\sigma}$ to all slices of X.\n\n**Without homoskedascticity, OLS no longer has the minimum mean squared errors**, which means that the *estimated standard errors are biased*, which in turn creates bias in the t-stat and the inference you'll make with your model.\n \n\n. . . \n\nFortunately, we have an easy solution for that.\n\n\n$$Var(\\hat{\\beta_1}) = \\frac{\\sum_i^n(x_i-\\bar{x})^2\\hat{\\mu}^2}{SST^2_x}$$\n\nThis formula simply \"includes\" the heteroskedascticity in the calculation of $Var(\\hat{\\beta_1})$, meaning this correct the estimated standard deviation to heteroskedascticity.\n\nWe call this correction as **Robust Standard Errors** (White Robust).\n\n. . .\n\nIn other words, you should always use Robust Standard Errors. It is easy to use it with R.\n\n\n\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Using Robust Standard-errors.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(sandwich)\nlibrary(foreign) \nlibrary(lmtest)\n\ndata <- read.dta(\"files/CEOSAL1.DTA\")\nmodel <- lm(salary ~ roe, data = data)\nrobust_model <- coeftest(model, vcov = vcovHC(model, type = \"HC3\"))\nSE_beta_robust <- robust_model[\"roe\", \"Std. Error\"]\ncat(\"Robust Standard Error :\", SE_beta_robust, \"\\n\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\ndata = pd.read_stata(\"files/CEOSAL1.DTA\")\nmodel = smf.ols(\"salary ~ roe\", data=data)\nresults = model.fit(cov_type='HC3')  \nSE_beta_robust = results.bse['roe']\nprint(\"Robust Standard Error :\", SE_beta_robust)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\n\nqui reg salary roe \ngen beta_se_non = _se[roe]\n\nqui reg salary roe , robust\ngen beta_se_summary = _se[roe]\n\ndi \"Standard Error (non-robust): \" sum(beta_se_non)\ndi \"Standard Error (robust): \" sum(beta_se_summary)\n```  \n\n:::\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\nNotice that the standard errors have changed quite significantly  in this example. \n\nUsually, the robust standard errors are larger than the traditional ones in empirical works.\n\n**But, in this example, they are smaller.**\n\n. . . \n\nPerhaps more importantly:\n\n**Once the S.e. change, you should expect that the t-stat of the estimates also change.**\n\n\n. . . \n\n\n**Final comment**: robust standard errors are robust in the case of homoskedasticity.\n\n::: {.callout-warning}\nThus, you should always use robust S.E.\n:::\n\n\n\n\n\n\n\n\n\n# Clustered standard errors {.smaller background=\"#edc5d1\"}\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nAlmost always, someone will ask you whether you clustered your standard errors.\n\n**The intuition is the following:**\n\n- When you do not cluster, you are assuming that all observations are independently and identically distributed (i.i.d.), which may or may not be true.\n\n- Imagine you are studying the effect of class size on students achievement.\n\n- How much of a effect would **have the teacher of a class**? \n\n. . . \n\n- In this design, the teacher influences the achievement of all the students in the same class, and one teacher cannot be at two classes at the same time.\n\n- Thus, it would be wise to cluster the errors at the class-level. This assumes that the residual of each individual is clustered with the other individuals in the same class.\n\n\n. . .\n\nIn principle, clustering solves any form of dependence of the residuals in your data.\n\n\n\n\n\n\n\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nIn corporate finance/accounting research panel data research, the tradition is to cluster at the **firm-level**.\n\n- The reason is that the observations of the same firm are not independent trough time, thus are correlated. \n\nBut, there is a lot of debate about this decision. \n\n. . .\n\nThe tip is to cluster where the **randomness exist**. That is quite subjective. In the class size example, the **randomness** comes out of the teacher, since each teacher has their own ways of teaching (materials, resources, etc.).\n\n. . .\n \nBut, it is a good practice to stress this decision a bit in your own research by **also showing results with clustered s.e. at the industry-level**.\n\n. . .\n\n**Final tip**: usually the minimum number of cluster is about 30. Less than that might be insufficient (but, again, the guidance in this topic is very subjective).  \n\n\n\n \n\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nThe clustered standard errors are different because I am fabricating the clusters here for the sake of the coding.\n\nIn your real research, you would have the cluster at hands. \n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(sandwich)\nlibrary(foreign) \nlibrary(lmtest)\nlibrary(plm)\n\ndata <- read.dta(\"files/CEOSAL1.DTA\")\nmodel <- lm(salary ~ roe, data = data)\nrobust_model <- coeftest(model, vcov = vcovHC(model, type = \"HC3\"))\n#clustered\ndata$cluster <- rep(1:35, length.out = nrow(data))\nmodel <- plm(salary ~ roe, data = data, index = c(\"cluster\"))\n\nclustered_se <- vcovHC(model, type = \"HC3\", cluster = \"group\")\nSE_beta_clustered <- sqrt(clustered_se[\"roe\", \"roe\"])\n\ncat(\"Standard Error (robust):\", SE_beta_robust, \"\\n\")\ncat(\"Standard Error (clustered)::\", SE_beta_clustered, \"\\n\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Read the dataset\ndata = pd.read_stata(\"files/CEOSAL1.DTA\")\n\n# Create a new variable 'cluster' with cluster numbers ranging from 1 to 35\ndata['cluster'] = list(range(1, 36)) * (len(data) // 35)\n\n# Fit the linear regression model\nmodel = sm.OLS(data['salary'], sm.add_constant(data['roe'])).fit()\n\n# Compute robust standard errors\nrobust_model = model.get_robustcov_results(cov_type='HC3')\nSE_beta_robust = robust_model.cov_params().loc['roe', 'roe'] ** 0.5\n\n# Fit the linear regression model with clustered standard errors\nmodel_clustered = sm.OLS(data['salary'], sm.add_constant(data['roe'])).fit(cov_type='cluster', cov_kwds={'groups': data['cluster']})\n\n# Extract the clustered standard errors for 'roe'\nclustered_se = model_clustered.HC3_se.loc['roe']\n\nprint(\"Robust Standard Error (HC3):\", SE_beta_robust)\nprint(\"Clustered Standard Error (HC3):\", clustered_se)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\n\nqui reg salary roe \ngen beta_se_non = _se[roe]\n\nqui reg salary roe , robust\ngen beta_se_summary = _se[roe]\n\negen cluster = seq(), block(6)\nqui regress salary roe , vce(cluster cluster)\ngen SE_beta_clustered = _se[roe]\n\ndi \"Standard Error (non-robust): \" sum(beta_se_non)\ndi \"Standard Error (robust): \" sum(beta_se_summary)\ndi \"Standard Error (clustered): \" sum(SE_beta_clustered)\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Panel Data {.smaller background=\"#dff5ce\"}\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nAs explained previously, OVB is a significant source of \"endogeneity\" in empirical research.\n\nOVB is a problem because of the considerable heterogeneity in many empirical settings. \n\n**Many of the omitted variables are unobservable to the researcher.**\n\nPanel data can sometimes offer a partial.\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nWe start defining the following:\n\n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\epsilon_{i,t}$$\n\nWhere: \n\n  - $i = 1, . . . , N$\n  - $t = 1, . . . , T$\n\n. . . \n\n\nImagine that the residual can be decomposed in: \n\n$$\\epsilon_{i,t} = c_i + \\mu_{i,t}$$\n\nThe term $c_i$ is constant.\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nThe term $c_i$ is constant.\n\n**It captures the aggregate effect of all of the unobservable, time-invariant explanatory variables for $y_{it}$.**\n\nTo focus attention on the issues specific to panel data, we assume that $e_{it}$ has a zero mean conditional on $x_{it}$ and $c_i$ for all $t$.\n\n. . .\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n\n**Why?**\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n\n\n- If $x_{it}$ and $c_i$ are correlated, then $c_i$  is referred to as a ‚Äúfixed effect‚Äù.\n  \n  - It there is correlation, there is violation of the *Conditional Mean Independence* (CMI) assumption.\n\n    \n- If $x_{it}$ and $c_i$ are not correlated, then $c_i$  is referred to as a ‚Äúrandom effect‚Äù.\n\n  - Endogeneity is not a concern; however, the computation of standard errors is affected.\n\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**Why might fixed effects arise?**\n\nFE are any time-invariant unit characteristic that cannot be observed in the data.\n\n- education level,\n- firm's culture,\n- technology,\n- managerial talent,\n- investment opportunities,\n- location (economic development, institutions, etc.),\n- etc.\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**We say things like (you have to understand that they refer to FE):** \n\n- \"*Time-invariant heterogeneity at the unit-level*\"\n- \"*Unobserved variation that occur at the unit-level that do not vary over time*\"\n\n**Important**: with FE, you are capturing **all** unobserved heterogeneity that do not vary over time.\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nDefinition of *Panel Data*:\n\nYou have multiple observations per unit (individual, firm, etc.)\n\nIn datasets, it is \"one panel below the other\" not \"one panel beside the other\".\n\n. . . \n\n\n**Four main topics in Panel Data:**\n\n1) Pooled cross-sectional\n\n2) Fixed Effect models (including multidimensional FE)\n\n3) Random Effects model\n\n4) First differences\n\n5) Lagged models\n\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nFormal definition\n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\delta FE +  \\epsilon_{i,t}$$\n\n- $E(\\epsilon_{i,t}) = 0$\n\n- $corr(x_{i,t},FE) \\neq 0$\n\n- $corr(FE, \\epsilon_{i,t}) = 0$\n\n- $corr(x_{i,t},epsilon_{i,t}) = 0$, for all t\n\nThe last assumption is called *strict exogeneity assumption* and means that the residual of any t is uncorrelated with x of any t.\n\n*That is, under a strict exogeneity assumption on the explanatory variables, the fixed effects estimator is unbiased: the idiosyncratic error should be uncorrelated with each explanatory variable across all time periods.*\n\n\n. . .\n\n**Remember that if we ignore FE, we have OVB.**\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**Before we continue...**\n\n**Comment #1**\n\n*The standard errors in this framework must be ‚Äúclustered‚Äù by panel unit (e.g., individual) to allow for correlation in the residual for the same person over time. This yields valid inference as long as the number of clusters is ‚Äúlarge.\"*\n\n. . . \n\n**Comment #2**\n\n*FE cannot solve reverse causality, it might help you with OVB.*\n\n. . . \n\n**Comment #3**\n\n*Three main types of FE:*\n\n- Pooled\n- Within-transformation (when someone says FE, it is usually this one)\n- Random Effects\n\n\n\n\n\n\n# Pooling Cross-sections  {.smaller background=\"#e0cafc\"}\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nWhen you have two periods of the same unit, but the periods are not consecutive, you have a pooled cross-sectional data.\n\nThis is common in survey data.\n\nIf you use only one period, you might find biased results.\n\n. . .\n\nLet's practice with the dataset CRIME2 from Wooldridge. \n\nThis dataset contains data (many cities) on the crime rate, unemployment rate and many other city-related variables.\n\nThere are two years, 82 and 87 (this is pooled cross-section). \n\n\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nIf we estimate only using the year 87, we would interpret that unemployment leads to lower crime rate.\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven) \ndata <- read_dta(\"files/CRIME2.dta\")\ndata1 <- subset(data, year == 87)\nmodel <- lm(crmrte ~ unem, data = data1)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\ndata = pd.read_stata(\"files/CRIME2.dta\")\ndata1 = data[data['year'] == 87]\nmodel = sm.OLS(data1['crmrte'], sm.add_constant(data1['unem'])).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CRIME2.dta\" , clear\nreg crmrte une if year ==87\n```  \n\n:::\n\n\n\n\n\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nWhen we consider a panel, we get the expected positive sign. This is evidence that the previous model suffered from OVB. Still, the coefficient of unem is not significant probably because of time-invariant unobserved heterogeneity in the cities.\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven) \ndata <- read_dta(\"files/CRIME2.dta\")\nmodel <- lm(crmrte ~ d87+ unem, data = data)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\ndata = pd.read_stata(\"files/CRIME2.dta\")\nmodel = sm.OLS(data['crmrte'], sm.add_constant(data[['d87','unem']])).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CRIME2.dta\" , clear\nreg crmrte  d87 une \n```  \n\n:::\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nThis shows us that we should also control for the year variable. \n\nWe call this, **Year Fixed Effects.**\n\nWe still most likely have OVB due to the unobserved heterogeneity in cities, that is, we still would need to include **cities FE**. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Demeaned variables  {.smaller background=\"#fccad9\"}\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\n**A first way to eliminate the FE is by demeaning the data.**\n\nConsider the following:\n\n$$\\bar{y_i} = \\alpha +\\beta \\bar{x_i} + \\delta FE + \\bar{\\epsilon_i}$$\n\n$$\\frac{1}{T}\\sum{y_{i,t}} = \\alpha +\\beta \\frac{1}{T}\\sum{x_{i,t}} + \\delta FE + \\frac{1}{T}\\sum{\\epsilon_{i,t}}$$\n\n. . .\n\nIf we subtract the mean of each variable, we have:\n\n$$(y_{i,t} - \\bar{y_i}) = \\beta (x_{i,t} - \\bar{x_i}) + (\\epsilon_{i,t} - \\bar{\\epsilon_i})$$\n\nBecause the FE does not vary over time, each value is equal to the mean.\n\nThus, when you demean, you eliminate the FE from the equation. You also eliminate the intercept $\\alpha$.\n\n. . .\n\n**Takeaway**: OLS will estimate unbiased coefficients if you demean the variables.\n\nThis is called **within-transformation** because you are demeaning \"within\" the group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\nLet's use the dataset WAGEPAN to estimate the following equation.\n\n$$Ln(wage)=\\alpha + \\beta_1 exper^2 + \\beta_2 married + \\beta_3 union + \\epsilon$$\n\n\nSome variables in the dataset do not vary over time. These variables cannot be included in this equation. \n\n\n\n\n\n\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\nSee page 495 Wooldridge.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign)\nlibrary(stargazer)\nlibrary(sandwich)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\n# Calculate mean by nr for lwage, expersq, married, and union\ndata <- data[order(data$nr), ]  # Sort data by nr for by-group operations\ndata$lwage_mean <- ave(data$lwage, data$nr, FUN = mean)\ndata$expersq_mean <- ave(data$expersq, data$nr, FUN = mean)\ndata$married_mean <- ave(data$married, data$nr, FUN = mean)\ndata$union_mean <- ave(data$union, data$nr, FUN = mean)\n\ndata$lwage_demean <- data$lwage - data$lwage_mean\ndata$expersq_demean <- data$expersq - data$expersq_mean\ndata$married_demean <- data$married - data$married_mean\ndata$union_demean <- data$union - data$union_mean\n\nmodel1 <- lm(lwage ~ educ + black + hisp + exper + expersq + married + union + d81 + d82 + d83 + d84 + d85 + d86 + d87, data = data)\nmodel2 <- lm(lwage_demean ~ expersq_demean + married_demean + union_demean + d81 + d82 + d83 + d84 + d85 + d86 + d87, data = data)\n\nstargazer(model1, model2 ,title = \"Regression Results\", column.labels=c(\"OLS\",\"Demean\"),  type = \"text\")\n\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.iolib.summary2 import summary_col\n\ndata = pd.read_stata(\"files/WAGEPAN.dta\")\n\ndata = data.sort_values(by='nr')  # Sort data by nr for by-group operations\ndata['lwage_mean'] = data.groupby('nr')['lwage'].transform('mean')\ndata['expersq_mean'] = data.groupby('nr')['expersq'].transform('mean')\ndata['married_mean'] = data.groupby('nr')['married'].transform('mean')\ndata['union_mean'] = data.groupby('nr')['union'].transform('mean')\n\ndata['lwage_demean'] = data['lwage'] - data['lwage_mean']\ndata['expersq_demean'] = data['expersq'] - data['expersq_mean']\ndata['married_demean'] = data['married'] - data['married_mean']\ndata['union_demean'] = data['union'] - data['union_mean']\n\nmodel1 = sm.OLS(data['lwage'], sm.add_constant(data[['educ', 'black', 'hisp', 'exper', 'expersq', 'married', 'union', 'd81', 'd82', 'd83', 'd84', 'd85', 'd86', 'd87']])).fit()\nmodel2 = sm.OLS(data['lwage_demean'], sm.add_constant(data[['expersq_demean', 'married_demean', 'union_demean', 'd81', 'd82', 'd83', 'd84', 'd85', 'd86', 'd87']])).fit()\n\n# Display regression results using stargazer\nsummary = summary_col([model1, model2], stars=True)\nprint(summary)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nbys nr:  egen lwage_mean = mean(lwage) \nbys nr:  egen expersq_mean = mean(expersq) \nbys nr:  egen married_mean = mean(married) \nbys nr:  egen union_mean = mean(union)\n\ngen lwage_demean = lwage - lwage_mean\ngen expersq_demean = expersq - expersq_mean\ngen married_demean = married - married_mean\ngen union_demean = union - union_mean\n\neststo: qui reg lwage        educ black hisp exper expersq       married        union d81 d82 d83 d84 d85 d86 d87\neststo: qui reg lwage_demean expersq_demean married_demean union_demean d81 d82 d83 d84 d85 d86 d87\nesttab , mtitles(\"OLS\" \"Demean\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n# Practical Tips  {.smaller background=\"#fce0cc\"}\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nYou will not need to demean the variables every time you want to estimate a fixed effect models.\n\nThe statistical softwares have packages that do that.\n\nYou only need to know that **Fixed effects model** is a **demeaned model**, i.e., a **within-transformation model**. \n\nBut notice that you will have many different Fixed Effects together:\n\n- Firm Fixed Effects\n- Year Fixed Effects\n- Individual Fixed Effects (if individuals change between firms)\n\n. . . \n\nI am calling a **multidimensional fixed effects design** if you expand the FE to interactions of FE. Most common:\n\n- Year-Industry Fixed Effects.\n- CEO-Firm Fixed Effects.\n\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nNotice the number of dummies in the last two columns.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign)\nlibrary(stargazer)\nlibrary(sandwich)\nlibrary(plm)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\n# Calculate mean by nr for lwage, expersq, married, and union\ndata <- data[order(data$nr), ]  # Sort data by nr for by-group operations\ndata$lwage_mean <- ave(data$lwage, data$nr, FUN = mean)\ndata$expersq_mean <- ave(data$expersq, data$nr, FUN = mean)\ndata$married_mean <- ave(data$married, data$nr, FUN = mean)\ndata$union_mean <- ave(data$union, data$nr, FUN = mean)\n\ndata$lwage_demean <- data$lwage - data$lwage_mean\ndata$expersq_demean <- data$expersq - data$expersq_mean\ndata$married_demean <- data$married - data$married_mean\ndata$union_demean <- data$union - data$union_mean\n\n# set panel data\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\n# Random effects regression using plm\nmodel_de <- lm(lwage_demean ~  expersq_demean + married_demean + union_demean +  d81 +d82+ d83+ d84+ d85 +d86 +d87 , data = data)\nmodel_fe <- plm(lwage ~  expersq + married + union + factor(year)              + educ + black + hisp + exper, data = pdata, model = \"within\")\nmodel_du <- lm( lwage ~  expersq + married + union + factor(year) + factor(nr) + educ + black + hisp + exper, data = data)\n\n# Display regression results using stargazer\n#summary(model_de)\n#summary(model_fe)\n#summary(model_du)\nstargazer(model_de, model_fe, model_du ,title = \"Regression Results\",  type = \"text\")\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nbys nr:  egen lwage_mean = mean(lwage) \nbys nr:  egen expersq_mean = mean(expersq) \nbys nr:  egen married_mean = mean(married) \nbys nr:  egen union_mean = mean(union)\n\ngen lwage_demean = lwage - lwage_mean\ngen expersq_demean = expersq - expersq_mean\ngen married_demean = married - married_mean\ngen union_demean = union - union_mean\n\nxtset nr year \neststo: qui reg lwage_demean expersq_demean married_demean union_demean i.year\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui reg lwage expersq married union i.year i.nr  educ black hisp exper \nesttab , mtitles(\"Demean\" \"FE\" \"LSDV\") compress\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nNotice that the parameter $\\delta$ does not have meaning. \n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\delta FE +  \\epsilon_{i,t}$$\n\nIn fact, the previous slides have shown that you will find the same results of a FE model if you include the dummies for the units in the panel (i.e., dummies for the firms or individuals, etc.).\n\nThis is called **least squares dummy variable (LSDV) model**.\n\n- the SE are also identical to the within-transformation model.\n\n- But the R2 of the LSDV will be very high because you are including a lot of \"explanatory variables\".\n\n::: {.callout-note}\nAt the end of the day, you will use the package for the unit's FE (i.e., the firm), and will include the additional FE as dummies, just like a LSDV model.\n:::\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nWhen you estimate a LSDV, the software will inform an $\\alpha$. \n\nBut this coefficient **has no interpretation whatsoever.** \n\n- it will be FE for the dropped unit of FE. \n\nYou can simply ignore it, you even don't need to include in your final table. \n\nNo problem if you do, just **don't make inferences from it**.\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nA FE model helps a lot, but it only does what it can do.\n\nThat is, FE models do not capture **time-variant unobserved heterogeneity**.\n\n. . .\n\nAlso, if you have constant Xs in your model, you will have to drop them.\n\n- More technically, if there is no within-variation in a X, you cannot include it (the software will drop them).\n\n- For instance, the software will drop $year_{birth}$ below if you include CEO FE.\n\n$$Y_{i,t} = \\alpha + \\beta_1 year_{birth} + CEO \\;FE + ... + \\epsilon_{i,t}$$\n\nIf you attempt to include the CEO FE manually, the software will drop a random CEO FE or the variable $year_{birth}$. If you get a beta for $year_{birth}$ it has no meaning.\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nAdding many FE can demand a lot of computational power.\n\nConsider the multidimensional model as follows:\n\n$$Y_{i,t} = \\alpha + \\beta_1 X_{i,t} + Firm \\;FE + Year\\; FE + Year.Industry \\;FE + CEO \\;FE + ... + \\epsilon_{i,t}$$\n\nIt would take a while to estimate in an average computer.\n\n\n\n\n\n\n\n\n# Random Effects  {.smaller background=\"#c6f7ec\"}\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\nRemember that:\n\n$$\\epsilon_{i,t} = c_i + \\mu_{i,t}$$\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n    \n- If they are, you should estimate Fixed Effects\n\n- If $x_{it}$ and $c_i$ are not correlated, then $c_i$  is referred to as a **random effect**.\n\n  - Endogeneity is not a concern; however, the computation of standard errors is affected.\n\nBut, if the $x_{it}$ and $c_i$ are not correlated, there is **no endogeneity concern**. \n\n$c_i$ can be let as part of the $\\epsilon_{i,t}$ without bias in the estimated betas.\n\n\n\n\n\n\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\nAdditionally, the assumption that $x_{it}$ and $c_i$ are not correlated is rather strong and not practical to most applications of corporate finance, economics or public policy.\n\nRE is a model not used often. Cunningham does not even discuss it.\n\n*If the key explanatory variable is constant over time, we cannot use FE to estimate its effect on y.*\n\n*Of course, we can only use RE because we are willing to assume the unobserved effect is uncorrelated with all explanatory variables.*\n\n*Typically, if one uses RE, and as many time-constant controls as possible are included among the explanatory variables (with an FE analysis, it is not necessary to include such controls) RE is preferred to pooled OLS because RE is generally more efficient.*\n\n(Wooldridge, p.496)\n\n\n\n\n\n\n\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(plm)\nlibrary(jtools)\nlibrary(foreign)\ndata <- read.dta(\"files/WAGEPAN.dta\")\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\npo_model <- lm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = data)\nfe_model <- plm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata, model = \"within\")\nre_model <- plm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata, model = \"random\")\n\nstargazer(po_model, fe_model , re_model ,title = \"Regression Results\", column.labels=c(\"OLS\",\"FE\",\"RE\"),  type = \"text\")\n\n```\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nxtset nr year \neststo: qui reg   lwage expersq married union i.year  educ black hisp exper \neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , re\n\nesttab , mtitles(\"OLS\" \"FE\" \"RE\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# FE vs. RE    {.smaller background=\"#5c97f7\" }\n\n\n## FE vs. RE    {.smaller background=\"#5c97f7\" }\n\n*The idea is that one uses the random effects estimates unless the Hausman test rejects.* \n\n*In practice, a failure to reject means either that the RE and FE estimates are sufficiently close so that it does not matter which is used, or the sampling variation is so large in the FE estimates that one cannot conclude practically significant differences are statistically significant.* (Wooldridge)\n\n\n**If the p-value of the Hausman test is significant then use FE, if not use RE.**\n\n\n\n\n\n## FE vs. RE   {.smaller background=\"#5c97f7\" }\n\n\n::: panel-tabset\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\", clear\nxtset nr year\nqui xtreg lwage expersq married union i.year educ black hisp exper, fe\nestimates store fe_model\nqui xtreg lwage expersq married union i.year educ black hisp exper, re\nestimates store re_model\nhausman fe_model re_model\n```  \n\n:::\n\n\n\n\n\n\n\n# First differences   {.smaller background=\"#e3e2b8\"}\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\nIn most applications, the main reason for collecting panel data is **to allow for the unobserved effect, $c_i$, to be correlated with the explanatory variables**. \n\nFor example, in the crime equation, we want to allow the unmeasured city factors in $c_i$ that affect the crime rate also to be correlated with the unemployment rate. \n\nIt turns out that this is simple to allow: **because $c_i$ is constant over time, we can difference the data across the two years.** \n\nMore precisely, for a cross-sectional observation $i$, write the two years as:\n\n\n$$y_{i,1} = \\beta_0 + \\beta_1 x_{i,1} + c_i + \\mu_{i,1}, t=1$$ \n\n$$y_{i,2} = (\\beta_0 + \\delta_0) + \\beta_1 x_{i,2} + c_i + \\mu_{i,2}, t=2$$ \n\nIf we subtract the second equation from the first, we obtain\n\n$$(y_{i,2} - y_{i,1}) = \\delta_0 + \\beta_1 (x_{i,2} - x_{i,1}) + (\\mu_{i,2}-\\mu_{i,1})$$ \n\n\n$$\\Delta y_{i} = \\delta_0 + \\beta_1 \\Delta x_{i} + \\Delta \\mu_{i}$$ \n\n\n\n\n\n\n\n\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\n**So, rather than subtracting the group mean of each variable, you  subtract the lagged observation.**\n\nNot hard to see that, when t=2, FE and FD will give identical solutions\n\n. . .\n\n- FE is more efficient if disturbances $\\mu_{i,t}$ have low serial correlation\n\n- FD is more efficient if disturbance $\\mu_{i,t}$ follow a random walk\n\nAt the end of the day, you can estimate both. \n\nEmpirical research usually estimate FD only in specific circumstances, when they are interested in how changes of X affect changes of Y.\n\nThings like stationarity or trends are often not concerns in panel data\n\n- where N is 10 to 20 \n\n\n\n\n\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\n# Load necessary libraries\nlibrary(plm)\nlibrary(lmtest)\nlibrary(stargazer)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\nols_model <- lm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata)\nfe_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"within\")\nre_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"random\")\nfd_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"fd\")\n\nstargazer(ols_model, fe_model ,re_model, fd_model,title = \"Regression Results\",   type = \"text\")\n\n```\n\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nxtset nr year \neststo: qui reg   lwage expersq married union i.year  educ black hisp exper \neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , re\neststo: qui reg D.lwage D.expersq D.married D.union i.year  D.educ D.black D.hisp D.exper \n\nesttab , mtitles(\"OLS\" \"FE\" \"RE\" \"FD\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Lagged independent variables   {.smaller background=\"#e3bfc3\"}\n\n## Lagged independent variables   {.smaller background=\"#e3bfc3\"}\n\nWhen you have a panel data and are concerned with simultaneity between Y and X, you can endeavor in lagging the Xs.\n\n\n$$y_{i,t} = \\beta_0 + \\beta_1 x_{i,t-1} + c_i + \\mu_{i,t}$$ \n\nAs a matter of fact, this is often expected in finance research. \n\n. . . \n\nThere is a limitation, however.\n\nThe usual proxy of corporate finance research is highly autocorrelated. \n \n - e.g., total assets do not vary much throughout  time. \n \nThus, lagging the X often does not make much of a difference. \n \n::: {.callout-tip}\nAlways do it. Otherwise, you will have to explain why you didn't do it.\n:::\n\n\n\n\n\n\n\n# Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\n## Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\nSometimes you may have something like\n\n$$y_{i,t} = \\beta_0 + \\beta_1 y_{i,t-1}+ \\beta_2 x_{i,t} + c_i + \\mu_{i,t}$$ \n\nThis is called a **Dynamic Panel Model**. It includes $y_{i,t-1}$ as X.\n\n. . .\n\nConsider a FE model.\n\n$$y_{i,t} - \\bar{y_i} = \\beta_0 + \\gamma_1 (y_{i,t-1} - \\bar{y}_{i,t-1}) + \\omega_2 (x_{i,t-1} - \\bar{x_i} )   + (FE_i - \\bar{FE}_i)  + (\\mu_{i,t} - \\bar{\\mu}_i )$$ \n\nThe within transformation removes the time-invariant unobserved heterogeneity from the model. \n\nHowever, it introduces a correlation between the transformed lag $(y_{i,t‚àí1}‚àí\\bar{y}_{i,t-1})$ and the transformed error $(\\mu_{i,t‚àí1}‚àí\\bar{\\mu}_{i,t-1})$ because the average error ($\\bar{\\mu} = \\sum_{i=1}^{T} \\mu_{i,t}$) includes $\\mu_{i,t-1}$, which is also \"included\" in $y_{i,t‚àí1}$ \n\n- $y_{i,t-1} = \\beta_0 + \\beta_1 y_{i,t-2}+ \\beta_2 x_{i,t-1} + c_i + \\mu_{i,t-1}$ \n\n\n\n\n\n\n\n\n## Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\nThe bias declines with panel length because $\\epsilon_{i,t‚àí1}$ becomes a smaller component of the average error term as T increases. \n\nIn other words, with higher T the correlation between the lagged dependent variable and the regression errors becomes smaller.\n\n**[Flannery and Hankins (2013)](https://doi.org/10.1016/j.jcorpfin.2012.09.004)** have a good review with applications in corporate finance.\n\nThey conclude that FE is biased when estimating these models.\n\nThey suggest to estimate **Sys-GMM** or **Least Squares Dummy Variable Correction**. We do not discuss these models in the course.\n\n\n\n\n\n\n\n\n\n\n# Selection Bias {.smaller background=\"#e3e2b8\"}\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nBack to the selection bias example of before.\n\n-   Imagine that John and Mary are moving to the north of Canada.\n\n-   John has a history of respiratory disease and decide to buy insurance.\n\n-   Mary does not have a history of respiratory disease and decide not to buy insurance.\n\n\n\n| Default                     | John | Mary |\n|-----------------------------|:-----|-----:|\n| State of insurance          | 1    |    0 |\n| Situation without insurance | `3`  |    5 |\n| Situation with insurance    | 4    |  `5` |\n| Observed                    | 4    |    5 |\n| Effect                      | ?    |    ? |\n\n$$(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5$$\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nRearranging the terms:\n\n\n$$(Y_{1,john} - Y_{0,Mary})   + (Y_{1,Mary}  - Y_{0,john})  = (4 - 5) + (5 - 3)  = 0.5$$\n$$We\\;see   + We\\;do\\;not\\;see  = (4 - 5) + (5 - 3)  = 0.5$$\n\nThe term $(Y_{1,Mary}  - Y_{0,john}) =  (5 - 3) = 2$ is the **selection bias**.\n\nIt exists because we are comparing two people that should not be compared.\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nSome notation:\n\n$d=1$ for the treated units (treatment group)\n\n$d=0$ for the treated units (control group)\n\n\n. . . \n\n\n$Y_{i}$ = Potential outcome of individual *i*.\n\n$Y_{i,1}$ or  $Y(1)$ = Potential outcome of individual *i*, treatement group.\n\n$Y_{i,0}$ or  $Y(0)$ = Potential outcome of individual *i*, control group.\n\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nSome notation:\n\nThese are the representations of the **causal effect** we often want to estimate.\n\n**Average Treatment Effect:**\n\nATE = $\\frac{1}{N} (E[Y_{i,1}] - E[Y_{i,0}])$\n\n. . . \n\n**Average Treatment Effect on the treated:**\n\nATET = $\\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])$\n\n. . . \n\n**Average Treatment Effect on the untreated:**\n\nATEU = $\\frac{1}{N} (E[Y_{i,1}|D_i=0] - E[Y_{i,0}|D_i=0])$\n\n. . . \n\nOf course, again, we cannot observe both potential outcomes of the same unit *i*.\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nWhen dealing with **causal inference**, we have to find ways to approximate what the hidden potential outcome of the treated units is. \n\nThat is, the challenge in identifying causal effects is that the untreated potential outcomes, $Y_{i,0}$, are never\nobserved for the treated group ($D_i= 1$). The \"second\" term in the following equation:\n\nATET = $\\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])$\n\n\nWe need an empirical design to **\"observe\"** what we do not really observe (i.e., the counterfactual). \n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nMany options:\n\n- Matching/Balancing\n- Difference-in-differences (DiD)\n- Instrumental variables\n- Regression discontinuity design (RDD)\n- Synthetic control (Synth)\n\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nThe process of finding units that are comparable is called **matching**.\n\n. . .\n\n**Before we continue...**\n\n**We will match on observables. We cannot be on unobservables.**\n\nThus, you may want to write in your article \"selection bias due to observables\".\n\n. . .\n\n**Cunningham:**\n\n*Propensity score matching has not seen as wide adoption among economists as in other nonexperimental methods like regression discontinuity or difference-in-differences. The most common reason given for this is that economists are oftentimes skeptical that CIA can be achieved in any dataset almost as an article of faith. This is because for many applications, economists as a group are usually more concerned about selection on unobservables than they are selection on observables, and as such, they reach for matching methods less often.*\n\nCIA = CMI\n\n\n\n\n\n\n\n\n# Matching  {.smaller background=\"#e0cafc\"}\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n**Matching** aims to compare the outcomes between observations that have the same values of all control variables, except that one unit is treated and the other is not. \n\n. . .\n\nIn this literature, the control variables used to matched are often called **covariates**.\n\nThat is, for each treated unit, the researcher finds an untreated unit that is similar in all covariates.\n\nThe implication is that the researcher can argue that \"*units are comparable after matching*\". \n\n\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\nThe easiest to see is **exact matching**: *it matches observations that have the exact same values*. \n\n- It might be doable if you have only one covariate. \n\n- Naturally, if you have only one covariate, you might still be left with some selection bias.\n\n  - In the previous example, health history is one important covariate that makes John and Mary different. \n  \n  - But what about life style? Nutrition? Etc. \n  \n\nAs the number of covariates grow, you cannot pursue exact matching. That is the job of PSM.\n\n\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n**In exact matching, the causal effect estimator (ATET) is:**\n\n$$ATET = \\frac{1}{N} \\sum (E[Y_{i}] - E[Y_{j(i)}] | D_i=1)$$\n\nWhere $Y_{j(i)}$ is the j-th unit matched to the i-th unit based on the j-th being ‚Äúclosest to‚Äù the i-th unit for some  covariate. \n\nFor instance, let‚Äôs say that a unit in the treatment group has a covariate with a value of 2 and we find another unit in the control group (exactly one unit) with a covariate value of 2. \n\nThen we will impute the treatment unit‚Äôs missing counterfactual with the matched unit‚Äôs, and take a difference.\n\n\n\n\n\n\n\n## Matching {.smaller background=\"#e0cafc\"}\n\nConsider the following dataset from Cunningham:\n\n![](figs/scott.png)\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n::: panel-tabset\n### R Averages\n\nAverage ages are very different. The salary of a 24 yrs old person is quite different than the salary of a 32 yrs person.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\nsummary(training_example$age_treat)\nsummary(training_example$age_control)\n```\n\n\n### R Treated\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_treat)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n### R Control\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_control)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n\n### R Matched\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_matched)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n\n:::\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\nIn this example, you are literally finding the units in the control group that have the same age as the units in the treatment group.\n\nYou are exact matching 1-by-1 in this example.\n\nYou have only one covariate, i.e., age.\n\n\n\n\n\n\n\n\n\n\n\n# Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\nThe last example was simple because you could *exact match*.\n\nIf you cannot find one exact match, you need an approximate match. \n\n. . .\n\nIn order to do that, you have to use distance matching.\n\n**Distance matching** minimizes the distance (i.e., how far the covariates are from each other) between the treatment and control groups.\n\n\n\n\n\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Euclidean distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'(X_i-X_j)}=\\sqrt{\\sum_{n=1}^k(X_{n,i}-X_{n,j})^2}$\n\n![](figs/euclidian.png)\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Normalized Euclidean distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'\\hat{V}^{-1}(X_i-X_j)}=\\sqrt{\\sum_{n=1}^k\\frac{(X_{n,i}-X_{n,j})}{\\sigma^2_n}}$\n\nThe problem with this measure of distance is that the distance measure itself depends on the **scale of the variables themselves**. \n\nFor this reason, researchers typically will use some modification of the Euclidean distance, such as the **normalized Euclidean distance**, or they‚Äôll use a wholly different alternative distance. \n\nThe normalized Euclidean distance is a commonly used distance, and what makes it different is that the distance of each variable is scaled by the variable‚Äôs variance. \n\n\n \n \n \n \n \n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Mahalanobis  distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'\\hat{\\sum_x}^{-1}(X_i-X_j)}$\n\nWhere $\\hat{\\sum_x}$ is the sample covariance matrix of X.\n\n. . . \n\n![](figs/malahanobis_king_nielsen.png)\n\n\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\nDistance matching only goes so far...\n\n... **the larger the dimensionality, the harder is to use distance matching**.\n\nAs sample size increases, for a given N of covariates, the matching discrepancies tend to zero.\n\nBut, the more covariates, the longer it takes.\n\n. . . \n\nAt the end of the day, it is preferable to have many covariates, but it is makes distance matching harder.\n\n\n\n\n\n\n\n\n# Coarsened Exact Matching (CER)  {.smaller background=\"#fce0cc\"}\n\n## Coarsened Exact Matching (CER)  {.smaller background=\"#fce0cc\"}\n\nIn coarsened exact matching, something only counts as a match if it exactly matches on each matching variable. \n\n**The ‚Äúcoarsened‚Äù part comes in because, if you have any continuous variables to match on, you need to ‚Äúcoarsen‚Äù them first by putting them into bins, rather than matching on exact values.**\n\nCoarsening means creating bins. Fewer bins makes exact matches more likely. \n\n. . .\n\nCER is not used much in empirical research in finance. It is used more in the big data realm when you have many variables to match. \n\n\n\n\n\n\n\n# Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n**PSM is one way to matching using many covariates.** \n\n**PSM aggregates all covariates into one score (propensity-score), which is the likelihood of receiving the treatment.**\n\nThe idea is to match units that, based on observables, have the same probability (called propensity-score) of being treated. \n\n. . .\n\nThe idea is to estimate a probit (default in stata) or logit model (fist stage):\n\n$$P(D=1|X)$$\n\n**The propensity-score is the predicted probability of a unit being treated given all covariates X**. The p-score is just a single number.\n\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nConsiderations in PSM.\n\n1) How many neighbors to match?\n\n- Nearest neighbor, radius or kernel?\n\n2) With or without replacement?\n\n3) With or without common support?\n\n- *Common support*: imposes a common support by dropping treatment observations whose pscore is higher than the maximum or less than the minimum pscore of the controls.\n\n4) It is expected that, after PSM, you show the overlap of propensity-scores.\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**The y-axis is the propensity-score**.\n\n![](figs/ani_katchova1.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Nearest matching:** Find the observation closest to ($min|p_i-p_j|$)\n\n![](figs/ani_katchova3.png)\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Kernel matching:** Each treated observation i is matched with several control observations, with weights inversely proportional to the distance between treated and control observations.\n\n![](figs/ani_katchova2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Radius matching**: Each treated observation i is matched with control observations j that fall within a specified radius.\n\n$$|p_i-p_j| <r$$\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Common support:** Restrict matching only based on the common range of propensity scores.\n\n![](figs/ani_katchova5.png)\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems good overlap, but \"good\" is arbitrary.\n\n![](figs/psm1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems bad overlap\n\n![](figs/psm2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems good overlap, but \"good\" is arbitrary.\n\n![](figs/psm_graph1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems bad overlap\n\n![](figs/psm_graph2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_bias.png)\n\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_ttest1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_ttest2.png)\n\n\n\n\n\n\n\n\n\n\n# Example  {.smaller background=\"#dff5ce\"}\n\n## Example  {.smaller background=\"#dff5ce\"}\n\nLet's practice with an example. 185 treated units vs 15,992 control units. \n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\n# Load necessary libraries\nlibrary(haven)\nlibrary(psych)\ndata <- read_dta(\"files/cps1re74.dta\")\nsummary_stats <- by(data, data$treat, FUN = function(group) {\n  c(\n    mean = mean(group$age, na.rm = TRUE),\n    variance = var(group$age, na.rm = TRUE),\n    skewness = skew(group$age, na.rm = TRUE),\n    count = length(group$age)\n  )\n})\nsummary_df <- as.data.frame(do.call(rbind, summary_stats))\ncolnames(summary_df) <- c(\"mean\", \"variance\", \"skewness\", \"count\")\nprint(summary_df)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nfrom scipy.stats import skew\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/cps1re74.dta\")\ngrouped_data = data.groupby('treat')['age'].agg(['mean', 'var', lambda x: skew(x, nan_policy='omit'), 'count']).reset_index()\ngrouped_data.columns = ['treat', 'mean', 'variance', 'skewness', 'count']\nprint(grouped_data)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui estpost tabstat age black educ , by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs nonumber compress \n```  \n\n:::\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\nClearly, the treated group is younger, mainly black, and less educated.\n\nAlso note that the **variance and skewness** of the two subsamples are **different**.\n\nIf we were to use these two subsamples in any econometric analysis **without preprocessing to make them comparable**, we would likely have coefficients biased by **selection bias**.\n\nTherefore, it is important to perform some matching method.\n\nLet's start with Propensity Score Matching (PSM). We will use the simplest matching, that is, without using any additional functions.\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Nearest with noreplacement.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# install.packages(\"MatchIt\")\nlibrary(haven)\nlibrary(psych)\nlibrary(MatchIt)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"nearest\")\nsummary(model)\n```\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\npsmatch2 treat age black educ , n(1) noreplacement\nsum _weight , d\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Notice that we are creating weights now**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# install.packages(\"MatchIt\")\nlibrary(haven)\nlibrary(MatchIt)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"exact\")\nsummary(model$weights)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui psmatch2 treat age black educ , kernel\nsum _weight , d\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Now, the descriptive statistics are much closer**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven)\nlibrary(MatchIt)\n#install.packages(\"e1071\")\nlibrary(e1071)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"exact\")\nmatched_data <- match.data(model)\nsummary_stats <- by(matched_data, matched_data$treat, function(x) {\n  c(mean(x$age), var(x$age), skewness(x$age), length(x$age))\n})\n\nresult_df <- data.frame(\n  Treatment = c(\"Control\", \"Treated\"),\n  Mean_Age = sapply(summary_stats, function(x) x[1]),\n  Variance_Age = sapply(summary_stats, function(x) x[2]),\n  Skewness_Age = sapply(summary_stats, function(x) x[3]),\n  Count = sapply(summary_stats, function(x) x[4])\n)\nprint(result_df)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui psmatch2 treat age black educ , kernel\nqui estpost tabstat age black educ [aweight = _weight], by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs  nonumber compress \n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n**Here, instead of matching units, we reweight the observations such that the moments of the distributions (mean, variance, skewness) are similar.**\n\n- The ebalance function implements a reweighting scheme. The user starts by choosing the covariates that should be included in the reweighting. \n\n- For each covariate, the user then specifies a set of balance constraints (in Equation 5) to equate the moments of the covariate distribution between the treatment and the reweighted control group. \n\n- The moment constraints may include the mean (first moment), the variance (second moment), and the skewness (third moment).\n\n**The outcome is a vector containing the weights to weight the observations, such that the weighted average, weighted variance, and weighted skewness of the covariates in control group are similar to those in the treatment group**\n\n\n\n\n\n\n\n\n\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven)\n#install.packages(\"ebal\")\nlibrary(ebal)\ndata <- read_dta(\"files/cps1re74.dta\")\ntreatment <-cbind(data$treat)\nvars <-cbind(data$age, data$educ, data$black)\neb <- ebalance(treatment, vars)\n# means in treatment group data\napply(vars[treatment==1,],2,mean)\n# means in reweighted control group data\napply(vars[treatment==0,],2,weighted.mean,w=eb$w)\n# means in raw data control group data\napply(vars[treatment==0,],2,mean)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nebalance treat age black educ, targets(3)\n```  \n\n:::\n\n\n\n\n\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n\n::: panel-tabset\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui ebalance treat age black educ, targets(3)\nqui estpost tabstat age black educ [aweight = _webal], by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs  nonumber compress \n```  \n\n:::\n\n\n\n\n\n## THANK YOU!\n\n::: columns\n::: {.column width=\"30%\"}\n![](figs/fgv.png){fig-align=\"right\"}\n:::\n\n::: {.column width=\"70%\"}\n**Henrique Castro Martins**\n\n-   [henrique.martins\\@fgv.br](henrique.martins@fgv.br)\n-   <https://eaesp.fgv.br/en/people/henrique-castro-martins>\n-   [henriquemartins.net](https://henriquemartins.net/)\n-   <https://www.linkedin.com/in/henriquecastror/>\n:::\n:::\n","srcMarkdownNoYaml":"\n\n\n\n```{r setup}\n#| include: false\n#| warning: false\n\n\n# library(reticulate)\n# use_python(\"C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe\")\nlibrary(reticulate)\nlibrary(Statamarkdown)\n#reticulate::py_install(\"matplotlib\")\n#reticulate::py_install(\"seaborn\")\n#reticulate::py_install(\"pyfinance\")\n#reticulate::py_install(\"xlrd\")\n#reticulate::py_install(\"quandl\")\n\n```\n\n\n# Agenda\n\n## Agenda {.smaller}\n\n- Apresenta√ß√£o do syllabus do curso\n  - Apresenta√ß√£o dos crit√©rios de avalia√ß√£o\n  \n. . .\n\n- Breve apresenta√ß√£o dos temas de pesquisa e discuss√£o inicial sobre a entrega final\n\n. . .\n\n- In√≠cio do conte√∫do\n  - Revis√£o\n  - Introdu√ß√£o a causalidade\n\n\n\n\n\n## Avalia√ß√£o {.smaller}\n\n- Apresenta√ß√£o/Discuss√£o de artigos: **25%** (n√∫mero de artigos a combinar)\n\n- Quizzes e exerc√≠cios: **30%** (n√∫mero aleat√≥rio, sem pr√©vio aviso)\n\n- Projeto final de pesquisa: **35%** (indicar tema at√© o 2o dia de aula)\n\n- Participa√ß√£o em aula: **10%** (intera√ß√µes, perguntas, coment√°rios, etc.)\n\n**(Nota para aprova√ß√£o √© >=6,0)**\n\n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller}\n\n- Formato letter\n  - Entre 2k e 2.5k palavras a depender do journal.\n  \n*The objective of a letter is to facilitate the rapid dissemination of important research that contains an insight, new data, or discuss current important topic.*\n  \n- Ir√° requerer todas as etapas da pesquisa (com √™nfase na an√°lise dos dados, i.e., regress√µes).\n\n- Idealmente, ser√° submetida com o/a orientador/a. Leia-se, sua miss√£o √© \"convencer\" de que o trabalho final √© submet√≠vel a uma revista. \n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller}\n\n- Op√ß√µes de revistas que aceitam letter (checar se refer√™ncias e tabelas fazem parte do word count):\n\n  - [Economic Letters](https://www.sciencedirect.com/journal/economics-letters) (ABS3): 2k palavras\n  - [Journal of Accounting and Public Policy](https://www.sciencedirect.com/journal/journal-of-accounting-and-public-policy) (ABS3): 3k palavras\n  - [Finance Research Letters](https://www.sciencedirect.com/journal/finance-research-letters) (ABS2): 2.5k palavras\n  - [Applied Economic Letters](https://www.tandfonline.com/journals/rael20) (ABS1): 2k palavras\n  - [Brazilian Review of Finance](https://periodicos.fgv.br/rbfin) (A4): [4k palavras](https://periodicos.fgv.br/rbfin/libraryFiles/downloadPublic/140) \n  \n* Voc√™ √© bem-vindo/a para propor outro journal que aceite letter, sob condi√ß√£o de valida√ß√£o junto ao instrutor. \n  \n\n\n\n\n## Sobre a letter  {.smaller}\n\nEm toda a aula, voc√™ far√° o report da situa√ß√£o do seu documento em at√© 1 slide e em at√© 2 minutos.\n\nProvidenciar inclus√£o dos slides no monitor da sala no in√≠cio da aula. \n\n\n\n\n\n\n\n## Stata {.smaller}\n\n**Providenciar programa instalado semana que vem**.\n\nPara instala√ß√£o do Stata, seguir instru√ß√µes da TI. \n\n\n\n\n\n\n\n## R {.smaller}\n\n**Providenciar programa instalado semana que vem**.\n\n\nInstall R [here Win](https://cran.r-project.org/bin/windows/base/)\n\nInstall R [here Mac](https://cran.r-project.org/bin/macosx/)\n\nInstall R Studio [here](https://posit.co/download/rstudio-desktop/)\n\n. . .\n\nPara instalar e carregar os pacotes voc√™ precisa rodar as duas linhas abaixo.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: false\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: false\n\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n\n\n\n## Python {.smaller}\n\n**I might show some code in python, but I cannot offer you support on it.**\n\n\n\n\n\n\n# Selection bias  {.smaller background=\"#fadea7\"} \n\n##  {.smaller background=\"#fadea7\"} \n\n\n![](figs/slides4-airplane.png)\n\n\n\n\n\n\n##  {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path1.jpg)\n\n\n**Voc√™ nunca sabe o resultado do caminho que n√£o toma.**\n\n\n\n\n\n\n\n\n\n\n\n\n## Quais as aplica√ß√µes do que vamos discutir? {.smaller background=\"#fadea7\"} \n\nH√° uma s√©rie de **quest√µes de pesquisa** que poderiam ser investigadas com as ferramentas que vamos discutir hoje.\n\n::: incremental\n\n1) Vale mais a pena estudar em escola particular ou p√∫blica?\n\n2) Qual o efeito de investimentos de marketing t√™m na lucratividade?\n\n3) Qual o efeito que jornadas de 4 dias semanais t√™m na produtividade?\n\n4) Qual efeito que educa√ß√£o tem na remunera√ß√£o futura?\n\n5) E diversas outras semelhantes...\n\n:::\n\n\n\n\n\n\n## Antes de come√ßar: Nossa agenda {.smaller background=\"#fadea7\"} \n\n\n::: incremental \n\n1) Introdu√ß√£o a **pesquisa quantitativa**\n\n2) Validade **Externa** vs. Validade **Interna**\n\n3) **Problemas** em pesquisa quantitativa inferencial\n\n4) **Rem√©dios**\n\n:::\n\n\n\n\n\n\n        \n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n::: incremental\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato)\n\n- Hip√≥teses\n\n- Modelo emp√≠rico\n\n- Coleta de dados \n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n  \n:::\n\n\n\n\n\n\n\n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato): **Aqui √© onde a matem√°tica √© necess√°ria**\n\n- Hip√≥teses\n\n- Modelo emp√≠rico: **Estat√≠stica e econometria necess√°rias**\n\n- Coleta de dados: **Geralmente secund√°rios**\n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n\n\n\n\n\n\n\n. . .\n\n## Defini√ß√£o {.smaller background=\"#fadea7\"} \n\n**_Pesquisa quantitativa busca testar hip√≥teses..._**\n\n. . .\n\n**_...a partir da defini√ß√£o de modelos formais (abstratos)..._**\n\n. . .\n\n**_...de onde se estimam modelos emp√≠ricos utilizando a estat√≠stica e a econometria como mecanismos/instrumentos._**\n\n. . .\n\n\nNo fim do dia, buscamos **entender as rela√ß√µes** (que tenham **validade interna** e que ofere√ßam **validade externa**) entre diferentes **vari√°veis de interesse.**\n\n\n\n\n\n\n\n\n\n\n\n## Quais as vantagens? {.smaller background=\"#fadea7\"} \n\n1) **Validade externa:** \n\n. . .\n\n- Conceito de que, se a pesquisa tem validade externa, os seus **achados s√£o representativos**.\n\n. . .\n\n- I.e., s√£o **v√°lidos al√©m do seu modelo**. Resultados \"valem externamente\".\n\n. . .\n\n- Idealmente, buscamos resultados que valem externamente para **acumular conhecimento**...\n\n. . .\n\n- ...naturalmente, nem toda pesquisa quantitativa oferece validade externa. A pesquisa √≥tima sim. **A pesquisa excelente tem validade externa para al√©m do seu tempo**.\n\n. . .\n\n- Pesquisa qualitativa dificilmente oferece **validade externa**.\n\n\n\n\n\n\n\n\n\n\n## Quais as armadilhas? {.smaller background=\"#fadea7\"} \n\n\n2) **Validade interna:** \n\n. . .\n\n- Conceito de que a pesquisa precisa de validade interna para que seus **resultados sejam cr√≠veis**.\n\n. . .\n\n- I.e., os **resultados n√£o podem conter erros**, vieses, problemas de estima√ß√£o, problemas nos dados, etc..\n\n. . .\n\n- √â aqui que a gente separa a pesquisa ruim da pesquisa boa. Para ser levada a s√©rio, a pesquisa **PRECISA** ter validade interna.\n\n. . .\n\n- Mas isso, nem sempre √© trivial. Muitas pesquisas que vemos publicadas, mesmo em top journals, **n√£o t√™m validade interna** (seja por erro do pesquisador, por m√©todo incorreto, por falta de dados...)\n\n. . .\n\n- Mas cada vez mais, **avaliadores est√£o de olho** em problemas e em modelos  **Trash-in-Trash-out**\n\n\n\n\n\n\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\nExemplo de modelo emp√≠rico:\n\n$Y_{i} = Œ± + ùú∑_{1} √ó X_i + Controls + error$\n\n. . .\n\n<img src=\"figs/slides4-ols.jpg\" width=\"30%\" align=\"right\" />\n\n. . .\n\nUma vez que estimemos esse modelo, temos o **valor**, o **sinal** e a **signific√¢ncia** do $ùú∑$.\n\n. . .\n\nSe o Beta for **significativamente diferente de zero** e **positivo** --> X e Y est√£o positivamente correlacionados.\n\n. . .\n\n**O problema?** Os pacotes estat√≠sticos que utilizamos **sempre \"cospem\" um beta**. Seja ele com ou sem vi√©s.\n\n. . .\n\nCabe ao pesquisador ter um **design emp√≠rico** que garanta que o beta estimado tenha validade interna.\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\n\n<img src=\"figs/slides4-table.png\" width=\"110%\" align=\"center\" />\n\nA decis√£o final √© baseada na signific√¢ncia do Beta estimado. Se **significativo**, as vari√°veis s√£o relacionadas e fazemos infer√™ncias em cima disso.\n\nContudo, **sem um design emp√≠rico inteligente**, o beta encontrado pode ter literalmente qualquer sinal e signific√¢ncia.\n\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius1.png\" width=\"100%\" align=\"center\" />\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius2.png\" width=\"110%\" align=\"center\" />\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see I {.smaller background=\"#fadea7\"} \n\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(data.table)\nlibrary(ggplot2)\n# Generate Data\nn = 10000\nset.seed(100)\nx <- rnorm(n)\ny <- rnorm(n)\ndata1 <- 1/(1+exp( 2 - x  -  y))\ngroup  <- rbinom(n, 1, data1)\n\n# Data Together\ndata_we_see     <- subset(data.table(x, y, group), group==1)\ndata_all        <- data.table(x, y, group)\n\n# Graphs\nggplot(data_we_see, aes(x = x, y = y)) + \n      geom_point(aes(colour = factor(-group)), size = 1) +\n      geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n      labs( y = \"\", x=\"\", title = \"The observations we see\")+\n      xlim(-3,4)+ ylim(-3,4)+ \n      theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n            panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n            axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n            axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n            legend.position = \"none\")\n```       \n\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(7, 5))\nplt.scatter(data_we_see['x'], data_we_see['y'], c=-data_we_see['group'], cmap='viridis', s=20)\nsns.regplot(x='x', y='y', data=data_we_see, scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"The observations we see\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()\n\n```       \n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\ntwoway (scatter x y if group == 1, mcolor(black) msize(small))    (lfit y x if group == 1, color(blue)),title(\"The observations we see\", size(large) ) xtitle(\"\") ytitle(\"\")\nquietly graph export figs/graph1.svg, replace\n```       \n\n![](figs/graph1.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see II  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\n# Fit a linear regression model\nmodel <- lm(y ~ x, data = data_we_see)\n# Print the summary of the regression model\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_we_see['x']  \nX = sm.add_constant(X)\ny = data_we_see['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x if group ==1\n\n```    \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nggplot(data_all, aes(x = x, y = y,  colour=group)) + \n  geom_point(aes(colour = factor(-group)), size = 1) +\n  geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n  labs( y = \"\", x=\"\", title = \"All observations\")+\n  xlim(-3,4)+ ylim(-3,4)+ \n  theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n      panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n      axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n      axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n      legend.position = \"none\")\n``` \n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| results: false\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(6, 4))\nsns.scatterplot(data=data_all, x='x', y='y', hue='group', palette=['blue', 'red'], s=20)\nsns.regplot(data=data_all, x='x', y='y', scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"All observations\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.legend(title=\"Group\", labels=[\"0\", \"1\"], loc=\"upper left\")\n\nplt.gca().get_legend().remove()\nplt.show()\n```       \n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: false\n#| output: true\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\ntwoway (scatter x y if group == 1, mcolor(red) msize(small))   (scatter x y if group == 0, mcolor(blue) msize(small))   (lfit y x , color(blue)),  title(\"All observations\", size(large))    legend(order(1 \"Group 0\" 2 \"Group 1\")) \nquietly graph export figs/graph2.svg, replace\n\n```  \n\n![](figs/graph2.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nmodel2 <- lm(y ~ x, data = data_all)\nsummary(model2)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_all['x']  \nX = sm.add_constant(X)\ny = data_all['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x \n\n```    \n\n\n:::\n\n\n\n\n\n\n\n\n\n## Selection bias {.smaller background=\"#fadea7\"} \n\nSelection bias n√£o √© o √∫nico dos nossos problemas, mas √© um **importante**.\n\nVeja que suas conclus√µes mudaram significativamente.\n\nN√£o seria dif√≠cil criar um exemplo em que o **coeficiente verdadeiro** fosse positivo.\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path2b.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=iPBV3BlV7jk)\n\n**N√£o podemos pegar dois caminhos.**\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-matching.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=6YrIDhaUQOE)\n\n**N√£o podemos comparar pessoas que n√£o s√£o compar√°veis.**\n\n\n\n\n\n\n\n\n## O que precisamos fazer? {.smaller background=\"#fadea7\"} \n\n. . .\n\nDefinir um bom **_Design emp√≠rico_**\n\n. . .\n\nNo mundo ideal: ter√≠amos **universos paralelos.** Ter√≠amos **dois clones**, em que cada um escolhe um caminho. Todo o resto √© igual.\n\n- Obviamente, isso n√£o existe.\n\n. . .\n\nSegunda melhor solu√ß√£o: **experimentos**\n\n. . .\n\n**Mas o que √© um experimento?**\n\n- Grupo de tratamento vs. Grupo de controle\n\n- Igualdade entre os grupos (i.e., aleatoriedade no sampling)\n\n    - Nada diferencia os grupos a n√£o ser o fato de que um indiv√≠duo recebe tratamento e o outro n√£o\n    - Estamos comparando ma√ßas com ma√ßas e laranjas com laranjas\n      \n- Testes placebo/falsifica√ß√£o.\n\n\n\n\n\n\n\n\n\n\n\n\n\n# The challenge {.smaller background=\"#b0aeae\"}\n\n## Correlation & Causality {.smaller background=\"#b0aeae\"}\n\n\nIt is very common these days to hear someone say ‚Äú*correlation does not mean causality*.‚Äù \n\nIn essence, that is true.\n\n- *The killer struck during daylight. Had the sun not been out that day, the victim would have been safe.*\n\n. . .\n\n- There is a correlation, but it is clear there is no causation.\n\n\n\n\n\n\n\n## Correlation & Causality  {.smaller background=\"#b0aeae\"}\n\nSometimes, there is causality even when we do not observe correlation.\n\n*The sailor is adjusting the rudder on a windy day to align the boat with the wind, but the boat is not changing direction.* ([Source: The Mixtape](https://mixtape.scunning.com/01-introduction#do-not-confuse-correlation-with-causality))\n\n\n```{=html}\n<iframe width=\"1000\" height=\"450\" src=\"https://mixtape.scunning.com/01-introduction#do-not-confuse-correlation-with-causality\" title=\"The Mixtape\"></iframe>\n```\n\n. . .\n\nIn this example, the sailor is *endogenously* adjusting the course to balance the unobserved wind.\n\n\n\n\n## The challenge  {.smaller background=\"#b0aeae\"}\n\n- I will discuss some issues in using plain OLS models in Finance Research (mainly with panel data).\n\n. . .\n\n- I will avoid the word ‚Äúendogeneity‚Äù as much as I can\n\n. . .\n\n- I will also avoid the word ‚Äúidentification‚Äù because identification does not guarantee causality and vice-versa (Kahn and Whited 2017)\n\n. . .\n\n- The discussion is based on [Atanasov and Black (2016)](https://www.nowpublishers.com/article/Details/CFR-0036)\n\n![](figs/slides1-empiricalissues-paper.png)\n\n\n\n\n\n\n\n\n## The challenge  {.smaller background=\"#b0aeae\"}\n\n- Imagine that you want to investigate the effect of Governance on Q\n\n    - You may have more covariates explaining Q (omitted  from slides)\n  \n $ùë∏_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$\n\n. . . \n\n All the issues in the next slides will make it not possible to infer that __changing Gov will _CAUSE_ a change in Q__ \n \n That is, cannot infer causality\n \n![](figs/slides1-empiricalissues-wrong.jpg)\n\n\n\n\n\n\n\n\n## 1) Reverse causation   {.smaller background=\"#b0aeae\"}\n\n_One source of bias is: reverse causation_\n\n- Perhaps it is Q that causes Gov\n\n- OLS based methods do not tell the difference between these two betas:\n\n$ùëÑ_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$\n\n$Gov_{i} = Œ± + ùú∑_{i} √ó Q + Controls + error$\n\n- If one Beta is significant, the other will most likely be significant too\n\n- You need a sound theory!\n\n\n\n\n\n\n\n\n\n\n\n\n## 2) Omitted variable bias (OVB)  {.smaller background=\"#b0aeae\"}\n\n_The second source of bias is: OVB_\n\n- Imagine that you do not include an important ‚Äútrue‚Äù predictor of Q\n\n- Let's say, long is:  $ùë∏_{i} = ùú∂_{long} + ùú∑_{long}* gov_{i} + Œ¥ * omitted + error$\n\n- But you estimate short:  $ùë∏_{i} = ùú∂_{short} + ùú∑_{short}* gov_{i} + error$\n\n- $ùú∑_{short}$ will be: \n\n    - $ùú∑_{short} = ùú∑_{long}$ +  bias\n\n    - $ùú∑_{short} = ùú∑_{long}$ +  relationship between omitted (omitted) and included (Gov) * effect of omitted in long (Œ¥)\n\n        - Where: relationship between omitted (omitted) and included (Gov) is: $Omitted = ùú∂ + œï *gov_{i} + u$\n\n- Thus, OVB is: $ùú∑_{short} ‚Äì ùú∑_{long} = œï * Œ¥$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 3) Specification error  {.smaller background=\"#b0aeae\"}\n\n_The third source of bias is: Specification error_\n\n- Even if we could perfectly measure gov and all relevant covariates, we would not know for sure the functional form through which each influences q\n\n    - Functional form: linear? Quadratic? Log-log? Semi-log?\n\n- Misspecification of x‚Äôs is similar to OVB\n\n\n\n\n\n\n\n\n## 4) Signaling   {.smaller background=\"#b0aeae\"}\n\n_The fourth source of bias is: Signaling_\n\n- Perhaps, some individuals are signaling the existence of an X without truly having it:\n\n    - For instance: firms signaling they have good governance without having it\n\n- This is similar to the OVB because you cannot observe the full story\n\n\n\n\n\n\n\n\n\n## 5) Simultaneity  {.smaller background=\"#b0aeae\"}\n\n_The fifth source of bias is: Simultaneity_\n\n- Perhaps gov and some other variable x are determined simultaneously\n\n- Perhaps there is bidirectional causation, with q causing gov and gov also causing q \n\n- In both cases, OLS regression will provide a biased estimate of the effect\n\n- Also, the sign might be wrong\n\n\n\n\n\n\n\n\n\n\n## 6) Heterogeneous effects   {.smaller background=\"#b0aeae\"}\n\n_The sixth source of bias is: Heterogeneous effects_\n\n- Maybe the causal effect of gov on q depends on observed and unobserved firm characteristics:\n\n    - Let's assume that firms seek to maximize q\n    - Different firms have different optimal gov\n    - Firms know their optimal gov\n    - If we observed all factors that affect q, each firm would be at its own optimum and OLS regression would give a non-significant coefficient\n\n- In such case, we may find a positive or negative relationship.\n\n- Neither is the true causal relationship\n\n\n\n\n\n## 7) Construct validity  {.smaller background=\"#b0aeae\"}\n\n_The seventh source of bias is: Construct validity_\n\n- Some constructs (e.g. Corporate governance) are complex, and sometimes have conflicting mechanisms\n\n- We usually don‚Äôt know for sure what ‚Äúgood‚Äù governance is, for instance\n\n- It is common that we use imperfect proxies\n\n- They may poorly fit the underlying concept\n\n\n\n\n\n\n\n## 8) Measurement error   {.smaller background=\"#b0aeae\"}\n\n_The eighth source of bias is: Measurement error_\n\n- \"Classical\" random measurement error for the outcome will inflate standard errors but will not lead to biased coefficients. \n\n    - $y^{*} = y + \\sigma_{1}$\n    - If you estimante $y^{*} = f(x)$, you have $y + \\sigma_{1} = x + \\epsilon$ \n    - $y = x + u$ \n        - where $u = \\epsilon + \\sigma_{1}$ \n\n- \"Classical\" random measurement error in x‚Äôs will bias coefficient estimates toward zero\n\n    - $x^{*} = x + \\sigma_{2}$\n    - Imagine that $x^{*}$ is a bunch of noise\n    - It would not explain anything\n    - Thus, your results are biased toward zero\n\n\n<!-- https://web.stanford.edu/class/polisci100a/regress5.pdf  --> \n\n\n\n\n\n\n\n\n\n## 9) Observation bias   {.smaller background=\"#b0aeae\"}\n\n_The ninth source of bias is: Observation bias_\n\n- This is analogous to the Hawthorne effect, in which observed subjects behave differently because they are observed\n\n- Firms which change gov may behave differently because their managers or employees think the change in gov matters, when in fact it has no direct effect\n\n\n\n\n\n\n\n\n\n\n## 10) Interdependent effects   {.smaller background=\"#b0aeae\"}\n\n_The tenth source of bias is: Interdependent effects_\n\n- Imagine that a governance reform that will not affect share prices for a single firm might be effective if several firms adopt\n\n- Conversely, a reform that improves efficiency for a single firm might not improve profitability if adopted widely because the gains will be competed away\n\n- \"One swallow doesn't make a summer\" \n\n\n\n\n\n\n## 11) Selection bias   {.smaller background=\"#b0aeae\"}\n\n_The eleventh source of bias is: Selection bias_\n\n- If you run a regression with two types of companies\n\n    - High gov (let's say they are the treated group)\n    - Low gov (let's say they are the control group)\n\n    \n- Without any matching method, these companies are likely not comparable\n\n- Thus, the estimated beta will contain selection bias\n\n- The bias can be either be positive or negative\n\n- It is similar to OVB\n\n\n  \n\n## 12) Self-Selection  {.smaller background=\"#b0aeae\"}\n\n_The twelfth source of bias is: Self-Selection_\n\n- Self-selection is a type of selection bias\n\n- Usually, firms decide which level of governance they adopt\n\n- There are reasons why firms adopt high governance\n\n    - If observable, you need to control for\n    - If unobservable, you have a problem\n\n- It is like they \"self-select\" into the treatment.\n\n    - Units decide whether they receive the treatment of not\n\n- Your coefficients will be biased.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Conclus√£o  {.smaller background=\"#b0aeae\"}\n\n**Pesquisa quantitativa tem a parte _quanti (m√©todos, modelos, etc.)_...**\n\n**... Mas talvez a parte mais importante seja o desenho da pesquisa (design emp√≠rico)!**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Preocupa√ß√µes recentes em pesquisa   {.smaller background=\"#b0aeae\"}\n\n**P-Hacking**\n\n![](figs/slides4-phacking.png) \n\nArtigo original [aqui](https://doi.org/10.1111/jofi.12530).\n\n\n\n\n\n\n\n\n\n\n## Preocupa√ß√µes recentes em pesquisa  {.smaller background=\"#b0aeae\"}\n\n**Publication bias**\n\n![](figs/slides4-Harvey-2017.png) \n\n\nArtigo original [aqui](https://doi.org/10.1111/jofi.12530).\n\n\n\n\n\n\n\n \n\n## Preocupa√ß√µes recentes em pesquisa   {.smaller background=\"#b0aeae\"}\n\n**Crise de replica√ß√£o**\n\n\n![](figs/slides4-aguinis.png) \n\n\nArtigo original [aqui](https://link.springer.com/article/10.1057/s41267-017-0081-0).\n\n\n\n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n![](figs/selection bias.png) \n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n![](figs/fig1.jpg) \n\n\n\n\n\n## Some fun stuff  {.smaller background=\"#b0aeae\"}\n\n\n![](figs/hypothesis2.png) \n\n\n\n\n\n\n## Some fun stuff {.smaller background=\"#b0aeae\"}\n\n\n![](figs/confounding variables.png) \n\n\n\n\n\n\n\n\n\n## Some fun stuff {.smaller background=\"#b0aeae\"}\n\n![](figs/proxy variable.png) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Conterfactuals {.smaller background=\"#b3eafc\"}\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n-   Imagine that John and Mary are moving to the north of Canada.\n\n-   John has a history of respiratory disease and decide to buy insurance.\n\n-   Mary does not have a history of respiratory disease and decide not to buy insurance.\n\n-   What is the causal effect of buying insurance?\n\n| Default                     | John   |   Mary |\n|-----------------------------|:-------|-------:|\n| State of insurance          | 1      |      0 |\n| Situation without insurance | `n.o.` |      5 |\n| Situation with insurance    | 4      | `n.o.` |\n| Observed                    | 4      |      5 |\n| Effect                      | ?      |      ? |\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n\n\n\n\n\n\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n**Na√Øve calculation: comparing John com Mary**\n\n$$Y_{john} - Y_{Mary} = 4 - 5 = -1$$\n\nConclusion: buying insurance has a negative effect on health.\n\n. . .\n\n**This is wrong!**\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n## Conterfactuals {.smaller background=\"#b3eafc\"}\n\n| Default                     | John | Mary |\n|-----------------------------|:-----|-----:|\n| State of insurance          | 1    |    0 |\n| Situation without insurance | `3`  |    5 |\n| Situation with insurance    | 4    |  `5` |\n| Observed                    | 4    |    5 |\n| Effect                      | ?    |    ? |\n\n$$(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5$$\n\n**Conclusion:** buying insurance has a positive effect of 1 in John's health and average effect of 0.5 in the sample's health (i.e. averages conditional on insurance status).\n\n[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Regressions {.smaller background=\"#dfe3f7\"}\n\n## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n**Let's see how a regression could solve the problem.** Imagine that you have the following data on students' application. (**Decisions in bold**)\n\n| Student | Private   | Private   | Private   | Public    | Public    | Public    | Earnings |\n|---------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n|         | Ivy       | Leafy     | Smart     | State     | Tall      | Altered   | 110,000  |\n| 1       |           | Reject    | **Admit** |           | Admit     |           | 110,000  |\n| 2       |           | Reject    | **Admit** |           | Admit     |           | 100,000  |\n| 3       |           | Reject    | Admit     |           | **Admit** |           | 110,000  |\n| 4       | **Admit** |           | Admit     |           | Admit     | Admit     | 60,000   |\n| 5       | Admit     |           | Admit     |           | Admit     | **Admit** | 30,000   |\n| 6       |           | **Admit** |           |           |           |           | 115,000  |\n| 7       |           | **Admit** |           |           |           |           | 75,000   |\n| 8       | Reject    |           |           | **Admit** | Admit     |           | 90,000   |\n| 9       | Reject    |           |           | Admit     | **Admit** |           | 60,000   |\n\n\n\n\n\n\n\n\n## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n**We can see from the table that:**\n\n-   Some students earn high salary, in both situations\n\n-   Some students earn low salary, in both situations\n\n-   There are clusters of students that applied for the same universities\n\n    -   How likely are they to be similar? Can we benefit from the fact they believe they are similar?\n\n. . .\n\n-   If we compare earnings from the first three individuals:\n\n    -   ((110 + 100)/ 2 - 11000) = -5.000\n\n-   If we compare earnings from individuals 4 and 5:\n\n    -   (60 - 30) = 30.000\n\n-   The average is:\n\n    -   25.000/2 = 12.500\n\n\n\n\n\n\n\n\n\n\n\n## Regression [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\nLet's create a dataframe to run regressions with the previous student's data.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Create the data frame\ndata <- data.frame(\n  id = 1:9,\n  earnings = c(110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000),\n  school = c(\"private\", \"private\", \"public\", \"private\", \"public\", \"private\", \"private\", \"public\", \"public\"),\n  private = c(1, 1, 0, 1, 0, 1, 1, 0, 0),\n  group = c(1, 1, 1, 2, 2, 3, 3, 4, 4)\n)\nprint(data)\n\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n\nimport pandas as pd\ndata = pd.DataFrame({\n    'id': range(1, 10),\n    'earnings': [110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000],\n    'school': [\"private\", \"private\", \"public\", \"private\", \"public\", \"private\", \"private\", \"public\", \"public\"],\n    'private': [1, 1, 0, 1, 0, 1, 1, 0, 0],\n    'group': [1, 1, 1, 2, 2, 3, 3, 4, 4]\n})\nprint(data)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\ninput id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\nlist\n```\n:::\n\n\n\n\n\n\n\n\n## \"Naive\" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon$$ **What is the benefit of private education here?**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Create the data frame\nmodel <- lm(earnings ~ private, data = data)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\nimport statsmodels.api as sm\nX = sm.add_constant(data['private'])  \ny = data['earnings']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\n\nreg earnings private \n```\n:::\n\n\n\n\n\n\n\n\n## \"Naive\" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon$$ **What is the benefit of private education here?**\n\nThe coefficient of `private` is 19500, meaning that those that have private education earn 19500 more.\n\n. . . \n\nThe problem with this design is that 1) we are including all students, even those that do not bring any \"information\", and 2) we are not controlling for the differences in students' profiles. \n\n\nLet's fix the first problem first. \n\n**What students should we not include in the model?**\n\n\n\n\n\n## Students id\\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon \\;,\\; if\\; i <=5$$ **What is the benefit of private education here?**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nmodel2 <- lm(earnings ~ private , data = subset(data,id<=5))\nsummary(model2)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\n\nsubset_data = data[data['id'] <= 5]\nX = sm.add_constant(subset_data['private']) \ny = subset_data['earnings']\nmodel2 = sm.OLS(y, X).fit()\nprint(model2.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\nreg earnings private if id<=5\n```\n:::\n\n\n\n\n\n## Students id\\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\epsilon \\;,\\; if\\; i <=5$$ **What is the benefit of private education here?**\n\nStudents 6 and 7 only applied to Private, while students 8 and 9 did not really had a choice. So we should exclude them.\n\n. . .\n\nThe benefit of private is now 20000.\n\nThe coefficient did not change much, but the design improved partially.\n\n. . .\n\nWe still have an uncontrolled \"heterogeneity\" in the groups of students. **Students 1 to 3 seem to earn more no matter their decisions**.\n\n\n\n\n\n\n\n## Apples-to-Apples [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background=\"#dfe3f7\"}\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group+ \\epsilon \\;,\\; if\\; i <=5$$ **This is the best we can do.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\ndata$dummy <- ifelse(data$group == 1, 1, 0)\ndata$dummy[data$group == 2] <- 0\nmodel3 <- lm(earnings ~ private + dummy, data = subset(data,id<=5))\nsummary(model3)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\n#pip install numpy scikit-learn statsmodels\n\ndata['dummy'] = 1\ndata.loc[data['group'] == 2, 'dummy'] = 0\nsubset_data = data[data['id'] <= 5]\nX = sm.add_constant(subset_data[['private', 'dummy']])\ny = subset_data['earnings']\nmodel3 = sm.OLS(y, X).fit()\nprint(model3.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\ngen \tdummy = 1 if group == 1\nreplace dummy = 0 if group == 2\nreg earnings private dummy if id<=5 \n```\n:::\n\n\n\n\n## Regression {.smaller background=\"#dfe3f7\"}\n\nThe previous regression assumes that students 1 to 3 are different that students 4 and 5. \n\nWe will find many instances like that in empirical research. E.g., industry. \n\n. . .\n\nThe private school coefficient, in this case 10,000, implies a private-public earnings differential of this value.\n\n. . .\n\n::: callout-important\nThe Y above is used in monetary values.\n\nUsing a logged y, ln(Y) or ln(earnings), allows estimates to be interpreted as a percent change.\n\nFor instance if $\\beta=0.05$, it means that the earnings differential is 5% for those studying in private schools (conditional on the controls included in the model). \n:::\n\n\n\n\n\n\n\n\n\n\n\n# OVB again {.smaller background=\"#f5caae\"}\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n\n\nRegression is a way to make other things equal (ceteris paribus), but equality  is generated only for variables included in the model as controls on the right-hand sided of the model.\n\nFailure to include enough controls of the right controls still leave us with selection bias.\n\nThe regression version of the selection bias generated by the inadequate controls is called **Omitted Variable Bias (OVB)**. \n\nThe inclusion of a control that should not be included is called \"**Bad Controls**\" problem.\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**How could we calculate the OVB in this example?**\n\n\n$$earnings_i = 70.000 + 20.000\\times Private_i  \\epsilon $$\n\n$$earnings_i = 40.000 + 10.000 \\times Private_i + 60.000 \\times Group+ \\epsilon$$ \n\n\n- $\\beta$ (1st regression) - $\\beta$ (second regression).\n- The OVB here is 20.000 - 10.000 = 10.000.\n- Meaning that the $\\beta$ (1st regression) is 10.000 higher than what it should be.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**How could we calculate the OVB in this example?**\n\n\nWe could calculate the bias by estimating:\n\n$$Private=\\alpha + \\beta_{omitted} \\times Group + \\epsilon$$\n\nThen,\n\n$$\\beta_{omitted} \\times \\beta_{missing} = 0.1667 * 60.000 = 10.000$$\n\nThe OVB is 10.000, meaning that the first model (the one with the omitted variable) estimates a Beta that is 10.000 higher than it should be. \n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nmodel4 <- lm(private ~ dummy , data = subset(data,id<=5))\nsummary(model4)\nmatrix2<- summary(model4)$coefficients\nsum(0.1667 * 60000 )\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nsubset_data = data[data['id'] <= 5]\nmodel4 = sm.OLS(subset_data['private'], sm.add_constant(subset_data[['dummy']])).fit()\nprint(model4.summary())\nbias = 0.1667 * 60000\nprint(bias)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nquiet input id earnings str7 school private group\n1 110000 \"private\" 1 1\n2 100000 \"private\" 1 1\n3 110000 \"public\" 0 1\n4 60000 \"private\" 1 2\n5 30000 \"public\" 0 2\n6 115000 \"private\" 1 3\n7 75000 \"private\" 1 3\n8 90000 \"public\" 0 4\n9 60000 \"public\" 0 4\nend\ngen \tdummy = 1 if group == 1\nreplace dummy = 0 if group == 2\nreg private dummy if id<=5\ndi .1666667 *  60000 \n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**So what?**\n\n- Anticipating the effect of the omitted variable on the non-omitted variable can tell you the sign of the bias.\n\n- Then you can know if the bias is attenuating or increasing the effect you are investigating.\n\n- If attenuating, the problem is smaller than if it is increasing\n\n\n\n\n\n\n\n\n\n\n\n\n## OVB again {.smaller background=\"#f5caae\"}\n\n**Regressions**\n\n-   The previous examples show that we can run **regressions and find correlations** ...\n\n-   ... And we can run regressions and find **causal effects**.\n\n-   But we need to control for all relevant variables, otherwise we have the *OVB problem*.\n\n-   Should you not look careful to your data, you'd miss the inclusion of the variable `group`.\n\n-   The results show that you may estimate a spurious coefficient twice the size of the \"true\" coefficient.\n\n\n\n\n\n\n\n# Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\n\n## Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\n**Bad controls** are variables that are **also outcome of the treatment** being studied.\n\nA **Bad control** could very well be a **dependent variable** of the treatment as well. \n\n**Good controls** are variables that **you can think as being fixed** at the time of the treatment. \n\n. . .\n\nLet's return to the model.\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group+ \\epsilon \\;,\\; if\\; i <=5$$ \n\n\nAssuming you also have the occupation of the students at the time of earnings. Should you include `occupation` in the model?\n\n\n$$earnings_i = \\alpha + \\beta_1 Private_i + \\beta_2 Group + \\beta_3 Occupation + \\epsilon \\;,\\; if\\; i <=5$$ \n\nReasoning: \"*We should use occupation as control because it would be wise to look at the effect of education on earnings only for those within an occupation*\".\n\nWhat is the problem with this reasoning?\n\n\n\n\n\n\n\n\n## Bad Controls Problem {.smaller background=\"#dff2c7\"}\n\nThe problem is that studying in private would increase the chances of getting a white-collar occupation, i.e., *private education (treatment) affects the occupation (bad control)*.\n\nIn this case, should you include occupation as control, the coefficient of interest no longer has a causal interpretation.\n\n\n. . .\n\n**This is a very common problem in empirical research**.\n\nIt is not hard to come up with stories of why a control is a bad control.\n\n\n\n\n\n\n# Randomization {.smaller background=\"#ff9c6b\"}\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Now I want to discuss the idea of randomization**\n\nSuppose you have developed a treatment (e.g., a program) that you believe will increase the 'motivation' of employees of a factory.\n\nYou have 100 employees to use in an experiment to test your claim that the treatment will increase motivation.\n\n. . .\n\n- You randomly allocate 50 employees to receive the treatment. The other 50 are part of the control group.\n\n. . .\n\n- You treat all employees in the same manner, except for the treatment.\n\n\n\n. . .\n\nUsing the data available, this is the **difference in motivation between the treatment and control groups (next slide):**\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(dplyr)\ndata  <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\n# Box plot control vs treatment groups\nggplot(data, aes(y=motivation, fill=group)) +   \n  geom_boxplot()+\n  theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n        axis.text.x = element_blank(),\n        legend.title = element_blank(),\n        legend.key.size = unit(3, \"cm\"))\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read data from Excel file\ndata = pd.read_excel(\"files/part_3_data.xlsx\")\n\n# Create a box plot of control vs treatment groups using seaborn\nplt.figure(figsize=(7, 5))\nsns.set(style='whitegrid')\nsns.boxplot(x='group', y='motivation', data=data, palette='Set2')\nplt.title(\"Box Plot of Control vs Treatment Groups\", fontsize=18)\nplt.xlabel(\"Group\", fontsize=14)\nplt.ylabel(\"Motivation\", fontsize=14)\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\n\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\ngraph box motivation , over(group) box(1, color(black)) \tytitle(\"Motivation\")  \n\nquietly graph export \"files/graph3_5.svg\", replace\n```       \n\n![](files/graph3_5.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\nThe calculated means are below. And they are statistically different.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\ndata  <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\ntapply(data$motivation, data$group, summary)\nt.test(motivation ~ group, data = data)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\ndata = pd.read_excel(\"files/part_3_data.xlsx\")\ngroup_summary = data.groupby('group')['motivation'].describe()\nprint(group_summary)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\nbys group  : sum motivation\nestpost ttest motivation , by(group)\n```\n:::\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Is there evidence that the program has increased motivation?**\n\n. . .\n\n- well, if you randomly split a group of 100 people into two groups of 50, you certainly wouldn't get the same mean motivation in both groups even if you treated them exactly alike. \n\n- Maybe the difference that we see is just such a difference?\n\n**How can we test this hypothesis?**\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Solution**: \n\n- Suppose the treatment had no effect, and the employees developed their motivation  independently of the treatment. \n\n- What is the chance that the 50 employees randomly assigned to the treatment group would have an average at least 1.47 (22.27 - 20.80)  points higher than the average motivation of the employees randomly assigned to the control group?\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n**Steps**\n\n1) Randomly split the 100 employees that we observed in this experiment into two groups of 50.\n\n2) Note the difference in the mean motivation  between the two groups.\n\n3) Repeat 1 and 2 a total of 10,000 times.\n\n4) Note the proportion of times the difference is at least 1.47 (22.27 - 20.80).\n\n\n\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary libraries\ndata <- read_excel(\"files/part_3_data.xlsx\", range = \"A1:C101\")\ncomb <- 10000\ndf <- data.frame(matrix(ncol = 2, nrow = comb))\ncolnames(df) <- c(\"order\" ,\"diff\")\n# Create the loop for randomization:\nfor (i in seq(from = 1, to = comb)) {\n  set.seed(i)                               \n  data$temp <- runif(100, min = 0, max = 1)  # Creating 100 random numbers 0 to 1\n  data <- data[order(data$temp),]            # Sorting data by the random numbers generated in the previous row\n  data$rank <- rank(data$temp)               # Ranking by the random numbers\n# The row below defines the treatment group based on the random numbers generated. This is where we guarantee randomization\ndata$status_rank <- case_when(data$rank <= 50 ~ \"Control_rand\", data$rank > 50 ~ \"Treated_rand\")\n# Calculate the new means of the new groups. Need to transpose data.\nmeans <- t(as.data.frame(tapply(data$motivation, data$status_rank, mean)))\n# Moving the new means to df. Each row is the difference of means\ndf[i, 1] <- i\ndf[i, 2] <- means[1, 2] - means[1, 1]\nrm(means) # Deleting value\ndata = subset(data, select = -c(temp, rank, status_rank)) # Deleting variables\n}\n# Calculate a suitable binwidth for the histogram\nbinwidth <- (max(df$diff) - min(df$diff)) / sqrt(length(df$diff))\n# Create a histogram of the differences with the calculated binwidth\nggplot(df, aes(x = diff)) +\n  geom_histogram(binwidth = binwidth, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Differences\", x = \"Difference\", y = \"Frequency\")\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nimport excel \"files/part_3_data.xlsx\", cellrange(A1:C101) firstrow clear\nset seed 472195 \t\t\nsort group\t\t \nset obs 10000 \t\t\t\t \negen fin_order = seq() \nsort fin_order \t\t\t\t \nsummarize \t\t\t\t\t\ngen av_diff=.\n\nlocal i = 1\nwhile `i'<=10000 {\n\n\tsort fin_order\n\tgen rand_num`i' = uniform() if !missing(motivation)\n\tegen ordering`i' = rank(rand_num`i')\n\tsort ordering`i'\n\n\tgen group`i' = \"\"\n\treplace group`i' = \"T\" if ordering <= 50\n\treplace group`i' = \"C\" if ordering > 50 & ordering<=100\n\t\n\tqui summ motivation if group`i'==\"T\"\n\tscalar avT = `r(mean)'\n\tqui summ motivation if group`i'==\"C\"\n\tscalar avC = `r(mean)'\n\t\n\tsort fin_order\n\treplace av_diff = avT-avC in `i'\n\t\n\tdrop rand_num`i' ordering`i' group`i'\n\tlocal i = `i' + 1\n}\nhistogram av_diff, frequency kdensity  \ngraph export \"files/graph3_6.png\" , replace\n\n```       \n\n![](files/graph3_6.png){ width=800px height=450px }\n:::\n\n\n\n\n\n\n## Randomization {.smaller background=\"#ff9c6b\"}\n\nThe mean difference was as far from 0 as 1.5 for only a few out of the 10,000 random divisions of the data into two groups of 50.\n\n- Thus, **the difference between the mean motivation would almost always be less than the observed difference of 1.47 (22.27 - 20.80) if the treatment had no effect.**\n\n- It seems reasonable to believe that the treatment caused the difference in motivation.\n\n\n\n\n\n\n\n\n\n# Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\nThe measurement error problem has a similar statistical structure to the omitted variable bias (OVB).\n\n- \"Classical\" random measurement error for the $y$ will inflate standard errors but will not lead to biased coefficients. \n\n    - $y^{*} = y + \\sigma_{1}$\n    - If you estimante $y^{*} = f(x)$, you have $y + \\sigma_{1} = x + \\epsilon$ \n    - $y = x + u$ \n        - where $u = \\epsilon - \\sigma_{1}$ \n\n\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\n- \"Classical‚Äù random measurement error in x‚Äôs will bias coefficient estimates toward zero.\n\n- $x^*=x+\\sigma_2$\n\n- Imagine that $x^*$ is a bunch of noise. It would not explain anything. Thus, your results are biased toward zero.\n\n\n\n\n\n## Measurement Error problem  {.smaller background=\"#f2e9b6\"}\n\nA example using one of the Wooldridge's datasets.\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) \nlibrary(jtools)\ndata <- read.dta(\"files/CEOSAL1.dta\")\nset.seed(2)\ndata$salary_noise <- data$salary + runif(length((data$salary)), min=-100, max= 100)\ndata$roe_noise <- data$roe + runif(length((data$roe)), min=-100, max= 100)\n# OLS model \nmodel1 <- lm(data$salary ~ data$roe)\nmodel2 <- lm(data$salary ~ data$roe_noise)\nmodel3 <- lm(data$salary_noise ~ data$roe)\n#summary(model1)\n#summary(model2)\n#summary(model3)\nexport_summs(model1, model2, model3, digits = 3 , model.names = c(\"Roe\", \"Roe (X) with noise\", \"Salary (y) with noise\") )\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.iolib.summary2 import summary_col\n\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nnp.random.seed(2)\n# Add noise to the 'salary' and 'roe' columns\ndata['salary_noise'] = data['salary'] + np.random.uniform(-100, 100, len(data))\ndata['roe_noise'] = data['roe'] + np.random.uniform(-100, 100, len(data))\n# OLS model\nmodel1 = smf.ols(formula='salary ~ roe', data=data).fit()\nmodel2 = smf.ols(formula='salary ~ roe_noise', data=data).fit()\nmodel3 = smf.ols(formula='salary_noise ~ roe', data=data).fit()\n# Create a summary table for all regressions\nresults = summary_col([model1, model2, model3], \n                      model_names=['Reg 1', 'Reg 2', 'Reg 3'],\n                      stars=True,\n                      float_format='%0.2f')\n# Print the summary table\nprint(results)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.dta\", clear\nset seed 2\ngen salary_noise = salary + runiform() * 200 - 100\ngen roe_noise = roe + runiform() * 200 - 100\neststo: qui reg salary roe\neststo: qui reg salary roe_noise\neststo: qui reg salary_noise roe\nesttab\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# More about Regressions {.smaller background=\"#454343\"}\n\n## Regression {.smaller background=\"#454343\"}\n\nLinear regressions are the workhorse tool in econometrics\n\n-   **Simplicity**: straightforward to understand, implement, and visualize.\n\n. . .\n\n-   **Interpretability**: coefficients have clear interpretations.\n    -   represents the change in the Y for a one-unit change in the X, holding all other variables constant.\n\n. . .\n\n-   **Versatility**: simple linear regression or *multiple linear regression*.\n\n. . .\n\n-   **Assumptions**: linearity, independence of errors, homoscedasticity, and normality of errors.\n\n. . .\n\n-   **Baseline Model**: You can compare the performance of more advanced models to linear regression.\n\n. . .\n\n-   **Estimation**: provides clear estimates of the coefficients' confidence intervals and hypothesis testing.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nIn this setting, the variables $y$ and $x$ can have several names.\n\n| Y                  | X                    |\n|--------------------|----------------------|\n| Dependent variable | Independent variable |\n| Explained variable | Explanatory variable |\n| Response variable  | Control variable     |\n| Predicted variable | Predictor variable   |\n| Regressand         | Regressor            |\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nBroadly, we are interested in how y is explained by x?\n\n-   $y_i = \\alpha + \\beta_1 x_i + \\epsilon$\n\n. . .\n\nPerhaps $\\epsilon$ is the most important part of a regression.\n\nThe interpretation is \"*everything that is not explained by X and that explains Y*\".\n\n. . .\n\nA comment\n\n-   Usually, the literature uses $\\epsilon$ for the \"estimated\" residual.\n\n-   And $\\mu$ for the \"true\" residual, which necessarily implies that the assumptions hold.\n\n-   At the end od the day, you don't need to worry to much with the notation of this term because we are always in the \"estimated world\", and almost never in the \"true world\".\n\n-   The \"true world\" implies that you are studying the population or that you have a true random sample of the population\n\n    -   $y_i = \\alpha + \\beta_1 x_i + \\mu$\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Remember**\n\n- $y, x$, and $\\mu$ are random variables\n- $y and x$ are observable\n- $\\mu$ and $\\beta$ are unobservable\n- $\\mu$ captures everything that determines y after accounting for x \n\nOur goal is to estimate Œ≤\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nThere are some assumptions/requirements about $\\mu$ in a OLS\n\n**First assumption**\n\n-   E($\\mu$) = 0\n\n    -   This is a simple assumption, not strong at all.\n    -   It simply assumes that the average of $\\mu$ is zero in the population.\n    -   Basically, any non-zero mean is absorbed by the intercept\n        -   Say that E($\\mu$) = k\n        -   We could rewrite $\\mu = k + w$, where E(w)=0\n        -   Then, model becomes $y=(\\alpha +ùëò) + \\betaùë•+ùë§$\n        -   Intercept is now just (Œ± + k), and error, w, is mean zero\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Second assumption**\n\n-   E($\\mu$\\|x) = E($\\mu$) for all values of x\n    -   It says that the average value of $\\mu$ does not depend on the value of x (i.e., the slice of the population you are looking at).\n    -   We say that $\\mu$ is mean-independent of x.\n    -   This is true if the X and the $\\mu$ are independent to each other.\n    -   Implies that x and $\\mu$ are *uncorrelated*.\n    -   **Conditional Mean Independence (CMI)**.\n    -   This is one of the keys assumption to *causal inference*.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Second assumption**\n\n**Example**\n\nLet's say the model is:\n\n$$wage = \\alpha + \\beta Schooling_{years} + \\epsilon$$\n\n-   where $\\epsilon$ represents *unobserved ability*.\n\nDoes CMI hold?\n\nThat is E(ability\\|x=8)=E(ability\\|x=10)=E(ability\\|x=12)?\n\n. . .\n\n**Probably not**, because the unobserved ability should depend on the years of schooling.\n\nThe solution (not trivial) would be to include ability as a new X.\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Another example**\n\nConsider the following model (with only one X)\n\n$$Leverage_i = \\alpha + \\beta_1 Profitability_i + \\mu_i$$\n\n-   CMI says that, to every firm *i*, $\\mu$ is the same, even when firms have different profitability.\n\n-   Can you think on examples when this assumption may not hold in this model?\n\n. . .\n\n1)  unprofitable firms have higher bankruptcy risk, which should make them to have lower leverage (tradeoff theory).\n\n2)  unprofitable firms have low cash, which should make them to have more leverage (pecking order theory).\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**The discussion of whether the CMI holds is the origin of the \"endogeneity\" problem.**\n\nYou will face reviewers arguing reasons of why the CMI might not hold in your case.\n\n- Many  will criticize a model by saying it has an ‚Äúendogeneity problem‚Äù, whithout explaining more.\n\n  - This is very generic. **Don't do that!**\n\n. . .\n\nThey should explain what is the source of the problem that is making the model violate CMI.\n\n - OVB, selection bias, reverse causality, simultaneity, etc?\n\n. . . \n\nGenerally speaking, endogeneity refers to a violation of CMI, meaning that $x$ and $\\mu$ are correlated.\n\nThis is always a plausible possibility, since $\\mu$ carries a lot of stuff (something must be correlated with X).\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\n**Third assumption**\n\nCombining 1 and 2 leads to\n\n-   E($\\mu$\\|x) = 0\n    -   This is a very important assumption called **zero conditional mean assumption**.\n\n## Ordinary Least Squares {.smaller background=\"#454343\"}\n\nOur focus is to find estimates for $\\alpha$ and $\\beta$. Should we have access to the population, it would be easy. We could write:\n\n$$y_i= \\alpha + \\beta_1x_i + \\mu$$\n\n. . .\n\nBut remember that,\n\n$$E(u) = 0$$ $$E(u|x) = 0$$\n\nThe second bullet implies that the correlation between x and $\\mu$ is zero (we can write that as E(x,u) = 0).\n\n. . .\n\n::: callout-important\nRemember: $\\alpha$ and $\\beta$ are parameters to be estimated (i.e., constants), while $X$ and $Y$ are variables\n:::\n\n\n\n\n\n\n\n\n## Regression {.smaller background=\"#454343\"}\n\nSo we can write that (in the **population**)\n\n$E(y - \\alpha - \\beta_1x ) = 0$\n\n$(x[y - \\alpha - \\beta_1x ]) = 0$\n\n. . .\n\nSo we can write that (in the **sample**)\n\n$\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ) = 0$ , We will use this to find $\\alpha$:\n\n$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ]) = 0$ , We will use this to find $\\beta$:\n\n\n\n\n\n\n\n## Finding $\\alpha$ {.smaller background=\"#454343\"}\n\nFrom before:\n\n$$\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ) =0$$\n\n. . .\n\nPassing the sum operator through\n\n$$\\frac{1}{n}\\sum_{i=1}^n(y_i) - \\frac{1}{n}\\sum_{i=1}^n(\\hat{\\alpha})  - \\frac{1}{n} \\sum_{i=1}^n(\\hat{\\beta_1} x_i )=0$$\n\n. . .\n\nCoefficients are constants, so we can get rid of the sum operator.\n\n$$\\frac{1}{n}\\sum_{i=1}^n(y_i) - \\hat{\\alpha}  - \\hat{\\beta_1} \\frac{1}{n}  \\sum_{i=1}^n(\\ x_i )=0$$\n\n\n\n\n\n\n\n\n## Finding $\\alpha$ {.smaller background=\"#454343\"}\n\n-   We know that $\\frac{1}{n}\\sum_{i=1}^n(y_i)$ is $\\bar{y_i}$ (the mean)\n\n$$\\bar{y_i} - \\hat{\\alpha}  - \\hat{\\beta_1}  \\bar{x_i}=0$$\n\n. . .\n\nSo we write:\n\n$$\\hat{\\alpha}  = \\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}$$\n\n. . .\n\n**Easy Peasy** üòÄ\n\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\nFrom before:\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i ]) = 0$$\n\n. . .\n\nBut now we have:\n\n$$\\hat{\\alpha}  = \\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}$$\n\n. . .\n\nThus,\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - (\\bar{y_i} -  \\hat{\\beta_1}   \\bar{x_i}) - \\hat{\\beta_1} x_i ]) = 0$$\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\nTurning into\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\bar{y_i} ])  -  \\frac{1}{n} \\sum_{i=1}^n (x_i [\\hat{\\beta_1} x_i - \\hat{\\beta_1} \\bar{x_i} ]) = 0$$\n\n. . .\n\nOr\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i [y_i - \\bar{y_i} ])  =  \\hat{\\beta_1} \\frac{1}{n} \\sum_{i=1}^n (x_i [ x_i  - \\bar{x_i} ]) $$\n\n. . . \n\nLast step (I am skipping some steps here)\n\n$$\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x} )(y_i - \\bar{y_i} )  =  \\hat{\\beta_1} \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x_i} )^2 $$\n\n\n\n\n## Finding $\\beta$ {.smaller background=\"#454343\"}\n\n\nIf the variance of x is not zero, we can write $\\beta$ as\n\n$$\\hat{\\beta_1} = \\frac{\\sum_i^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_i^n (x_i - \\bar{x})^2} = \\frac{Covariance(x_i,y_i)}{Variance(x_i)}$$\n\n\n\n## Finding $\\mu$  {.smaller background=\"#454343\"}\n\nNow that we have $\\hat{Y_i}=\\hat{\\alpha} + \\hat{\\beta_1} X_i$, we can estimate the residual $\\mu$\n\n$$\\hat{\\mu} = Y_i - \\hat{Y_i}$$\n\n\nWhich is the same as:\n\n$$\\hat{\\mu} = Y_i - \\hat{\\alpha} - \\hat{\\beta_1}x_i$$\n\nMost residuals will not be 0, meaning they do not lie on the best fitting line. \n\n\n\n\n\n\n## Finding $\\mu$  {.smaller background=\"#454343\"}\n\nThe job of an OLS model is find the parameters to minimize the squared error (i.e., to find the best fitting line).\n\n$$\\sum_{i=1}^n \\hat{\\mu}^2 = \\sum_{i=1}^n(Y_i - \\hat{Y_i})^2$$\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nAnother example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \nsummary(reg_tb)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nnp.random.seed(1)\n\nobs = 10000\ndata = pd.DataFrame({\n    'x': np.random.normal(size=obs),\n    'u': np.random.normal(size=obs),\n})\ndata['y'] = 5.5 * data['x'] + 12 * data['u']\n\nX = sm.add_constant(data['x'])\nmodel = sm.OLS(data['y'], X).fit()\n\nprint(model.summary())\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nreg y x \n```\n:::\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nAnother example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb %>% \n  lm(y ~ x, .) %>% \n  ggplot(aes(x=x, y=y)) + \n  ggtitle(\"OLS Regression Line\") +\n  geom_point(size = 0.05, color = \"black\", alpha = 0.5) +\n  geom_smooth(method = lm, color = \"black\") +\n  annotate(\"text\", x = -1.5, y = 30, color = \"red\", \n           label = paste(\"Intercept = \", reg_tb$coefficients[1])) +\n  annotate(\"text\", x = 1.5, y = -30, color = \"blue\", \n           label = paste(\"Slope =\", reg_tb$coefficients[2]))\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a scatterplot with the OLS regression line using Seaborn\nsns.set(style='whitegrid')\nplt.figure(figsize=(7, 5))\nsns.scatterplot(x='x', y='y', data=data, color='black', alpha=0.5, s=5)\nsns.regplot(x='x', y='y', data=data, color='black', scatter=False, line_kws={'color':'black'})\nplt.title('OLS Regression Line')\nplt.annotate(f'Intercept = {model.params[0]:.2f}', xy=(-1.5, 30), color='red')\nplt.annotate(f'Slope = {model.params[1]:.2f}', xy=(1.5, -30), color='blue')\nplt.show()\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nreg y x \npredict yhat1 \ngen yhat2 = -0.0750109  + 5.598296*x \npredict uhat1, residual \ngen uhat2=y-yhat2 \nqui sum uhat* \ntwoway (lfit y x, lcolor(black) lwidth(medium)) (scatter y x, mcolor(black) msize(tiny) msymbol(point)), title(OLS Regression Line) \nqui graph export \"files/graph3.svg\", replace\n```  \n\n![](files/graph3.svg) \n\n:::\n\n\n\n\n\n\n## Regression ([Source](https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares)) {.smaller background=\"#454343\"}\n\nUsing the previous regressions, we can show  that:\n\n1)  $\\hat{y_i} = \\hat{\\alpha} + \\hat{\\beta_1} x_i$\n\n2)  $\\hat{\\mu_i} = y_i - \\hat{y_i}$\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \n\ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\nsummary(tb[-1:-3])\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\n\nprint(tb[['yhat1','yhat2', 'uhat1','uhat2']].describe())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nclear \nqui set obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict uhat1, residual \npredict yhat1 \ngen yhat2 = -0.0750109  + 5.598296*x \ngen uhat2=y-yhat2 \nsum yhat*  uhat* \n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nWe can easily show that (remember from before) \n\n$$\\sum_i^n(y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i) = 0$$\n\nAnd that \n\n$$\\sum_i^n \\hat{\\mu}  = 0$$\n\nThe graphs next slide shows a spherical figure, suggesting that the residual is not correlated with the the fitted values ($\\hat{y_i}$)\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\ntb %>% \n  lm(uhat1 ~ yhat1 , .) %>% \n  ggplot(aes(x=yhat1, y=uhat1)) + \n  geom_point(size = 0.1, color = \"black\") +\n  geom_smooth(method = lm, color = \"black\")\n```\n\n\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\nmodel = sm.OLS(tb['uhat1'], sm.add_constant(tb['yhat1'])).fit()\n# Create a scatter plot with a regression line\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(7, 4.5))\nsns.scatterplot(x='yhat1', y='uhat1', data=tb, size=0.05, color='black', alpha=0.5)\nsns.regplot(x='yhat1', y='uhat1', data=tb, scatter=False, color='black')\nplt.xlabel('yhat1')\nplt.ylabel('uhat1')\nplt.title('Scatter Plot of uhat1 vs. yhat1')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict yhat1 \npredict uhat1, residual \ntwoway (lfit uhat1 yhat1 , lcolor(black) lwidth(large)) (scatter uhat1 yhat1 , mcolor(black)  msymbol(point))\nqui graph export \"files/graph4.svg\", replace\n```  \n\n![](files/graph4.svg) \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nSimilarly, we can easily show that \n\n$$\\sum_i^nx_i(y_i - \\hat{\\alpha} - \\hat{\\beta_1} x_i) = 0$$\n \nAnd that\n \n$$\\sum_i^nx_i\\hat{\\mu}  = 0$$\n\n \nMeaning that the sample covariance between the X and the residual will be always zero.\n\n\n\n\n\n\n\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(tidyverse)\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u # notice that I am defining the beta1 here. The 5.5 is the \"true\" beta we want to estimate.\n) \nreg_tb <- lm(y ~ x, data=tb) \ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = reg_tb$coefficients[1] + reg_tb$coefficients[2]*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\ntb %>% \n  lm(uhat1 ~ x , .) %>% \n  ggplot(aes(x=x, y=uhat1)) + \n  geom_point(size = 0.1, color = \"black\") +\n  geom_smooth(method = lm, color = \"black\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nnp.random.seed(1)\nobs = 10000\nx = np.random.normal(size=obs)\nu = np.random.normal(size=obs)\ny = 5.5 * x + 12 * u\n\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\n\ntb = pd.DataFrame({'x': x, 'u': u, 'y': y})\ntb['yhat1'] = model.predict(X)\ntb['uhat1'] = y - tb['yhat1']\ntb['yhat2'] = model.params[0] + model.params[1] * x\ntb['uhat2'] = y - tb['yhat2']\nmodel = sm.OLS(tb['uhat1'], sm.add_constant(tb['yhat1'])).fit()\n# Create a scatter plot with a regression line\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(7, 4.5))\nsns.scatterplot(x='x', y='uhat1', data=tb, size=0.05, color='black', alpha=0.5)\nsns.regplot(x='x', y='uhat1', data=tb, scatter=False, color='black')\nplt.xlabel('x')\nplt.ylabel('uhat1')\nplt.title('Scatter Plot of uhat1 vs. x')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nset seed 1 \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nqui reg y x \npredict yhat1 \npredict uhat1, residual \ntwoway (lfit uhat1 x , lcolor(black) lwidth(large)) (scatter uhat1 x , mcolor(black) msymbol(point))\nqui graph export \"files/graph5.svg\", replace\n```  \n\n![](files/graph5.svg) \n\n:::\n\n\n## Properties of OLS {.smaller background=\"#bfc4d9\"}\n\nLet's say you estimate a model and find the $\\hat{\\mu}$.\n\nIf you calculate the correlation between the X and $\\hat{\\mu}$, you will find zero.\n\n**This is by construction!** It is not an evidence that CMI is nos violated.\n\nIn fact, the OLS \"assumes\" and \"forces\" zero correlation.\n\n**It is intuitive: if you are \"forcing\" zero correlation when the correlation is not in fact zero, your coefficients will be biased.**\n\nThe previous graphs actually show zero correlation. But that is expected and does not suggest the model is not violating CMI.\n\n**At the end of the day, CMI is untestable and unverifiable**.\n\n\n\n\n\n\n\n\n\n# Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n**Understanding what SSR, SSE and SST mean** \n\n- SSE = Sum of Squares Explained = $\\sum_i^n(\\hat{y_i}-\\bar{y})^2$\n- SSR = Sum of Squares Residuals = $\\sum_i^n\\hat{\\mu}^2$\n- SST = Sum of Squares Total = SSE + SSR = $\\sum_i^n(y_i-\\hat{y_i})^2$ \n\n\nR-squared is simply the ratio of portion explained over the total that could be explained.\n\n\n$$R^2 = \\frac{SSE}{SST} = 1-\\frac{SSR}{SST}$$\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n![](figs/R2.jpg)\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\nYou can think this way:\n\n1) If X does not explain Y, then the best predictor of Y is $\\bar{y}$. In that case, your model does not explain anything of Y, thus $R^2$ is zero, and $\\hat{y_i}=\\bar{y}$\n\n. . .\n\n2) If X partially explains Y, then $\\hat{y_i} \\neq \\bar{y}$, meaning that $\\hat{y_i}$ has some inclination (like the figure next slide). This means that $SSE>0$ and your $R^2>0$ but $R^2<1$\n\n. . .\n\n3) Whatever is not explained by $\\hat{y_i}$ is left to $\\sum_i^2\\hat{\\mu}^2$, meaning that SSR will be non-zero.\n\n. . .\n\n4) The ratio of the portion that you can explain by  $\\hat{y_i}$ over the total that is to be explained  $y_i-\\hat{y_i}$ if the $R^2$.\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# Statistics of salary \nmean(salary)\n# OLS model\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nprint(data['salary'].mean())\n# OLS model\nX = data['roe']\nX = sm.add_constant(X)\ny = data['salary']\n\nmodel = sm.OLS(y, X).fit()  # Fit the linear regression model\nsalaryhat = model.fittedvalues  # Predicted values for the dependent variable\nuhat = model.resid  # Predict regression residuals\nsalarymean = pd.Series([y.mean()] * len(y))  # Generating the mean of salary\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nsum salary \nreg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\nmydata <- read.dta(\"files/CEOSAL1.dta\")\nattach(mydata)\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \n# r-squared is simply the ratio of portion explained over total that could be explained - Understanding what SSR, SSE and SST mean \nplot(salary ~ roe)\nabline(lm(salary ~ roe), col = \"blue\")\nabline(lm(salarymean ~ roe), col = \"red\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data[['roe']]\ny = data['salary']\nsalarymean = np.repeat(y.mean(), len(y))\nX_mean = X.mean()\ny_mean = y.mean()\nslope = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\nintercept = y_mean - slope * X_mean\nsalaryhat = slope * X + intercept\n# Plotting the data and regression lines\nplt.scatter(X, y,  alpha=0.7)\nplt.plot(X, salaryhat,  color='blue', linewidth=2)\nplt.plot(X, salarymean, color='red',  linewidth=2)\nplt.xlabel('roe')\nplt.ylabel('salary')\nplt.show()\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: false\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nsum salary , d\nreg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\n\ntwoway (scatter salary roe) (lfit salary roe) (lfit salarymean roe) \nqui graph export \"files/graph4_6.svg\", replace\n```  \n\n![](files/graph4_6.svg) \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Goodness-of-fit {.smaller background=\"#dff2c7\"}\n\nManually calculating $R^2$\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\nmydata <- read.dta(\"files/CEOSAL1.dta\")\nattach(mydata)\nmodel <- lm(salary ~ roe)\nsalaryhat <- fitted(model)                      # Predict values for dependent variable\nuhat <- resid(model)                            # Predict regression residuals\nsalarymean <- rep(mean(salary),length(salary))  # Generating the mean of salary \n\n# r-squared is simply the ratio of portion explained over total that could be explained\nssr  <- sum(uhat^2)\nssrB <- sum((salary    - salaryhat)^2)\nsst  <- sum((salary    - salarymean)^2)\nsse  <- sum((salaryhat - salarymean)^2)\nsse / sst\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data['roe']\ny = data['salary']\nX = sm.add_constant(X)  # Add a constant term (intercept)\nmodel = sm.OLS(y, X).fit()\nsalaryhat = model.fittedvalues\nuhat = model.resid\nsalarymean = np.repeat(y.mean(), len(y))\n# Calculate R-squared\nssr = np.sum(uhat**2)\nssrB = np.sum((y - salaryhat)**2)\nsst = np.sum((y - salarymean)**2)\nsse = np.sum((salaryhat - salarymean)**2)\nrsquared = sse / sst\nprint(rsquared)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \npredict salaryhat , xb\t\t\t\t\npredict uhat, resid\t\t\t\t\t\negen salarymean = mean(salary)\t\t\negen sst  = total((salary    - salarymean)^2)  \negen ssr  = total((salary    - salaryhat)^2)\negen ssrB = total(uhat^2)\t\t\t\t\t\negen sse  = total((salaryhat - salarymean)^2)\t\ndi sse / sst\n```  \n\n:::\n\n\n\n\n\n\n\n# Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nWhen we estimate coefficients we have some \"error of estimation\".\n\n- Basically, you are searching the \"true\" coefficient using a sample, which should be representative of the population but it is not the population itself.\n\n- This means that the coefficient estimated is estimated with error.\n\n- We would like (e.g., we will need) to impose some \"structure\" to that error.\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Standard error and T-stat**\n\nTo assess if the variables are significantly related, you need to assess the significance of $\\beta$ coefficients.\n\nUsing the example from Wooldridge, we know that the Beta of ROE is `18.591`, while the standard error of ROE is `11.123`.\n\n. . .\n\n- The standard error is a measure of the accuracy of your estimate. If you find a large standard error, your estimate does not have good accuracy. \n\n- Ideally, you would find small standard errors, meaning that your coefficient is accurately estimated. \n\n- However, you do not have good control over the magnitude of the standard errors. \n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Standard error and T-stat**\n\nIf you have a large standard error, probably you coefficient will not be significantly different from zero. You can test whether your coefficient is significantly different from zero computing the t-statistics as follows:\n\n$$t_{\\beta} = \\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$$\n\nIf $t_{\\beta}$ is large enough, you can say that $\\beta$ is significantly different from zero. Usually, $t_{\\beta}$ larger than 2 is enough to be significant. \n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nIn the previous example, you can find the t-stat manually as follows ($t_{\\beta} =\\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$):\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# OLS model\nmodel <- lm(salary ~ roe)\nsummary(model)$coefficients[2,1] / summary(model)$coefficients[2,2] \nsummary(model)$coefficients[2,3]\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\n# OLS model\nX = data['roe']\nX = sm.add_constant(X)\ny = data['salary']\nmodel = sm.OLS(y, X).fit()  \n# Extract and calculate specific coefficients\ncoef_beta = model.params['roe']\ncoef_std_error = model.bse['roe']\n# Calculate t-value\nt_value = coef_beta / coef_std_error\n# Print the coefficient and t-value\nprint(\"Coefficient (beta):\", coef_beta)\nprint(\"Standard Error:\", coef_std_error)\nprint(\"t-value:\", t_value)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \nlocal beta = _b[roe]\nlocal std_error = _se[roe]\nlocal t_value = `beta' / `std_error'\ndisplay \"Coefficient (beta): \" `beta'\ndisplay \"Standard Error: \" `std_error'\ndisplay \"t-value: \" `t_value'\n```  \n\n:::\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\nNaturally, the previous analysis requires an estimate of $\\beta$ and an estimate of the $\\beta$'s standard error.\n\n\nThe standard error can be defined as:\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n- Where $\\hat{\\sigma}$ is the standard deviation of the error term in the regression, which can be calculated as:\n\n$$\\hat{\\sigma} = \\sqrt{\\frac{SSR}{n-2}}$$\n\n    - The $n-2$ here is an adjustment for the degrees of freedom in the regression.\n\n- SST is defined as before $\\sum_i^n(y_i-\\hat{y_i})^2$ \n\n\n\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign) # importing dataset from a stata dta file\ndata <- read.dta(\"files/CEOSAL1.dta\")\nattach(data)\n# OLS model\nmodel <- lm(salary ~ roe)\n# Extract the standard error of the coefficient for 'roe'\nsummary(model)$coefficients[\"roe\", \"Std. Error\"]\n\n#calculating manually\n# Extract the residuals\nresiduals <- resid(model)\n# Number of observations (n)\nn <- length(residuals)\n# Calculate the mean of the independent variable (roe)\nroe_mean <- mean(roe)\n# Calculate the sum of squared deviations of roe from its mean (SXX)\nSST <- sum((roe - roe_mean)^2)\n# Calculate the sum of squared errors (SSE)\nSSR <- sum(residuals^2)\n# Calculate the standard error of beta\nSd_beta <- sqrt(SSR / ((n - 2)))\n# Calculate S.E\nSe_beta <- Sd_beta / sqrt(SST)\n# Print the standard error of beta\nprint(Se_beta)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/CEOSAL1.dta\")\nX = data['roe']\ny = data['salary']\nX = sm.add_constant(X)  \nmodel = sm.OLS(y, X).fit()\n# Extract the standard error of the coefficient for 'roe'\nbeta_se_summary = model.bse['roe']\nprint(\"Standard Error (from summary):\", beta_se_summary)\n# Calculate it manually\n# Extract the residuals\nresiduals = model.resid\n# Number of observations (n)\nn = len(residuals)\n# Calculate the mean of the independent variable (roe)\nroe_mean = X['roe'].mean()\n# Calculate the sum of squared deviations of roe from its mean (SST)\nSST = np.sum((X['roe'] - roe_mean) ** 2)\n# Calculate the sum of squared errors (SSE)\nSSE = np.sum(residuals ** 2)\n# Calculate the standard error of beta (Sd_beta)\nSd_beta = np.sqrt(SSE / (n - 2))\n# Calculate SE_beta\nSE_beta = Sd_beta / np.sqrt(SST)\nprint(\"Standard Error (manually calculated):\", SE_beta)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\nqui reg salary roe \ngen beta_se_summary = _se[roe]\ngen n = _N\npredict residuals, residuals\nsum roe, meanonly\ngen roe_diff = roe - r(mean)\negen roe_diff_sq = total(roe_diff^2)\ngen residuals_sq = residuals^2\negen residuals_sq_sum = total(residuals_sq)\ngen Sd_beta = sqrt(residuals_sq_sum / (n - 2))\ngen SE_beta = Sd_beta / sqrt(roe_diff_sq)\ndisplay \"Standard Error (from summary): \" sum(beta_se_summary)\ndisplay \"Standard Error (manually calculated): \" sum(SE_beta)\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n## Variance of coefficients {.smaller background=\"#c4f5d7\"}\n\n**Another comment:**\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n1) The larger $\\hat{\\sigma}$ is, the larger the variance of $\\beta$. That is, the more \"noise\" in the association between x and Y, the harder it is to learn something about $\\beta$.\n\n2) However, more variation in x, the larger the SST, so the smaller is the variance of $\\beta$.\n\n\n\n\n\n\n\n\n\n# Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\nLooking at both equations below:\n\n$$t_{\\beta} = \\frac{\\hat{\\beta}}{se(\\hat{\\beta})}$$\n\n\n$$se(\\hat{\\beta_1})=\\frac{\\hat{\\sigma}}{\\sqrt{SST_x}}$$\n\n\n**What happens if $\\hat{\\sigma}$ is not constant (for the values of x)?**\n\n**In other words, how realistic is to assume that the variance in the errors is the same for all slices of x?**\n\n**Can you think of an example where that may happen?**\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Earnings = f(education)**\n\nPhD have a higher variance of earnings than non-educated people.\n\n. . .\n\n**Leveragge=f(Size)**\n\nIt is quite possible that small firms will have less options of leverage than large companies. \n\nThis means that a sub-sample of large companies will have higher variance in the leverage decisions (and thus the error terms) than the sub-sample of small firms\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\nOne of the key assumptions in OLS estimators is homoscedasticity \n\nThat is, the assumption is that the variance of the errors is homoscedastic (constant variance in all slices of X). \n\nIt means that throughout all observations, the error term shows the **same variance**. \n\nIf errors are not homoscedastic, we have the heteroscedasticity problem.\n\n\n. . . \n\nHeteroskedasticity **does not cause bias or inconsistency in the OLS estimators** of the $\\beta$ like the OVB would. \n\nIt also does not affect the $R^2$. \n\n**What Heteroscedasticity does is to bias the standard errors of the estimates.**\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n![](files/homoscedasticity.png)\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\n\n![](files/heteroscedasticity.png)\n\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Homoskedascticity** = Constant $\\hat{\\sigma}$ to all slices of X.\n\n**Heteroskedascticity** = Non-constant $\\hat{\\sigma}$ to all slices of X.\n\n**Without homoskedascticity, OLS no longer has the minimum mean squared errors**, which means that the *estimated standard errors are biased*, which in turn creates bias in the t-stat and the inference you'll make with your model.\n \n\n. . . \n\nFortunately, we have an easy solution for that.\n\n\n$$Var(\\hat{\\beta_1}) = \\frac{\\sum_i^n(x_i-\\bar{x})^2\\hat{\\mu}^2}{SST^2_x}$$\n\nThis formula simply \"includes\" the heteroskedascticity in the calculation of $Var(\\hat{\\beta_1})$, meaning this correct the estimated standard deviation to heteroskedascticity.\n\nWe call this correction as **Robust Standard Errors** (White Robust).\n\n. . .\n\nIn other words, you should always use Robust Standard Errors. It is easy to use it with R.\n\n\n\n\n\n\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n**Using Robust Standard-errors.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(sandwich)\nlibrary(foreign) \nlibrary(lmtest)\n\ndata <- read.dta(\"files/CEOSAL1.DTA\")\nmodel <- lm(salary ~ roe, data = data)\nrobust_model <- coeftest(model, vcov = vcovHC(model, type = \"HC3\"))\nSE_beta_robust <- robust_model[\"roe\", \"Std. Error\"]\ncat(\"Robust Standard Error :\", SE_beta_robust, \"\\n\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\ndata = pd.read_stata(\"files/CEOSAL1.DTA\")\nmodel = smf.ols(\"salary ~ roe\", data=data)\nresults = model.fit(cov_type='HC3')  \nSE_beta_robust = results.bse['roe']\nprint(\"Robust Standard Error :\", SE_beta_robust)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\n\nqui reg salary roe \ngen beta_se_non = _se[roe]\n\nqui reg salary roe , robust\ngen beta_se_summary = _se[roe]\n\ndi \"Standard Error (non-robust): \" sum(beta_se_non)\ndi \"Standard Error (robust): \" sum(beta_se_summary)\n```  \n\n:::\n\n\n\n\n##  Robust standard errors {.smaller background=\"#e0cafc\"}\n\n\nNotice that the standard errors have changed quite significantly  in this example. \n\nUsually, the robust standard errors are larger than the traditional ones in empirical works.\n\n**But, in this example, they are smaller.**\n\n. . . \n\nPerhaps more importantly:\n\n**Once the S.e. change, you should expect that the t-stat of the estimates also change.**\n\n\n. . . \n\n\n**Final comment**: robust standard errors are robust in the case of homoskedasticity.\n\n::: {.callout-warning}\nThus, you should always use robust S.E.\n:::\n\n\n\n\n\n\n\n\n\n# Clustered standard errors {.smaller background=\"#edc5d1\"}\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nAlmost always, someone will ask you whether you clustered your standard errors.\n\n**The intuition is the following:**\n\n- When you do not cluster, you are assuming that all observations are independently and identically distributed (i.i.d.), which may or may not be true.\n\n- Imagine you are studying the effect of class size on students achievement.\n\n- How much of a effect would **have the teacher of a class**? \n\n. . . \n\n- In this design, the teacher influences the achievement of all the students in the same class, and one teacher cannot be at two classes at the same time.\n\n- Thus, it would be wise to cluster the errors at the class-level. This assumes that the residual of each individual is clustered with the other individuals in the same class.\n\n\n. . .\n\nIn principle, clustering solves any form of dependence of the residuals in your data.\n\n\n\n\n\n\n\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nIn corporate finance/accounting research panel data research, the tradition is to cluster at the **firm-level**.\n\n- The reason is that the observations of the same firm are not independent trough time, thus are correlated. \n\nBut, there is a lot of debate about this decision. \n\n. . .\n\nThe tip is to cluster where the **randomness exist**. That is quite subjective. In the class size example, the **randomness** comes out of the teacher, since each teacher has their own ways of teaching (materials, resources, etc.).\n\n. . .\n \nBut, it is a good practice to stress this decision a bit in your own research by **also showing results with clustered s.e. at the industry-level**.\n\n. . .\n\n**Final tip**: usually the minimum number of cluster is about 30. Less than that might be insufficient (but, again, the guidance in this topic is very subjective).  \n\n\n\n \n\n\n## Clustered standard errors {.smaller background=\"#edc5d1\"}\n\nThe clustered standard errors are different because I am fabricating the clusters here for the sake of the coding.\n\nIn your real research, you would have the cluster at hands. \n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(sandwich)\nlibrary(foreign) \nlibrary(lmtest)\nlibrary(plm)\n\ndata <- read.dta(\"files/CEOSAL1.DTA\")\nmodel <- lm(salary ~ roe, data = data)\nrobust_model <- coeftest(model, vcov = vcovHC(model, type = \"HC3\"))\n#clustered\ndata$cluster <- rep(1:35, length.out = nrow(data))\nmodel <- plm(salary ~ roe, data = data, index = c(\"cluster\"))\n\nclustered_se <- vcovHC(model, type = \"HC3\", cluster = \"group\")\nSE_beta_clustered <- sqrt(clustered_se[\"roe\", \"roe\"])\n\ncat(\"Standard Error (robust):\", SE_beta_robust, \"\\n\")\ncat(\"Standard Error (clustered)::\", SE_beta_clustered, \"\\n\")\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Read the dataset\ndata = pd.read_stata(\"files/CEOSAL1.DTA\")\n\n# Create a new variable 'cluster' with cluster numbers ranging from 1 to 35\ndata['cluster'] = list(range(1, 36)) * (len(data) // 35)\n\n# Fit the linear regression model\nmodel = sm.OLS(data['salary'], sm.add_constant(data['roe'])).fit()\n\n# Compute robust standard errors\nrobust_model = model.get_robustcov_results(cov_type='HC3')\nSE_beta_robust = robust_model.cov_params().loc['roe', 'roe'] ** 0.5\n\n# Fit the linear regression model with clustered standard errors\nmodel_clustered = sm.OLS(data['salary'], sm.add_constant(data['roe'])).fit(cov_type='cluster', cov_kwds={'groups': data['cluster']})\n\n# Extract the clustered standard errors for 'roe'\nclustered_se = model_clustered.HC3_se.loc['roe']\n\nprint(\"Robust Standard Error (HC3):\", SE_beta_robust)\nprint(\"Clustered Standard Error (HC3):\", clustered_se)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CEOSAL1.DTA\" , replace\n\nqui reg salary roe \ngen beta_se_non = _se[roe]\n\nqui reg salary roe , robust\ngen beta_se_summary = _se[roe]\n\negen cluster = seq(), block(6)\nqui regress salary roe , vce(cluster cluster)\ngen SE_beta_clustered = _se[roe]\n\ndi \"Standard Error (non-robust): \" sum(beta_se_non)\ndi \"Standard Error (robust): \" sum(beta_se_summary)\ndi \"Standard Error (clustered): \" sum(SE_beta_clustered)\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Panel Data {.smaller background=\"#dff5ce\"}\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nAs explained previously, OVB is a significant source of \"endogeneity\" in empirical research.\n\nOVB is a problem because of the considerable heterogeneity in many empirical settings. \n\n**Many of the omitted variables are unobservable to the researcher.**\n\nPanel data can sometimes offer a partial.\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nWe start defining the following:\n\n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\epsilon_{i,t}$$\n\nWhere: \n\n  - $i = 1, . . . , N$\n  - $t = 1, . . . , T$\n\n. . . \n\n\nImagine that the residual can be decomposed in: \n\n$$\\epsilon_{i,t} = c_i + \\mu_{i,t}$$\n\nThe term $c_i$ is constant.\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nThe term $c_i$ is constant.\n\n**It captures the aggregate effect of all of the unobservable, time-invariant explanatory variables for $y_{it}$.**\n\nTo focus attention on the issues specific to panel data, we assume that $e_{it}$ has a zero mean conditional on $x_{it}$ and $c_i$ for all $t$.\n\n. . .\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n\n**Why?**\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n\n\n- If $x_{it}$ and $c_i$ are correlated, then $c_i$  is referred to as a ‚Äúfixed effect‚Äù.\n  \n  - It there is correlation, there is violation of the *Conditional Mean Independence* (CMI) assumption.\n\n    \n- If $x_{it}$ and $c_i$ are not correlated, then $c_i$  is referred to as a ‚Äúrandom effect‚Äù.\n\n  - Endogeneity is not a concern; however, the computation of standard errors is affected.\n\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**Why might fixed effects arise?**\n\nFE are any time-invariant unit characteristic that cannot be observed in the data.\n\n- education level,\n- firm's culture,\n- technology,\n- managerial talent,\n- investment opportunities,\n- location (economic development, institutions, etc.),\n- etc.\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**We say things like (you have to understand that they refer to FE):** \n\n- \"*Time-invariant heterogeneity at the unit-level*\"\n- \"*Unobserved variation that occur at the unit-level that do not vary over time*\"\n\n**Important**: with FE, you are capturing **all** unobserved heterogeneity that do not vary over time.\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nDefinition of *Panel Data*:\n\nYou have multiple observations per unit (individual, firm, etc.)\n\nIn datasets, it is \"one panel below the other\" not \"one panel beside the other\".\n\n. . . \n\n\n**Four main topics in Panel Data:**\n\n1) Pooled cross-sectional\n\n2) Fixed Effect models (including multidimensional FE)\n\n3) Random Effects model\n\n4) First differences\n\n5) Lagged models\n\n\n\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\nFormal definition\n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\delta FE +  \\epsilon_{i,t}$$\n\n- $E(\\epsilon_{i,t}) = 0$\n\n- $corr(x_{i,t},FE) \\neq 0$\n\n- $corr(FE, \\epsilon_{i,t}) = 0$\n\n- $corr(x_{i,t},epsilon_{i,t}) = 0$, for all t\n\nThe last assumption is called *strict exogeneity assumption* and means that the residual of any t is uncorrelated with x of any t.\n\n*That is, under a strict exogeneity assumption on the explanatory variables, the fixed effects estimator is unbiased: the idiosyncratic error should be uncorrelated with each explanatory variable across all time periods.*\n\n\n. . .\n\n**Remember that if we ignore FE, we have OVB.**\n\n\n\n\n\n## Panel Data {.smaller background=\"#dff5ce\"}\n\n**Before we continue...**\n\n**Comment #1**\n\n*The standard errors in this framework must be ‚Äúclustered‚Äù by panel unit (e.g., individual) to allow for correlation in the residual for the same person over time. This yields valid inference as long as the number of clusters is ‚Äúlarge.\"*\n\n. . . \n\n**Comment #2**\n\n*FE cannot solve reverse causality, it might help you with OVB.*\n\n. . . \n\n**Comment #3**\n\n*Three main types of FE:*\n\n- Pooled\n- Within-transformation (when someone says FE, it is usually this one)\n- Random Effects\n\n\n\n\n\n\n# Pooling Cross-sections  {.smaller background=\"#e0cafc\"}\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nWhen you have two periods of the same unit, but the periods are not consecutive, you have a pooled cross-sectional data.\n\nThis is common in survey data.\n\nIf you use only one period, you might find biased results.\n\n. . .\n\nLet's practice with the dataset CRIME2 from Wooldridge. \n\nThis dataset contains data (many cities) on the crime rate, unemployment rate and many other city-related variables.\n\nThere are two years, 82 and 87 (this is pooled cross-section). \n\n\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nIf we estimate only using the year 87, we would interpret that unemployment leads to lower crime rate.\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven) \ndata <- read_dta(\"files/CRIME2.dta\")\ndata1 <- subset(data, year == 87)\nmodel <- lm(crmrte ~ unem, data = data1)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\ndata = pd.read_stata(\"files/CRIME2.dta\")\ndata1 = data[data['year'] == 87]\nmodel = sm.OLS(data1['crmrte'], sm.add_constant(data1['unem'])).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CRIME2.dta\" , clear\nreg crmrte une if year ==87\n```  \n\n:::\n\n\n\n\n\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nWhen we consider a panel, we get the expected positive sign. This is evidence that the previous model suffered from OVB. Still, the coefficient of unem is not significant probably because of time-invariant unobserved heterogeneity in the cities.\n\n::: panel-tabset\n\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven) \ndata <- read_dta(\"files/CRIME2.dta\")\nmodel <- lm(crmrte ~ d87+ unem, data = data)\nsummary(model)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\n\ndata = pd.read_stata(\"files/CRIME2.dta\")\nmodel = sm.OLS(data['crmrte'], sm.add_constant(data[['d87','unem']])).fit()\nprint(model.summary())\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/CRIME2.dta\" , clear\nreg crmrte  d87 une \n```  \n\n:::\n\n\n\n## Pooling Cross-Sections  {.smaller background=\"#e0cafc\"}\n\nThis shows us that we should also control for the year variable. \n\nWe call this, **Year Fixed Effects.**\n\nWe still most likely have OVB due to the unobserved heterogeneity in cities, that is, we still would need to include **cities FE**. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Demeaned variables  {.smaller background=\"#fccad9\"}\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\n**A first way to eliminate the FE is by demeaning the data.**\n\nConsider the following:\n\n$$\\bar{y_i} = \\alpha +\\beta \\bar{x_i} + \\delta FE + \\bar{\\epsilon_i}$$\n\n$$\\frac{1}{T}\\sum{y_{i,t}} = \\alpha +\\beta \\frac{1}{T}\\sum{x_{i,t}} + \\delta FE + \\frac{1}{T}\\sum{\\epsilon_{i,t}}$$\n\n. . .\n\nIf we subtract the mean of each variable, we have:\n\n$$(y_{i,t} - \\bar{y_i}) = \\beta (x_{i,t} - \\bar{x_i}) + (\\epsilon_{i,t} - \\bar{\\epsilon_i})$$\n\nBecause the FE does not vary over time, each value is equal to the mean.\n\nThus, when you demean, you eliminate the FE from the equation. You also eliminate the intercept $\\alpha$.\n\n. . .\n\n**Takeaway**: OLS will estimate unbiased coefficients if you demean the variables.\n\nThis is called **within-transformation** because you are demeaning \"within\" the group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\nLet's use the dataset WAGEPAN to estimate the following equation.\n\n$$Ln(wage)=\\alpha + \\beta_1 exper^2 + \\beta_2 married + \\beta_3 union + \\epsilon$$\n\n\nSome variables in the dataset do not vary over time. These variables cannot be included in this equation. \n\n\n\n\n\n\n\n## Demeaned variables  {.smaller background=\"#fccad9\"}\n\nSee page 495 Wooldridge.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign)\nlibrary(stargazer)\nlibrary(sandwich)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\n# Calculate mean by nr for lwage, expersq, married, and union\ndata <- data[order(data$nr), ]  # Sort data by nr for by-group operations\ndata$lwage_mean <- ave(data$lwage, data$nr, FUN = mean)\ndata$expersq_mean <- ave(data$expersq, data$nr, FUN = mean)\ndata$married_mean <- ave(data$married, data$nr, FUN = mean)\ndata$union_mean <- ave(data$union, data$nr, FUN = mean)\n\ndata$lwage_demean <- data$lwage - data$lwage_mean\ndata$expersq_demean <- data$expersq - data$expersq_mean\ndata$married_demean <- data$married - data$married_mean\ndata$union_demean <- data$union - data$union_mean\n\nmodel1 <- lm(lwage ~ educ + black + hisp + exper + expersq + married + union + d81 + d82 + d83 + d84 + d85 + d86 + d87, data = data)\nmodel2 <- lm(lwage_demean ~ expersq_demean + married_demean + union_demean + d81 + d82 + d83 + d84 + d85 + d86 + d87, data = data)\n\nstargazer(model1, model2 ,title = \"Regression Results\", column.labels=c(\"OLS\",\"Demean\"),  type = \"text\")\n\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.iolib.summary2 import summary_col\n\ndata = pd.read_stata(\"files/WAGEPAN.dta\")\n\ndata = data.sort_values(by='nr')  # Sort data by nr for by-group operations\ndata['lwage_mean'] = data.groupby('nr')['lwage'].transform('mean')\ndata['expersq_mean'] = data.groupby('nr')['expersq'].transform('mean')\ndata['married_mean'] = data.groupby('nr')['married'].transform('mean')\ndata['union_mean'] = data.groupby('nr')['union'].transform('mean')\n\ndata['lwage_demean'] = data['lwage'] - data['lwage_mean']\ndata['expersq_demean'] = data['expersq'] - data['expersq_mean']\ndata['married_demean'] = data['married'] - data['married_mean']\ndata['union_demean'] = data['union'] - data['union_mean']\n\nmodel1 = sm.OLS(data['lwage'], sm.add_constant(data[['educ', 'black', 'hisp', 'exper', 'expersq', 'married', 'union', 'd81', 'd82', 'd83', 'd84', 'd85', 'd86', 'd87']])).fit()\nmodel2 = sm.OLS(data['lwage_demean'], sm.add_constant(data[['expersq_demean', 'married_demean', 'union_demean', 'd81', 'd82', 'd83', 'd84', 'd85', 'd86', 'd87']])).fit()\n\n# Display regression results using stargazer\nsummary = summary_col([model1, model2], stars=True)\nprint(summary)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nbys nr:  egen lwage_mean = mean(lwage) \nbys nr:  egen expersq_mean = mean(expersq) \nbys nr:  egen married_mean = mean(married) \nbys nr:  egen union_mean = mean(union)\n\ngen lwage_demean = lwage - lwage_mean\ngen expersq_demean = expersq - expersq_mean\ngen married_demean = married - married_mean\ngen union_demean = union - union_mean\n\neststo: qui reg lwage        educ black hisp exper expersq       married        union d81 d82 d83 d84 d85 d86 d87\neststo: qui reg lwage_demean expersq_demean married_demean union_demean d81 d82 d83 d84 d85 d86 d87\nesttab , mtitles(\"OLS\" \"Demean\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n# Practical Tips  {.smaller background=\"#fce0cc\"}\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nYou will not need to demean the variables every time you want to estimate a fixed effect models.\n\nThe statistical softwares have packages that do that.\n\nYou only need to know that **Fixed effects model** is a **demeaned model**, i.e., a **within-transformation model**. \n\nBut notice that you will have many different Fixed Effects together:\n\n- Firm Fixed Effects\n- Year Fixed Effects\n- Individual Fixed Effects (if individuals change between firms)\n\n. . . \n\nI am calling a **multidimensional fixed effects design** if you expand the FE to interactions of FE. Most common:\n\n- Year-Industry Fixed Effects.\n- CEO-Firm Fixed Effects.\n\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nNotice the number of dummies in the last two columns.\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(foreign)\nlibrary(stargazer)\nlibrary(sandwich)\nlibrary(plm)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\n# Calculate mean by nr for lwage, expersq, married, and union\ndata <- data[order(data$nr), ]  # Sort data by nr for by-group operations\ndata$lwage_mean <- ave(data$lwage, data$nr, FUN = mean)\ndata$expersq_mean <- ave(data$expersq, data$nr, FUN = mean)\ndata$married_mean <- ave(data$married, data$nr, FUN = mean)\ndata$union_mean <- ave(data$union, data$nr, FUN = mean)\n\ndata$lwage_demean <- data$lwage - data$lwage_mean\ndata$expersq_demean <- data$expersq - data$expersq_mean\ndata$married_demean <- data$married - data$married_mean\ndata$union_demean <- data$union - data$union_mean\n\n# set panel data\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\n# Random effects regression using plm\nmodel_de <- lm(lwage_demean ~  expersq_demean + married_demean + union_demean +  d81 +d82+ d83+ d84+ d85 +d86 +d87 , data = data)\nmodel_fe <- plm(lwage ~  expersq + married + union + factor(year)              + educ + black + hisp + exper, data = pdata, model = \"within\")\nmodel_du <- lm( lwage ~  expersq + married + union + factor(year) + factor(nr) + educ + black + hisp + exper, data = data)\n\n# Display regression results using stargazer\n#summary(model_de)\n#summary(model_fe)\n#summary(model_du)\nstargazer(model_de, model_fe, model_du ,title = \"Regression Results\",  type = \"text\")\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nbys nr:  egen lwage_mean = mean(lwage) \nbys nr:  egen expersq_mean = mean(expersq) \nbys nr:  egen married_mean = mean(married) \nbys nr:  egen union_mean = mean(union)\n\ngen lwage_demean = lwage - lwage_mean\ngen expersq_demean = expersq - expersq_mean\ngen married_demean = married - married_mean\ngen union_demean = union - union_mean\n\nxtset nr year \neststo: qui reg lwage_demean expersq_demean married_demean union_demean i.year\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui reg lwage expersq married union i.year i.nr  educ black hisp exper \nesttab , mtitles(\"Demean\" \"FE\" \"LSDV\") compress\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nNotice that the parameter $\\delta$ does not have meaning. \n\n$$y_{i,t} = \\alpha + \\beta_1 x_{i,t} + \\delta FE +  \\epsilon_{i,t}$$\n\nIn fact, the previous slides have shown that you will find the same results of a FE model if you include the dummies for the units in the panel (i.e., dummies for the firms or individuals, etc.).\n\nThis is called **least squares dummy variable (LSDV) model**.\n\n- the SE are also identical to the within-transformation model.\n\n- But the R2 of the LSDV will be very high because you are including a lot of \"explanatory variables\".\n\n::: {.callout-note}\nAt the end of the day, you will use the package for the unit's FE (i.e., the firm), and will include the additional FE as dummies, just like a LSDV model.\n:::\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nWhen you estimate a LSDV, the software will inform an $\\alpha$. \n\nBut this coefficient **has no interpretation whatsoever.** \n\n- it will be FE for the dropped unit of FE. \n\nYou can simply ignore it, you even don't need to include in your final table. \n\nNo problem if you do, just **don't make inferences from it**.\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nA FE model helps a lot, but it only does what it can do.\n\nThat is, FE models do not capture **time-variant unobserved heterogeneity**.\n\n. . .\n\nAlso, if you have constant Xs in your model, you will have to drop them.\n\n- More technically, if there is no within-variation in a X, you cannot include it (the software will drop them).\n\n- For instance, the software will drop $year_{birth}$ below if you include CEO FE.\n\n$$Y_{i,t} = \\alpha + \\beta_1 year_{birth} + CEO \\;FE + ... + \\epsilon_{i,t}$$\n\nIf you attempt to include the CEO FE manually, the software will drop a random CEO FE or the variable $year_{birth}$. If you get a beta for $year_{birth}$ it has no meaning.\n\n\n\n\n\n\n## Practical Tips  {.smaller background=\"#fce0cc\"}\n\nAdding many FE can demand a lot of computational power.\n\nConsider the multidimensional model as follows:\n\n$$Y_{i,t} = \\alpha + \\beta_1 X_{i,t} + Firm \\;FE + Year\\; FE + Year.Industry \\;FE + CEO \\;FE + ... + \\epsilon_{i,t}$$\n\nIt would take a while to estimate in an average computer.\n\n\n\n\n\n\n\n\n# Random Effects  {.smaller background=\"#c6f7ec\"}\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\nRemember that:\n\n$$\\epsilon_{i,t} = c_i + \\mu_{i,t}$$\n\nThe most important thing here is whether $x_{it}$ and $c_i$ are correlated.\n    \n- If they are, you should estimate Fixed Effects\n\n- If $x_{it}$ and $c_i$ are not correlated, then $c_i$  is referred to as a **random effect**.\n\n  - Endogeneity is not a concern; however, the computation of standard errors is affected.\n\nBut, if the $x_{it}$ and $c_i$ are not correlated, there is **no endogeneity concern**. \n\n$c_i$ can be let as part of the $\\epsilon_{i,t}$ without bias in the estimated betas.\n\n\n\n\n\n\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\nAdditionally, the assumption that $x_{it}$ and $c_i$ are not correlated is rather strong and not practical to most applications of corporate finance, economics or public policy.\n\nRE is a model not used often. Cunningham does not even discuss it.\n\n*If the key explanatory variable is constant over time, we cannot use FE to estimate its effect on y.*\n\n*Of course, we can only use RE because we are willing to assume the unobserved effect is uncorrelated with all explanatory variables.*\n\n*Typically, if one uses RE, and as many time-constant controls as possible are included among the explanatory variables (with an FE analysis, it is not necessary to include such controls) RE is preferred to pooled OLS because RE is generally more efficient.*\n\n(Wooldridge, p.496)\n\n\n\n\n\n\n\n\n## Random Effects  {.smaller background=\"#c6f7ec\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(plm)\nlibrary(jtools)\nlibrary(foreign)\ndata <- read.dta(\"files/WAGEPAN.dta\")\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\npo_model <- lm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = data)\nfe_model <- plm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata, model = \"within\")\nre_model <- plm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata, model = \"random\")\n\nstargazer(po_model, fe_model , re_model ,title = \"Regression Results\", column.labels=c(\"OLS\",\"FE\",\"RE\"),  type = \"text\")\n\n```\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nxtset nr year \neststo: qui reg   lwage expersq married union i.year  educ black hisp exper \neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , re\n\nesttab , mtitles(\"OLS\" \"FE\" \"RE\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# FE vs. RE    {.smaller background=\"#5c97f7\" }\n\n\n## FE vs. RE    {.smaller background=\"#5c97f7\" }\n\n*The idea is that one uses the random effects estimates unless the Hausman test rejects.* \n\n*In practice, a failure to reject means either that the RE and FE estimates are sufficiently close so that it does not matter which is used, or the sampling variation is so large in the FE estimates that one cannot conclude practically significant differences are statistically significant.* (Wooldridge)\n\n\n**If the p-value of the Hausman test is significant then use FE, if not use RE.**\n\n\n\n\n\n## FE vs. RE   {.smaller background=\"#5c97f7\" }\n\n\n::: panel-tabset\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\", clear\nxtset nr year\nqui xtreg lwage expersq married union i.year educ black hisp exper, fe\nestimates store fe_model\nqui xtreg lwage expersq married union i.year educ black hisp exper, re\nestimates store re_model\nhausman fe_model re_model\n```  \n\n:::\n\n\n\n\n\n\n\n# First differences   {.smaller background=\"#e3e2b8\"}\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\nIn most applications, the main reason for collecting panel data is **to allow for the unobserved effect, $c_i$, to be correlated with the explanatory variables**. \n\nFor example, in the crime equation, we want to allow the unmeasured city factors in $c_i$ that affect the crime rate also to be correlated with the unemployment rate. \n\nIt turns out that this is simple to allow: **because $c_i$ is constant over time, we can difference the data across the two years.** \n\nMore precisely, for a cross-sectional observation $i$, write the two years as:\n\n\n$$y_{i,1} = \\beta_0 + \\beta_1 x_{i,1} + c_i + \\mu_{i,1}, t=1$$ \n\n$$y_{i,2} = (\\beta_0 + \\delta_0) + \\beta_1 x_{i,2} + c_i + \\mu_{i,2}, t=2$$ \n\nIf we subtract the second equation from the first, we obtain\n\n$$(y_{i,2} - y_{i,1}) = \\delta_0 + \\beta_1 (x_{i,2} - x_{i,1}) + (\\mu_{i,2}-\\mu_{i,1})$$ \n\n\n$$\\Delta y_{i} = \\delta_0 + \\beta_1 \\Delta x_{i} + \\Delta \\mu_{i}$$ \n\n\n\n\n\n\n\n\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\n**So, rather than subtracting the group mean of each variable, you  subtract the lagged observation.**\n\nNot hard to see that, when t=2, FE and FD will give identical solutions\n\n. . .\n\n- FE is more efficient if disturbances $\\mu_{i,t}$ have low serial correlation\n\n- FD is more efficient if disturbance $\\mu_{i,t}$ follow a random walk\n\nAt the end of the day, you can estimate both. \n\nEmpirical research usually estimate FD only in specific circumstances, when they are interested in how changes of X affect changes of Y.\n\nThings like stationarity or trends are often not concerns in panel data\n\n- where N is 10 to 20 \n\n\n\n\n\n\n## First differences   {.smaller background=\"#e3e2b8\"}\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\n# Load necessary libraries\nlibrary(plm)\nlibrary(lmtest)\nlibrary(stargazer)\n\ndata <- read.dta(\"files/WAGEPAN.dta\")\npdata <- pdata.frame(data, index = c(\"nr\", \"year\"))\n\nols_model <- lm(lwage ~ expersq + married + union + factor(year) + educ + black + hisp + exper, data = pdata)\nfe_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"within\")\nre_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"random\")\nfd_model <- plm(lwage ~ expersq + married + union + educ + black + hisp + exper, data = pdata, model = \"fd\")\n\nstargazer(ols_model, fe_model ,re_model, fd_model,title = \"Regression Results\",   type = \"text\")\n\n```\n\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse \"files/WAGEPAN.dta\" , clear\n\nxtset nr year \neststo: qui reg   lwage expersq married union i.year  educ black hisp exper \neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , fe\neststo: qui xtreg lwage expersq married union i.year  educ black hisp exper , re\neststo: qui reg D.lwage D.expersq D.married D.union i.year  D.educ D.black D.hisp D.exper \n\nesttab , mtitles(\"OLS\" \"FE\" \"RE\" \"FD\") compress\n\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n# Lagged independent variables   {.smaller background=\"#e3bfc3\"}\n\n## Lagged independent variables   {.smaller background=\"#e3bfc3\"}\n\nWhen you have a panel data and are concerned with simultaneity between Y and X, you can endeavor in lagging the Xs.\n\n\n$$y_{i,t} = \\beta_0 + \\beta_1 x_{i,t-1} + c_i + \\mu_{i,t}$$ \n\nAs a matter of fact, this is often expected in finance research. \n\n. . . \n\nThere is a limitation, however.\n\nThe usual proxy of corporate finance research is highly autocorrelated. \n \n - e.g., total assets do not vary much throughout  time. \n \nThus, lagging the X often does not make much of a difference. \n \n::: {.callout-tip}\nAlways do it. Otherwise, you will have to explain why you didn't do it.\n:::\n\n\n\n\n\n\n\n# Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\n## Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\nSometimes you may have something like\n\n$$y_{i,t} = \\beta_0 + \\beta_1 y_{i,t-1}+ \\beta_2 x_{i,t} + c_i + \\mu_{i,t}$$ \n\nThis is called a **Dynamic Panel Model**. It includes $y_{i,t-1}$ as X.\n\n. . .\n\nConsider a FE model.\n\n$$y_{i,t} - \\bar{y_i} = \\beta_0 + \\gamma_1 (y_{i,t-1} - \\bar{y}_{i,t-1}) + \\omega_2 (x_{i,t-1} - \\bar{x_i} )   + (FE_i - \\bar{FE}_i)  + (\\mu_{i,t} - \\bar{\\mu}_i )$$ \n\nThe within transformation removes the time-invariant unobserved heterogeneity from the model. \n\nHowever, it introduces a correlation between the transformed lag $(y_{i,t‚àí1}‚àí\\bar{y}_{i,t-1})$ and the transformed error $(\\mu_{i,t‚àí1}‚àí\\bar{\\mu}_{i,t-1})$ because the average error ($\\bar{\\mu} = \\sum_{i=1}^{T} \\mu_{i,t}$) includes $\\mu_{i,t-1}$, which is also \"included\" in $y_{i,t‚àí1}$ \n\n- $y_{i,t-1} = \\beta_0 + \\beta_1 y_{i,t-2}+ \\beta_2 x_{i,t-1} + c_i + \\mu_{i,t-1}$ \n\n\n\n\n\n\n\n\n## Lagged dependent variables   {.smaller background=\"#d6cbf5\"}\n\nThe bias declines with panel length because $\\epsilon_{i,t‚àí1}$ becomes a smaller component of the average error term as T increases. \n\nIn other words, with higher T the correlation between the lagged dependent variable and the regression errors becomes smaller.\n\n**[Flannery and Hankins (2013)](https://doi.org/10.1016/j.jcorpfin.2012.09.004)** have a good review with applications in corporate finance.\n\nThey conclude that FE is biased when estimating these models.\n\nThey suggest to estimate **Sys-GMM** or **Least Squares Dummy Variable Correction**. We do not discuss these models in the course.\n\n\n\n\n\n\n\n\n\n\n# Selection Bias {.smaller background=\"#e3e2b8\"}\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nBack to the selection bias example of before.\n\n-   Imagine that John and Mary are moving to the north of Canada.\n\n-   John has a history of respiratory disease and decide to buy insurance.\n\n-   Mary does not have a history of respiratory disease and decide not to buy insurance.\n\n\n\n| Default                     | John | Mary |\n|-----------------------------|:-----|-----:|\n| State of insurance          | 1    |    0 |\n| Situation without insurance | `3`  |    5 |\n| Situation with insurance    | 4    |  `5` |\n| Observed                    | 4    |    5 |\n| Effect                      | ?    |    ? |\n\n$$(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5$$\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nRearranging the terms:\n\n\n$$(Y_{1,john} - Y_{0,Mary})   + (Y_{1,Mary}  - Y_{0,john})  = (4 - 5) + (5 - 3)  = 0.5$$\n$$We\\;see   + We\\;do\\;not\\;see  = (4 - 5) + (5 - 3)  = 0.5$$\n\nThe term $(Y_{1,Mary}  - Y_{0,john}) =  (5 - 3) = 2$ is the **selection bias**.\n\nIt exists because we are comparing two people that should not be compared.\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nSome notation:\n\n$d=1$ for the treated units (treatment group)\n\n$d=0$ for the treated units (control group)\n\n\n. . . \n\n\n$Y_{i}$ = Potential outcome of individual *i*.\n\n$Y_{i,1}$ or  $Y(1)$ = Potential outcome of individual *i*, treatement group.\n\n$Y_{i,0}$ or  $Y(0)$ = Potential outcome of individual *i*, control group.\n\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nSome notation:\n\nThese are the representations of the **causal effect** we often want to estimate.\n\n**Average Treatment Effect:**\n\nATE = $\\frac{1}{N} (E[Y_{i,1}] - E[Y_{i,0}])$\n\n. . . \n\n**Average Treatment Effect on the treated:**\n\nATET = $\\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])$\n\n. . . \n\n**Average Treatment Effect on the untreated:**\n\nATEU = $\\frac{1}{N} (E[Y_{i,1}|D_i=0] - E[Y_{i,0}|D_i=0])$\n\n. . . \n\nOf course, again, we cannot observe both potential outcomes of the same unit *i*.\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nWhen dealing with **causal inference**, we have to find ways to approximate what the hidden potential outcome of the treated units is. \n\nThat is, the challenge in identifying causal effects is that the untreated potential outcomes, $Y_{i,0}$, are never\nobserved for the treated group ($D_i= 1$). The \"second\" term in the following equation:\n\nATET = $\\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])$\n\n\nWe need an empirical design to **\"observe\"** what we do not really observe (i.e., the counterfactual). \n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nMany options:\n\n- Matching/Balancing\n- Difference-in-differences (DiD)\n- Instrumental variables\n- Regression discontinuity design (RDD)\n- Synthetic control (Synth)\n\n\n\n\n\n\n\n\n## Selection Bias {.smaller background=\"#e3e2b8\"}\n\nThe process of finding units that are comparable is called **matching**.\n\n. . .\n\n**Before we continue...**\n\n**We will match on observables. We cannot be on unobservables.**\n\nThus, you may want to write in your article \"selection bias due to observables\".\n\n. . .\n\n**Cunningham:**\n\n*Propensity score matching has not seen as wide adoption among economists as in other nonexperimental methods like regression discontinuity or difference-in-differences. The most common reason given for this is that economists are oftentimes skeptical that CIA can be achieved in any dataset almost as an article of faith. This is because for many applications, economists as a group are usually more concerned about selection on unobservables than they are selection on observables, and as such, they reach for matching methods less often.*\n\nCIA = CMI\n\n\n\n\n\n\n\n\n# Matching  {.smaller background=\"#e0cafc\"}\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n**Matching** aims to compare the outcomes between observations that have the same values of all control variables, except that one unit is treated and the other is not. \n\n. . .\n\nIn this literature, the control variables used to matched are often called **covariates**.\n\nThat is, for each treated unit, the researcher finds an untreated unit that is similar in all covariates.\n\nThe implication is that the researcher can argue that \"*units are comparable after matching*\". \n\n\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\nThe easiest to see is **exact matching**: *it matches observations that have the exact same values*. \n\n- It might be doable if you have only one covariate. \n\n- Naturally, if you have only one covariate, you might still be left with some selection bias.\n\n  - In the previous example, health history is one important covariate that makes John and Mary different. \n  \n  - But what about life style? Nutrition? Etc. \n  \n\nAs the number of covariates grow, you cannot pursue exact matching. That is the job of PSM.\n\n\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n**In exact matching, the causal effect estimator (ATET) is:**\n\n$$ATET = \\frac{1}{N} \\sum (E[Y_{i}] - E[Y_{j(i)}] | D_i=1)$$\n\nWhere $Y_{j(i)}$ is the j-th unit matched to the i-th unit based on the j-th being ‚Äúclosest to‚Äù the i-th unit for some  covariate. \n\nFor instance, let‚Äôs say that a unit in the treatment group has a covariate with a value of 2 and we find another unit in the control group (exactly one unit) with a covariate value of 2. \n\nThen we will impute the treatment unit‚Äôs missing counterfactual with the matched unit‚Äôs, and take a difference.\n\n\n\n\n\n\n\n## Matching {.smaller background=\"#e0cafc\"}\n\nConsider the following dataset from Cunningham:\n\n![](figs/scott.png)\n\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\n::: panel-tabset\n### R Averages\n\nAverage ages are very different. The salary of a 24 yrs old person is quite different than the salary of a 32 yrs person.\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\nsummary(training_example$age_treat)\nsummary(training_example$age_control)\n```\n\n\n### R Treated\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_treat)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n### R Control\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_control)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n\n### R Matched\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\nlibrary(kableExtra)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://github.com/scunning1975/mixtape/raw/master/\",df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% slice(1:20)\n\nggplot(training_example, aes(x=age_matched)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\n```\n\n\n:::\n\n\n\n\n## Matching   {.smaller background=\"#e0cafc\"}\n\nIn this example, you are literally finding the units in the control group that have the same age as the units in the treatment group.\n\nYou are exact matching 1-by-1 in this example.\n\nYou have only one covariate, i.e., age.\n\n\n\n\n\n\n\n\n\n\n\n# Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\nThe last example was simple because you could *exact match*.\n\nIf you cannot find one exact match, you need an approximate match. \n\n. . .\n\nIn order to do that, you have to use distance matching.\n\n**Distance matching** minimizes the distance (i.e., how far the covariates are from each other) between the treatment and control groups.\n\n\n\n\n\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Euclidean distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'(X_i-X_j)}=\\sqrt{\\sum_{n=1}^k(X_{n,i}-X_{n,j})^2}$\n\n![](figs/euclidian.png)\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Normalized Euclidean distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'\\hat{V}^{-1}(X_i-X_j)}=\\sqrt{\\sum_{n=1}^k\\frac{(X_{n,i}-X_{n,j})}{\\sigma^2_n}}$\n\nThe problem with this measure of distance is that the distance measure itself depends on the **scale of the variables themselves**. \n\nFor this reason, researchers typically will use some modification of the Euclidean distance, such as the **normalized Euclidean distance**, or they‚Äôll use a wholly different alternative distance. \n\nThe normalized Euclidean distance is a commonly used distance, and what makes it different is that the distance of each variable is scaled by the variable‚Äôs variance. \n\n\n \n \n \n \n \n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\n**Mahalanobis  distance** = $|X_i-X_j|=\\sqrt{(X_i-X_j)'\\hat{\\sum_x}^{-1}(X_i-X_j)}$\n\nWhere $\\hat{\\sum_x}$ is the sample covariance matrix of X.\n\n. . . \n\n![](figs/malahanobis_king_nielsen.png)\n\n\n\n\n\n## Distance Matching  {.smaller background=\"#c6f7ec\"}\n\nDistance matching only goes so far...\n\n... **the larger the dimensionality, the harder is to use distance matching**.\n\nAs sample size increases, for a given N of covariates, the matching discrepancies tend to zero.\n\nBut, the more covariates, the longer it takes.\n\n. . . \n\nAt the end of the day, it is preferable to have many covariates, but it is makes distance matching harder.\n\n\n\n\n\n\n\n\n# Coarsened Exact Matching (CER)  {.smaller background=\"#fce0cc\"}\n\n## Coarsened Exact Matching (CER)  {.smaller background=\"#fce0cc\"}\n\nIn coarsened exact matching, something only counts as a match if it exactly matches on each matching variable. \n\n**The ‚Äúcoarsened‚Äù part comes in because, if you have any continuous variables to match on, you need to ‚Äúcoarsen‚Äù them first by putting them into bins, rather than matching on exact values.**\n\nCoarsening means creating bins. Fewer bins makes exact matches more likely. \n\n. . .\n\nCER is not used much in empirical research in finance. It is used more in the big data realm when you have many variables to match. \n\n\n\n\n\n\n\n# Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n**PSM is one way to matching using many covariates.** \n\n**PSM aggregates all covariates into one score (propensity-score), which is the likelihood of receiving the treatment.**\n\nThe idea is to match units that, based on observables, have the same probability (called propensity-score) of being treated. \n\n. . .\n\nThe idea is to estimate a probit (default in stata) or logit model (fist stage):\n\n$$P(D=1|X)$$\n\n**The propensity-score is the predicted probability of a unit being treated given all covariates X**. The p-score is just a single number.\n\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nConsiderations in PSM.\n\n1) How many neighbors to match?\n\n- Nearest neighbor, radius or kernel?\n\n2) With or without replacement?\n\n3) With or without common support?\n\n- *Common support*: imposes a common support by dropping treatment observations whose pscore is higher than the maximum or less than the minimum pscore of the controls.\n\n4) It is expected that, after PSM, you show the overlap of propensity-scores.\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**The y-axis is the propensity-score**.\n\n![](figs/ani_katchova1.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Nearest matching:** Find the observation closest to ($min|p_i-p_j|$)\n\n![](figs/ani_katchova3.png)\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Kernel matching:** Each treated observation i is matched with several control observations, with weights inversely proportional to the distance between treated and control observations.\n\n![](figs/ani_katchova2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Radius matching**: Each treated observation i is matched with control observations j that fall within a specified radius.\n\n$$|p_i-p_j| <r$$\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n[Source](https://sites.google.com/site/econometricsacademy/home)\n\n**Common support:** Restrict matching only based on the common range of propensity scores.\n\n![](figs/ani_katchova5.png)\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems good overlap, but \"good\" is arbitrary.\n\n![](figs/psm1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems bad overlap\n\n![](figs/psm2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems good overlap, but \"good\" is arbitrary.\n\n![](figs/psm_graph1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\nSeems bad overlap\n\n![](figs/psm_graph2.png)\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_bias.png)\n\n\n\n\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_ttest1.png)\n\n\n## Propensity-score matching (PSM)  {.smaller background=\"#e3bfc3\"}\n\n![](figs/psm_ttest2.png)\n\n\n\n\n\n\n\n\n\n\n# Example  {.smaller background=\"#dff5ce\"}\n\n## Example  {.smaller background=\"#dff5ce\"}\n\nLet's practice with an example. 185 treated units vs 15,992 control units. \n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# Load necessary packages\n# Load necessary libraries\nlibrary(haven)\nlibrary(psych)\ndata <- read_dta(\"files/cps1re74.dta\")\nsummary_stats <- by(data, data$treat, FUN = function(group) {\n  c(\n    mean = mean(group$age, na.rm = TRUE),\n    variance = var(group$age, na.rm = TRUE),\n    skewness = skew(group$age, na.rm = TRUE),\n    count = length(group$age)\n  )\n})\nsummary_df <- as.data.frame(do.call(rbind, summary_stats))\ncolnames(summary_df) <- c(\"mean\", \"variance\", \"skewness\", \"count\")\nprint(summary_df)\n```\n\n### Python\n\n```{python}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Python\"\nimport pandas as pd\nfrom scipy.stats import skew\nimport statsmodels.api as sm\ndata = pd.read_stata(\"files/cps1re74.dta\")\ngrouped_data = data.groupby('treat')['age'].agg(['mean', 'var', lambda x: skew(x, nan_policy='omit'), 'count']).reset_index()\ngrouped_data.columns = ['treat', 'mean', 'variance', 'skewness', 'count']\nprint(grouped_data)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui estpost tabstat age black educ , by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs nonumber compress \n```  \n\n:::\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\nClearly, the treated group is younger, mainly black, and less educated.\n\nAlso note that the **variance and skewness** of the two subsamples are **different**.\n\nIf we were to use these two subsamples in any econometric analysis **without preprocessing to make them comparable**, we would likely have coefficients biased by **selection bias**.\n\nTherefore, it is important to perform some matching method.\n\nLet's start with Propensity Score Matching (PSM). We will use the simplest matching, that is, without using any additional functions.\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Nearest with noreplacement.**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# install.packages(\"MatchIt\")\nlibrary(haven)\nlibrary(psych)\nlibrary(MatchIt)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"nearest\")\nsummary(model)\n```\n\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\npsmatch2 treat age black educ , n(1) noreplacement\nsum _weight , d\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Notice that we are creating weights now**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\n# install.packages(\"MatchIt\")\nlibrary(haven)\nlibrary(MatchIt)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"exact\")\nsummary(model$weights)\n\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui psmatch2 treat age black educ , kernel\nsum _weight , d\n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n## Example  {.smaller background=\"#dff5ce\"}\n\n**Now, the descriptive statistics are much closer**\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven)\nlibrary(MatchIt)\n#install.packages(\"e1071\")\nlibrary(e1071)\ndata <- read_dta(\"files/cps1re74.dta\")\nmodel <- matchit(treat ~ age + black + educ, data = data, method = \"exact\")\nmatched_data <- match.data(model)\nsummary_stats <- by(matched_data, matched_data$treat, function(x) {\n  c(mean(x$age), var(x$age), skewness(x$age), length(x$age))\n})\n\nresult_df <- data.frame(\n  Treatment = c(\"Control\", \"Treated\"),\n  Mean_Age = sapply(summary_stats, function(x) x[1]),\n  Variance_Age = sapply(summary_stats, function(x) x[2]),\n  Skewness_Age = sapply(summary_stats, function(x) x[3]),\n  Count = sapply(summary_stats, function(x) x[4])\n)\nprint(result_df)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui psmatch2 treat age black educ , kernel\nqui estpost tabstat age black educ [aweight = _weight], by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs  nonumber compress \n```  \n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n**Here, instead of matching units, we reweight the observations such that the moments of the distributions (mean, variance, skewness) are similar.**\n\n- The ebalance function implements a reweighting scheme. The user starts by choosing the covariates that should be included in the reweighting. \n\n- For each covariate, the user then specifies a set of balance constraints (in Equation 5) to equate the moments of the covariate distribution between the treatment and the reweighted control group. \n\n- The moment constraints may include the mean (first moment), the variance (second moment), and the skewness (third moment).\n\n**The outcome is a vector containing the weights to weight the observations, such that the weighted average, weighted variance, and weighted skewness of the covariates in control group are similar to those in the treatment group**\n\n\n\n\n\n\n\n\n\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n\n::: panel-tabset\n### R\n\n```{r}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output-location: default\n#| code-fold: true\n#| code-summary: \"R\"\n#| code-line-numbers: true\n#| eval: true\nlibrary(haven)\n#install.packages(\"ebal\")\nlibrary(ebal)\ndata <- read_dta(\"files/cps1re74.dta\")\ntreatment <-cbind(data$treat)\nvars <-cbind(data$age, data$educ, data$black)\neb <- ebalance(treatment, vars)\n# means in treatment group data\napply(vars[treatment==1,],2,mean)\n# means in reweighted control group data\napply(vars[treatment==0,],2,weighted.mean,w=eb$w)\n# means in raw data control group data\napply(vars[treatment==0,],2,mean)\n```\n\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nebalance treat age black educ, targets(3)\n```  \n\n:::\n\n\n\n\n\n\n## Entropy Balancing  {.smaller background=\"#fccad9\"}\n\n\n::: panel-tabset\n### Stata\n\n```{stata}\n#| warning: false\n#| message: false\n#| fig-align: center\n#| echo: true\n#| output: true\n#| output-location: default\n#| code-fold: true\n#| code-line-numbers: true\n#| eval: true\n#| code-summary: \"Stata\"\nuse files/cps1re74.dta, clear\nqui ebalance treat age black educ, targets(3)\nqui estpost tabstat age black educ [aweight = _webal], by(treat) c(s) s(me v sk n) nototal\nesttab . \t,varwidth(20) cells(\"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))\") noobs  nonumber compress \n```  \n\n:::\n\n\n\n\n\n## THANK YOU!\n\n::: columns\n::: {.column width=\"30%\"}\n![](figs/fgv.png){fig-align=\"right\"}\n:::\n\n::: {.column width=\"70%\"}\n**Henrique Castro Martins**\n\n-   [henrique.martins\\@fgv.br](henrique.martins@fgv.br)\n-   <https://eaesp.fgv.br/en/people/henrique-castro-martins>\n-   [henriquemartins.net](https://henriquemartins.net/)\n-   <https://www.linkedin.com/in/henriquecastror/>\n:::\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["styles.css"],"output-file":"part_1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.549","auto-stretch":true,"editor":"visual","title":"Infer√™ncia Causal","subtitle":"Part 1","author":"Henrique C. Martins","slideNumber":true,"theme":"simple","chalkboard":true,"previewLinks":"auto","logo":"figs/background2.png","footer":"<https://eaesp.fgv.br/>","multiplex":true}}},"projectFormats":["html"]}
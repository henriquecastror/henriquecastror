{
  "hash": "fe6f331bca062be5bef0343740e1b8b2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Empirical Methods in Finance'\nsubtitle: 'Part 1'\nauthor: 'Henrique C. Martins'\nformat:\n  revealjs: \n    slide-number: true\n    theme: simple\n    chalkboard: true\n    preview-links: auto\n    logo: figs/background8.png\n    css: logo.css\n    footer: '**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  '\n    multiplex: true\n    scrollable: true \ntitle-slide-attributes:\n    data-background-color: \"#b1cafa\"\ninclude-after: |\n  <script type=\"text/javascript\">\n    Reveal.on('ready', event => {\n      if (event.indexh === 0) {\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n    });\n    Reveal.addEventListener('slidechanged', (event) => {\n      if (event.indexh === 0) {\n        Reveal.configure({ slideNumber: null });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n      if (event.indexh === 1) { \n        Reveal.configure({ slideNumber: 'c' });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = null;\n      }\n    });\n  </script>\n\n---\n\n\n\n\n\n# Agenda\n\n## Agenda {.smaller}\n\n- Apresenta√ß√£o do syllabus do curso\n  - Apresenta√ß√£o dos crit√©rios de avalia√ß√£o\n  \n. . .\n\n- Breve apresenta√ß√£o dos temas de pesquisa e discuss√£o inicial sobre a entrega final\n\n. . .\n\n- In√≠cio do conte√∫do\n  - Introdu√ß√£o a causalidade\n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller visibility=\"hidden\"}\n\n- Formato letter\n  - Entre 2k e 2.5k palavras a depender do journal.\n  \n*The objective of a letter is to facilitate the rapid dissemination of important research that contains an insight, new data, or discuss current important topic.*\n  \n- Ir√° requerer todas as etapas da pesquisa (com √™nfase na an√°lise dos dados, i.e., regress√µes).\n\n- Idealmente, ser√° submetida com o/a orientador/a. Leia-se, sua miss√£o √© \"convencer\" de que o trabalho final √© submet√≠vel a uma revista. \n\n\n\n\n\n\n\n\n\n## Sobre a letter  {.smaller visibility=\"hidden\"}\n\n- Op√ß√µes de revistas que aceitam letter (checar se refer√™ncias e tabelas fazem parte do word count):\n\n  - [Economic Letters](https://www.sciencedirect.com/journal/economics-letters) (ABS3): 2k palavras\n  - [Journal of Accounting and Public Policy](https://www.sciencedirect.com/journal/journal-of-accounting-and-public-policy) (ABS3): 3k palavras\n  - [Finance Research Letters](https://www.sciencedirect.com/journal/finance-research-letters) (ABS2): 2.5k palavras\n  - [Applied Economic Letters](https://www.tandfonline.com/journals/rael20) (ABS1): 2k palavras\n  - [Brazilian Review of Finance](https://periodicos.fgv.br/rbfin) (A4): [4k palavras](https://periodicos.fgv.br/rbfin/libraryFiles/downloadPublic/140) \n  \n* Voc√™ √© bem-vindo/a para propor outro journal que aceite letter, sob condi√ß√£o de valida√ß√£o junto ao instrutor. \n  \n\n\n\n\n\n## Stata {.smaller}\n\n**Providenciar instala√ß√£o para pr√≥ximo encontro**.\n\nPara instala√ß√£o do Stata, seguir instru√ß√µes da TI. \n\n\n\n\n\n\n\n## R {.smaller}\n\n**Providenciar instala√ß√£o para pr√≥ximo encontro**.\n\n\nInstall R [here Win](https://cran.r-project.org/bin/windows/base/)\n\nInstall R [here Mac](https://cran.r-project.org/bin/macosx/)\n\nInstall R Studio [here](https://posit.co/download/rstudio-desktop/)\n\n. . .\n\nPara instalar e carregar os pacotes voc√™ precisa rodar as duas linhas abaixo.\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"false\" code-summary=\"R\" code-line-numbers=\"true\"}\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n## Python {.smaller}\n\n**I might show some code in python, but I cannot offer you support on it.**\n\n\n\n\n\n\n# Selection bias  {.smaller background=\"#fadea7\"} \n\n##  {.smaller background=\"#fadea7\"} \n\n\n![](figs/slides4-airplane.png)\n\n\n\n\n\n\n##  {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path1.jpg)\n\n\n**Voc√™ nunca sabe o resultado do caminho que n√£o toma.**\n\n\n\n\n\n\n\n\n\n\n\n\n## Quais as aplica√ß√µes do que vamos discutir? {.smaller background=\"#fadea7\"} \n\nH√° uma s√©rie de **quest√µes de pesquisa** que poderiam ser investigadas com as ferramentas que vamos discutir hoje.\n\n::: incremental\n\n1) Vale mais a pena estudar em escola particular ou p√∫blica?\n\n2) Qual o efeito de investimentos de marketing t√™m na lucratividade?\n\n3) Qual o efeito que jornadas de 4 dias semanais t√™m na produtividade?\n\n4) Qual efeito que educa√ß√£o tem na remunera√ß√£o futura?\n\n5) E diversas outras semelhantes...\n\n:::\n\n\n\n\n\n\n## Antes de come√ßar: Nossa agenda {.smaller background=\"#fadea7\"} \n\n\n::: incremental \n\n1) Introdu√ß√£o a **pesquisa quantitativa**\n\n2) Validade **Externa** vs. Validade **Interna**\n\n3) **Problemas** em pesquisa quantitativa inferencial\n\n4) **Rem√©dios**\n\n:::\n\n\n\n\n\n\n        \n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n::: incremental\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato)\n\n- Hip√≥teses\n\n- Modelo emp√≠rico\n\n- Coleta de dados \n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n  \n:::\n\n\n\n\n\n\n\n\n\n## Introdu√ß√£o {.smaller background=\"#fadea7\"} \n\n**O que fazemos em pesquisa quantitiva?** Seguimos o m√©todo de pesquisa tradicional (com ajustes):\n\n\n- Observa√ß√£o \n\n- Quest√£o de pesquisa \n\n- Modelo te√≥rico (abstrato): **Aqui √© onde a matem√°tica √© necess√°ria**\n\n- Hip√≥teses\n\n- Modelo emp√≠rico: **Estat√≠stica e econometria necess√°rias**\n\n- Coleta de dados: **Geralmente secund√°rios**\n\n- An√°lise do resultado do modelo (diferente de an√°lise de dados \"pura\")\n\n- Conclus√£o/desdobramentos/aprendizados\n\n\n\n\n\n\n\n. . .\n\n## Defini√ß√£o {.smaller background=\"#fadea7\"} \n\n**_Pesquisa quantitativa busca testar hip√≥teses..._**\n\n. . .\n\n**_...a partir da defini√ß√£o de modelos formais (abstratos)..._**\n\n. . .\n\n**_...de onde se estimam modelos emp√≠ricos utilizando a estat√≠stica e a econometria como mecanismos/instrumentos._**\n\n. . .\n\n\nNo fim do dia, buscamos **entender as rela√ß√µes** (que tenham **validade interna** e que ofere√ßam **validade externa**) entre diferentes **vari√°veis de interesse.**\n\n\n\n\n\n\n\n\n\n\n\n## Quais as vantagens? {.smaller background=\"#fadea7\"} \n\n1) **Validade externa:** \n\n. . .\n\n- Conceito de que, se a pesquisa tem validade externa, os seus **achados s√£o representativos**.\n\n. . .\n\n- I.e., s√£o **v√°lidos al√©m do seu modelo**. Resultados \"valem externamente\".\n\n. . .\n\n- Idealmente, buscamos resultados que valem externamente para **acumular conhecimento**...\n\n. . .\n\n- ...naturalmente, nem toda pesquisa quantitativa oferece validade externa. A pesquisa √≥tima sim. **A pesquisa excelente tem validade externa para al√©m do seu tempo**.\n\n. . .\n\n- Pesquisa qualitativa dificilmente oferece **validade externa**.\n\n\n\n\n\n\n\n\n\n\n## Quais as armadilhas? {.smaller background=\"#fadea7\"} \n\n\n2) **Validade interna:** \n\n. . .\n\n- Conceito de que a pesquisa precisa de validade interna para que seus **resultados sejam cr√≠veis**.\n\n. . .\n\n- I.e., os **resultados n√£o podem conter erros**, vieses, problemas de estima√ß√£o, problemas nos dados, etc..\n\n. . .\n\n- √â aqui que a gente separa a pesquisa ruim da pesquisa boa. Para ser levada a s√©rio, a pesquisa **PRECISA** ter validade interna.\n\n. . .\n\n- Mas isso, nem sempre √© trivial. Muitas pesquisas que vemos publicadas, mesmo em top journals, **n√£o t√™m validade interna** (seja por erro do pesquisador, por m√©todo incorreto, por falta de dados...)\n\n. . .\n\n- Mas cada vez mais, **avaliadores est√£o de olho** em problemas e em modelos  **Trash-in-Trash-out**\n\n\n\n\n\n\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\nExemplo de modelo emp√≠rico:\n\n$Y_{i} = Œ± + ùú∑_{1} √ó X_i + Controls + error$\n\n. . .\n\n<img src=\"figs/slides4-ols.jpg\" width=\"30%\" align=\"right\" />\n\n. . .\n\nUma vez que estimemos esse modelo, temos o **valor**, o **sinal** e a **signific√¢ncia** do $ùú∑$.\n\n. . .\n\nSe o Beta for **significativamente diferente de zero** e **positivo** --> X e Y est√£o positivamente correlacionados.\n\n. . .\n\n**O problema?** Os pacotes estat√≠sticos que utilizamos **sempre \"cospem\" um beta**. Seja ele com ou sem vi√©s.\n\n. . .\n\nCabe ao pesquisador ter um **design emp√≠rico** que garanta que o beta estimado tenha validade interna.\n\n\n\n\n\n## Como fazemos na pr√°tica? {.smaller background=\"#fadea7\"} \n\n\n<img src=\"figs/slides4-table.png\" width=\"110%\" align=\"center\" />\n\nA decis√£o final √© baseada na signific√¢ncia do Beta estimado. Se **significativo**, as vari√°veis s√£o relacionadas e fazemos infer√™ncias em cima disso.\n\nContudo, **sem um design emp√≠rico inteligente**, o beta encontrado pode ter literalmente qualquer sinal e signific√¢ncia.\n\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius1.png\" width=\"100%\" align=\"center\" />\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\nVeja esse [site](http://www.tylervigen.com/spurious-correlations).\n\n<img src=\"figs/slides4-spurius2.png\" width=\"110%\" align=\"center\" />\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see I {.smaller background=\"#fadea7\"} \n\n\n::: panel-tabset\n\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nlibrary(data.table)\nlibrary(ggplot2)\n# Generate Data\nn = 10000\nset.seed(100)\nx <- rnorm(n)\ny <- rnorm(n)\ndata1 <- 1/(1+exp( 2 - x  -  y))\ngroup  <- rbinom(n, 1, data1)\n\n# Data Together\ndata_we_see     <- subset(data.table(x, y, group), group==1)\ndata_all        <- data.table(x, y, group)\n\n# Graphs\nggplot(data_we_see, aes(x = x, y = y)) + \n      geom_point(aes(colour = factor(-group)), size = 1) +\n      geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n      labs( y = \"\", x=\"\", title = \"The observations we see\")+\n      xlim(-3,4)+ ylim(-3,4)+ \n      theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n            panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n            axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n            axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n            legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](part_1_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(7, 5))\nplt.scatter(data_we_see['x'], data_we_see['y'], c=-data_we_see['group'], cmap='viridis', s=20)\nsns.regplot(x='x', y='y', data=data_we_see, scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"The observations we see\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](part_1_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.stata .cell-code  code-fold=\"true\" code-summary=\"Stata\" code-line-numbers=\"true\"}\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\ntwoway (scatter x y if group == 1, mcolor(black) msize(small))    (lfit y x if group == 1, color(blue)),title(\"The observations we see\", size(large) ) xtitle(\"\") ytitle(\"\")\nquietly graph export figs/graph1.svg, replace\n```\n:::\n\n\n![](figs/graph1.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - We see II  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\n# Fit a linear regression model\nmodel <- lm(y ~ x, data = data_we_see)\n# Print the summary of the regression model\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = data_we_see)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.05878 -0.63754 -0.00276  0.62056  3.11374 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.72820    0.02660   27.37  < 2e-16 ***\nx           -0.14773    0.02327   -6.35 2.75e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9113 on 1747 degrees of freedom\nMultiple R-squared:  0.02256,\tAdjusted R-squared:  0.022 \nF-statistic: 40.32 on 1 and 1747 DF,  p-value: 2.746e-10\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_we_see['x']  \nX = sm.add_constant(X)\ny = data_we_see['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.018\nModel:                            OLS   Adj. R-squared:                  0.018\nMethod:                 Least Squares   F-statistic:                     33.84\nDate:                sex, 29 ago 2025   Prob (F-statistic):           7.06e-09\nTime:                        13:31:25   Log-Likelihood:                -2411.1\nNo. Observations:                1809   AIC:                             4826.\nDf Residuals:                    1807   BIC:                             4837.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.7037      0.026     26.826      0.000       0.652       0.755\nx             -0.1339      0.023     -5.817      0.000      -0.179      -0.089\n==============================================================================\nOmnibus:                        4.656   Durbin-Watson:                   1.973\nProb(Omnibus):                  0.097   Jarque-Bera (JB):                5.264\nSkew:                          -0.038   Prob(JB):                       0.0720\nKurtosis:                       3.253   Cond. No.                         1.93\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n\n\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.stata .cell-code  code-fold=\"true\" code-summary=\"Stata\" code-line-numbers=\"true\"}\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x if group ==1\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of observations (_N) was 0, now 10,000.\n\n      Source |       SS           df       MS      Number of obs   =     1,872\n-------------+----------------------------------   F(1, 1870)      =     48.62\n       Model |  40.9398907         1  40.9398907   Prob > F        =    0.0000\n    Residual |  1574.57172     1,870  .842016963   R-squared       =    0.0253\n-------------+----------------------------------   Adj R-squared   =    0.0248\n       Total |  1615.51161     1,871  .863448215   Root MSE        =    .91761\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n           x |  -.1579538   .0226526    -6.97   0.000    -.2023808   -.1135269\n       _cons |   .7202285   .0257215    28.00   0.000     .6697827    .7706744\n------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I  {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nggplot(data_all, aes(x = x, y = y,  colour=group)) + \n  geom_point(aes(colour = factor(-group)), size = 1) +\n  geom_smooth(method=lm, se=FALSE, fullrange=FALSE)+\n  labs( y = \"\", x=\"\", title = \"All observations\")+\n  xlim(-3,4)+ ylim(-3,4)+ \n  theme(plot.title = element_text(color=\"black\", size=30, face=\"bold\"),\n      panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n      axis.text.y = element_text(face=\"bold\", color=\"black\", size = 18),\n      axis.text.x = element_text(face=\"bold\", color=\"black\", size = 18),\n      legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](part_1_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(6, 4))\nsns.scatterplot(data=data_all, x='x', y='y', hue='group', palette=['blue', 'red'], s=20)\nsns.regplot(data=data_all, x='x', y='y', scatter=False, ci=None, line_kws={'color': 'blue'})\nplt.title(\"All observations\", fontsize=18)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.legend(title=\"Group\", labels=[\"0\", \"1\"], loc=\"upper left\")\n\nplt.gca().get_legend().remove()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](part_1_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of observations (_N) was 0, now 10,000.\n```\n\n\n:::\n:::\n\n\n![](figs/graph2.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n## Selection bias - All I {.smaller background=\"#fadea7\"} \n\n::: panel-tabset\n\n### R\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nmodel2 <- lm(y ~ x, data = data_all)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = data_all)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9515 -0.6716  0.0087  0.6698  3.9878 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)\n(Intercept) -0.011825   0.009994  -1.183    0.237\nx           -0.003681   0.010048  -0.366    0.714\n\nResidual standard error: 0.9994 on 9998 degrees of freedom\nMultiple R-squared:  1.342e-05,\tAdjusted R-squared:  -8.66e-05 \nF-statistic: 0.1342 on 1 and 9998 DF,  p-value: 0.7141\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport statsmodels.api as sm\nimport pandas as pd\nn = 10000\nnp.random.seed(100)\nx = np.random.normal(size=n)\ny = np.random.normal(size=n)\ndata1 = 1 / (1 + np.exp(2 - x - y))\ngroup = np.random.binomial(1, data1, n)\n\ndata_we_see = pd.DataFrame({'x': x[group == 1], 'y': y[group == 1], 'group': group[group == 1]})\ndata_all = pd.DataFrame({'x': x, 'y': y, 'group': group})\n\nX = data_all['x']  \nX = sm.add_constant(X)\ny = data_all['y']  \nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     1.281\nDate:                sex, 29 ago 2025   Prob (F-statistic):              0.258\nTime:                        13:31:33   Log-Likelihood:                -14157.\nNo. Observations:               10000   AIC:                         2.832e+04\nDf Residuals:                    9998   BIC:                         2.833e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.0003      0.010     -0.034      0.973      -0.020       0.019\nx             -0.0112      0.010     -1.132      0.258      -0.031       0.008\n==============================================================================\nOmnibus:                        0.267   Durbin-Watson:                   2.009\nProb(Omnibus):                  0.875   Jarque-Bera (JB):                0.242\nSkew:                           0.009   Prob(JB):                        0.886\nKurtosis:                       3.017   Cond. No.                         1.01\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n\n\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.stata .cell-code  code-fold=\"true\" code-summary=\"Stata\" code-line-numbers=\"true\"}\nclear all\nset seed 100\nset obs 10000\ngen x = rnormal(0,1)\ngen y = rnormal(0,1)\ngen data1 = 1 / (1 + exp(2 - x - y))\ngen group = rbinomial(1, data1)\nreg y x \n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of observations (_N) was 0, now 10,000.\n\n      Source |       SS           df       MS      Number of obs   =    10,000\n-------------+----------------------------------   F(1, 9998)      =      0.28\n       Model |  .284496142         1  .284496142   Prob > F        =    0.5938\n    Residual |  9999.04347     9,998  1.00010437   R-squared       =    0.0000\n-------------+----------------------------------   Adj R-squared   =   -0.0001\n       Total |  9999.32797     9,999   1.0000328   Root MSE        =    1.0001\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n           x |  -.0053101    .009956    -0.53   0.594    -.0248259    .0142057\n       _cons |   .0006182   .0100006     0.06   0.951    -.0189849    .0202213\n------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n## Selection bias {.smaller background=\"#fadea7\"} \n\nSelection bias n√£o √© o √∫nico dos nossos problemas, mas √© um **importante**.\n\nVeja que suas conclus√µes mudaram significativamente.\n\nN√£o seria dif√≠cil criar um exemplo em que o **coeficiente verdadeiro** fosse positivo.\n\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-path2b.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=iPBV3BlV7jk)\n\n**N√£o podemos pegar dois caminhos.**\n\n\n\n\n\n\n\n\n\n\n## Exemplo desses problemas {.smaller background=\"#fadea7\"} \n\n![](figs/slides4-matching.png) \n\n\nSource: [Angrist](https://www.youtube.com/watch?v=6YrIDhaUQOE)\n\n**N√£o podemos comparar pessoas que n√£o s√£o compar√°veis.**\n\n\n\n\n\n\n\n\n## O que precisamos fazer? {.smaller background=\"#fadea7\"} \n\n. . .\n\nDefinir um bom **_Design emp√≠rico_**\n\n. . .\n\nNo mundo ideal: ter√≠amos **universos paralelos.** Ter√≠amos **dois clones**, em que cada um escolhe um caminho. Todo o resto √© igual.\n\n- Obviamente, isso n√£o existe.\n\n. . .\n\nSegunda melhor solu√ß√£o: **experimentos**\n\n. . .\n\n**Mas o que √© um experimento?**\n\n- Grupo de tratamento vs. Grupo de controle\n\n- Igualdade entre os grupos (i.e., aleatoriedade no sampling)\n\n    - Nada diferencia os grupos a n√£o ser o fato de que um indiv√≠duo recebe tratamento e o outro n√£o\n    - Estamos comparando ma√ßas com ma√ßas e laranjas com laranjas\n      \n- Testes placebo/falsifica√ß√£o.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## üôã‚Äç‚ôÇÔ∏è **Any Questions?**{ .smaller  background=\"#fdf6e3\"}\n\n::: columns\n::: {.column width=\"50%\"}\n### Thank You!\n\n![](figs/qa2.png){width=\"110%\" style=\"box-shadow: none;\"}\n\n:::\n\n::: {.column width=\"50%\"}\n<div style=\"text-align:right;\">\n  <img src=\"figs/avatar.jpg\" width=\"120px\" style=\"border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,.25);\" />\n</div>\n\n### **Henrique C. Martins**\n\n- üåê [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)  \n- üíº [LinkedIn](https://www.linkedin.com/in/henriquecastror/)  \n- üß† [Google Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)  \n- üìÑ [Lattes CV](http://lattes.cnpq.br/6076997472159785)  \n- üè† [Personal Website](https://henriquemartins.net/)  \n:::\n:::\n\n",
    "supporting": [
      "part_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
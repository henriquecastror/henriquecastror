{
  "hash": "04c889ab3b6021a6b6a26b71dc2827c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Empirical Methods in Finance'\nsubtitle: 'Part 8'\nauthor: 'Henrique C. Martins'\nformat:\n  revealjs: \n    slide-number: true\n    theme: simple\n    chalkboard: true\n    preview-links: auto\n    logo: figs/background8.png\n    css: logo.css\n    footer: '**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  '\n    multiplex: true\n    scrollable: true \ntitle-slide-attributes:\n    data-background-color: \"#b1cafa\"\ninclude-after: |\n  <script type=\"text/javascript\">\n    Reveal.on('ready', event => {\n      if (event.indexh === 0) {\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n    });\n    Reveal.addEventListener('slidechanged', (event) => {\n      if (event.indexh === 0) {\n        Reveal.configure({ slideNumber: null });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n      if (event.indexh === 1) { \n        Reveal.configure({ slideNumber: 'c' });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = null;\n      }\n    });\n  </script>\n\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Regression Discontinuity Design (RDD) {.smaller background=\"#e3e2b8\"}\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**The regression-discontinuity (RD) research design is a quasi experimental method.**\n\nHere the *treatment* is not a binary as before. \n\n**Treated units are assigned based on a cutoff score of a continuous variable.**\n\n. . .\n\nIn a RDD the treatment assignment is not random...\n\n... but it is based in the value of an observed covariate, in which the units lie on either side of the threshold.\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\n- Age for drinking is 18 in Brazil. \n\nWhy prohibiting younger than 18?\n\nThe theory behind this effort is that legal drinking at age 18 discourages binge drinking and promotes a culture of mature alcohol consumption. \n\nThe cutoff splits who can drink and who can't.\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nThe name RDD comes from a *jump*, a discontinuity that occurs in a continuous variable.\n\nIn its simplest form, the design has a:\n\n- The assignment variable (e.g., age), \n\n- Two groups (above and below the cutoff),\n\n- The outcome variable.\n\n- You may include nonlinearities and control variables. \n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nRDD is:\n\n$$D_i = 1(x_i>c) \\;$$\n\nwhere:\n\n- $$\\;D = 1 \\; if \\;X \\;_i>c $$ \n\n- $$\\;D = 0 \\; if \\;X \\;_i<c $$\n\n\n$X$ is called the forcing variable because it \"forces\" units into treatment or control groups.\n\n$X$ may be correlated with $Y_1$ or $Y_0$, so simply comparing treated and control units would not provide causal effects\n\nHowever, if the units are randomly assigned into treatment around the cutoff, we would have causal effects.\n\n\n\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nThe main assumption that allows using RDD as a causal method is that\n\n**Next to the cut, the participants are similar. The only difference is that one individual is in each of the \"sides\".** [Source](http://dx.doi.org/10.1016/B978-0-08-097086-8.44049-3)\n\n![](figs/rdd0.png){width=60%  height=60%}\n\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n- The cutoff value **occurs at 50**\n\n- What are the differences between someone that scores 49.99 and 50.01 in the X variable?\n\n- The intuition is that these individuals are similar and comparable.\n\nIn the absence of **treatment**, the assumption is that the solid line would \"continue\" with the same inclination and values. \n\nThere is a discontinuity, however. This implies that the pretreatment  in the absence of the treatment should be the dashed line.\n\nThe discontinuity is the causal effect of X (at the cutoff) to Y.\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n*Unlike the matching and regression strategies based on treatment-control comparisons conditional on covariates, the validity of RDD is based on our willingness to extrapolate across values of the running variable, at least for values in the neighborhood of the cutoff at which treatment switches on.* [MM](https://www.masteringmetrics.com/)\n\n\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**Again the drinking example:**\n\n\n**In the US it is 21 years (age & alcohol).** **[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\n*Notice the x-axis.*\n\n![](figs/rdd1.png)\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**In the US it is 21 years.** **[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\n*Notice the x-axis.*\n\n![](figs/rdd2.png)\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nExamples [Almeida et al 2016](https://doi.org/10.1016/j.jfineco.2015.08.008)\n\n\n![](figs/almeida.png)\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nExamples [Flammer 2015](https://doi.org/10.1287/mnsc.2014.2038)\n\n\n![](figs/flammer.png)\n\n\n\n\n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nThis is (legally, it should be) an example of a **Sharp RDD**\n\nA **Sharp RDD** occurs when the cutoff is mandatory. There are no exceptions. In this case, there are no 17 years old drinking and driving. \n\nThe treatment is\n\n$$D_a= 1, \\;if \\;a \\;>=\\; 18, \\;0 \\;if \\;a\\; <\\; 18$$ \n\n\n. . . \n\nThe alternative is a **fuzzy RDD**, which occurs when there is some misassignment.\n\n- People from under the cut also receiving the treatment.\n- Ex. students that receive 5,96 usually are *approved* in a course (this is a misassignment).\n- To estimate a Fuzzy RDD, you can use the treatment as an instrumental variable (Angrist & Pischke, 2009).  \n\n\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**fuzzy RDD** ([The effect](https://theeffectbook.net/ch-DifferenceinDifference.html) )\n\n\n![](figs/fuzzy.png)\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\n**fuzzy RDD** \n\n*Compliers*: Takes treatment if above threshold but not if below threshold.\n\n*Always-Takers*: Always takes the treatment, ignores the cut.\n\n*Never-Takers*: Never takes the treatment, ignores the cut.\n\n*Defiers*: Takes treatment if below the threshold, does not take the treatment if above the threshold.\n\n\n\n\n## Regression Discontinuity Design (RDD)   {.smaller background=\"#e3e2b8\"}\n\nThings that are \"good\" to a RDD.\n\n- Age \n- Dates (you need 6 years to start school, 5,99 years is not allowed)\n  - Great example: Most of NHL players are those with anniversaries just after the enrollment date\n- Ranking systems\n- Location (when people cannot \"move\" easily)\n\n\n\n\n\n\n# Estimation {.smaller background=\"#d4d3bc\"}\n\n\n## Estimation   {.smaller background=\"#d4d3bc\"}\n\nA **Sharp RDD** can take the form of:\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 \\tilde{x}_1 + \\epsilon$$\n\nWhere $D_a$ is the treatment based on the cutoff.\n\n$x$ is the running variable (the difference between the actual $X$ and the cutoff in $X_0$).\n\n- For instance, months until the 18 years birthday.\n\n- We can also use the notation: $\\tilde{X}=x-x_0$ regarding the difference. \n\n\n\n\n\n\n\n## Estimation   {.smaller background=\"#d4d3bc\"}\n\nYou also should trim the sample to a reasonable window around the cutoff $c$ \n\n- Something like: $c-h<X_i<c+h$, where $h$ is a positive value that determines the window\n\n- There is no theoretical solution to how big should $h$ be. It invites robustness tests.\n\n\n\n## Estimation   {.smaller background=\"#d4d3bc\"}\n\n**Final Step:**\n\nDecide on the model of E[Y|X]:\n\n- linear in both \"sides\" with same slope\n\n- linear with different slopes\n\n- non-linear\n\n\n\n**Tip**: always execute a visual inspection to check which model os appropriate.\n\nAlso, always estimate different models and discuss the results.\n\n\n\n\n\n\n## Estimation   {.smaller background=\"#d4d3bc\"}\n\n**fuzzy RDD** \n\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 \\tilde{x}_1 + \\beta_3(Z \\times \\tilde{x}_1) \\epsilon$$\n\nWhere Z is 1 if unit is above the cut or 0 if unit is below the cut.\n\nNotice that D is not equal to Z, in these cases.\n\n\n\n\n\n\n\n\n\n# RDD Nonlinearities  {.smaller background=\"#f2f1d5\"}\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\n\n**[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\nThis is a linear relationship, with the same slopes.\n\n![](figs/rdd3.png)\n\n$$E[Y|X,D] = \\alpha + \\beta_1 \\times D + \\beta_2 \\times \\tilde{X}$$\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\n\n[The effect](https://theeffectbook.net/ch-DifferenceinDifference.html) This is a linear relationship, with different  slopes.\n\n![](figs/rdd_diff_slope.png)\n\n\n\n\n\n\n\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\n**[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\nThis is a nonlinear relationship.\n\n![](figs/rdd4.png)\n\n\n\n\n\n\n\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\n**[Example Mastering Metrics](https://www.masteringmetrics.com/):**\n\n Is the relationship linear or nonlinear here? If you misjudge the relationship, it will be hard to tell a story credibly.\n\n![](figs/rdd5.png)\n\n\n\n\n\n\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\n**The takeaway:** **RDD is a graphical method. You need to show the graphs**.\n\n**Nobody will believe your story without the correct specification of the model**.\n\n. . .\n\nIn the first case:\n\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 x_1 + \\epsilon$$\n\nIn the second case:\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 x_1 + \\beta_3 x_1^2 + \\epsilon$$\n\n\n\n\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\nWe can also add an interaction term (notice that I am changing the notation now to make it similar to MM)\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 (x - x_0) + \\beta_3 (x - x_0) D_a + \\epsilon$$\n\nThis allows for different inclinations before and after the cut.\n\n\n\n## RDD Nonlinearities   {.smaller background=\"#f2f1d5\"}\n\nOr even different nonlinearities before and after the cut:\n\n\n$$Y_i = \\alpha + \\beta_1 D_a + \\beta_2 (x - x_0) + \\beta_3 (x - x_0)^2 + \\beta_4 (x - x_0) D_a  + \\beta_5 (x - x_0)^2 D_a + \\epsilon$$\n\n\n![](figs/rdd6.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Example RDD  {.smaller background=\"#edecc0\"}\n\n## Example RDD **Clearly, this is not linear.** {.smaller background=\"#edecc0\"}\n\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nlibrary(readxl)\nlibrary(ggplot2)\ndata  <- read_excel(\"files/RDD.xlsx\")\nggplot(data, aes(x, y))  + \n  geom_point(size=1.2) + \n  labs(y = \"\", x=\"\", title = \"Evolution of Y\") +\n  theme(plot.title = element_text(color=\"black\", size=20, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 12),\n        axis.text.x = element_text(face=\"bold\", color=\"black\", size = 12),\n        legend.title = element_blank(),\n        legend.key.size = unit(1, \"cm\")) +\n    geom_smooth(method = \"lm\", fill = NA)\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Read Excel file\ndata = pd.read_excel(\"files/RDD.xlsx\")\n# Generate line graph - Including all observations together\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10, 5))\nscatter_plot = sns.scatterplot(x='x', y='y', data=data, s=50)\nscatter_plot.set_title(\"Evolution of Y\", fontsize=20, fontweight='bold')\nscatter_plot.set_xlabel(\"\", fontsize=12, fontweight='bold')\nscatter_plot.set_ylabel(\"\", fontsize=12, fontweight='bold')\n# Add regression line\nsns.regplot(x='x', y='y', data=data, scatter=False, line_kws={'color': 'blue'})\nplt.show()\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n:::\n\n\n![](figs/graph1.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Example RDD  {.smaller background=\"#edecc0\"}\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nlibrary(readxl)\nlibrary(ggplot2)\ndata  <- read_excel(\"files/RDD.xlsx\")\n# Creating  groups\ndata$treated <- 0\ndata$treated[data$x >= 101] <- 1  \n# Generate a line graph - two groups\nggplot(data, aes(x, y, group=treated, color = factor(treated)))  + \n    geom_point( size=1.25) + \n    labs(y = \"\", x=\"\", title = \"RDD exemplo\")+\n    theme(plot.title = element_text(color=\"black\", size=25, face=\"bold\"),\n          panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n          axis.text.y = element_text(face=\"bold\", color=\"black\", size = 16),\n          axis.text.x = element_text(face=\"bold\", color=\"black\", size = 16),\n          legend.title = element_blank(),\n          legend.key.size = unit(2, \"cm\")) +\n    geom_smooth(method = \"lm\", fill = NA)\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-4-3.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Read Excel file\ndata = pd.read_excel(\"files/RDD.xlsx\")\n# Create treated variable\ndata['treated'] = 0\ndata.loc[data['x'] >= 101, 'treated'] = 1\n# Generate line graph with two groups\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10, 5))\nscatter_plot = sns.scatterplot(x='x', y='y', hue='treated', style='treated', data=data, s=50)\nscatter_plot.set_title(\"RDD exemplo\", fontsize=25, fontweight='bold')\nscatter_plot.set_xlabel(\"\", fontsize=16, fontweight='bold')\nscatter_plot.set_ylabel(\"\", fontsize=16, fontweight='bold')\nscatter_plot.legend().set_title('')\nscatter_plot.legend(title='', loc='upper left', fontsize='small')\n# Add regression lines\nsns.regplot(x='x', y='y', data=data[data['treated'] == 0], scatter=False, line_kws={'color': 'blue'})\nsns.regplot(x='x', y='y', data=data[data['treated'] == 1], scatter=False, line_kws={'color': 'orange'})\nplt.show()\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n:::\n\n\n![](figs/graph2.svg) \n\n:::\n\n\n\n\n\n\n\n\n\n## Example RDD  {.smaller background=\"#edecc0\"}\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nlibrary(readxl)\nlibrary(ggplot2)\ndata  <- read_excel(\"files/RDD.xlsx\")\n# Creating  groups\ndata$treated <- 0\ndata$treated[data$x >= 101] <- 1  \n# define cut\ncut <- 100\nband <- 50\nxlow = cut - band\nxhigh = cut + band\n# subset the data for the bandwidth\ndata <- subset(data, x > xlow & x <= xhigh, select=c(x, y,  treated))\n# Generate a line graph - two groups\nggplot(data, aes(x, y, group=treated, color = factor(treated)))  + \n  geom_point( size=1.25) + \n  labs(y = \"\", x=\"\", title = \"RDD example\")+\n  theme(plot.title = element_text(color=\"black\", size=25, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 16),\n        axis.text.x = element_text(face=\"bold\", color=\"black\", size = 16),\n        legend.title = element_blank(),\n        legend.key.size = unit(2, \"cm\")) +\n  geom_smooth(method = \"lm\", fill = NA)\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-7-3.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Read Excel file\ndata = pd.read_excel(\"files/RDD.xlsx\")\n# Create treated variable\ndata['treated'] = 0\ndata.loc[data['x'] >= 101, 'treated'] = 1\n# Define cut, band, and subset data\ncut = 100\nband = 50\nxlow = cut - band\nxhigh = cut + band\ndata = data[(data['x'] > xlow) & (data['x'] <= xhigh)][['x', 'y', 'treated']]\n# Generate line graph with two groups\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10, 5))\nscatter_plot = sns.scatterplot(x='x', y='y', hue='treated', style='treated', data=data, s=50)\nscatter_plot.set_title(\"RDD example\", fontsize=25, fontweight='bold')\nscatter_plot.set_xlabel(\"\", fontsize=16, fontweight='bold')\nscatter_plot.set_ylabel(\"\", fontsize=16, fontweight='bold')\nscatter_plot.legend().set_title('')\nscatter_plot.legend(title='', loc='upper left', fontsize='small')\n# Add regression lines\nsns.regplot(x='x', y='y', data=data[data['treated'] == 0], scatter=False, line_kws={'color': 'blue'})\nsns.regplot(x='x', y='y', data=data[data['treated'] == 1], scatter=False, line_kws={'color': 'orange'})\nplt.show()\n```\n\n::: {.cell-output-display}\n![](part_8_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n:::\n\n\n![](figs/graph3.svg)\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Example RDD  {.smaller background=\"#edecc0\"}\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R\" code-line-numbers=\"true\"}\nlibrary(readxl)\nlibrary(ggplot2)\ndata  <- read_excel(\"files/RDD.xlsx\")\ndata$treated <- 0\ndata$treated[data$x >= 101] <- 1  \ncut <- 100\nband <- 50\nxlow = cut - band\nxhigh = cut + band\ndata <- subset(data, x > xlow & x <= xhigh, select=c(x, y,  treated))\n# Generating xhat - Now we are going to the RDD\ndata$xhat <- data$x - cut\n# Generating xhat * treated to allow different inclinations (we will use the findings of the last graph, i.e. that each group has a different trend.)\ndata$xhat_treated <- data$xhat * data$treated\n# RDD Assuming different trends\nrdd <- lm(y  ~ xhat + treated  + xhat_treated, data = data)\nsummary(rdd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ xhat + treated + xhat_treated, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.9477  -3.2607   0.6875   3.2227  12.2004 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  55.83059    1.53681  36.329  < 2e-16 ***\nxhat          0.29431    0.05405   5.445 3.97e-07 ***\ntreated      28.93921    2.20672  13.114  < 2e-16 ***\nxhat_treated -0.51587    0.07644  -6.749 1.13e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.515 on 96 degrees of freedom\nMultiple R-squared:  0.8942,\tAdjusted R-squared:  0.8909 \nF-statistic: 270.3 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Python\" code-line-numbers=\"true\"}\nimport pandas as pd\nimport statsmodels.api as sm\ndata = pd.read_excel(\"files/RDD.xlsx\")\n# Generate treated variable\ndata['treated'] = 0\ndata.loc[data['x'] >= 101, 'treated'] = 1\n# Define cut and band\ncut = 100\nband = 50\nxlow = cut - band\nxhigh = cut + band\n# Subset data\ndata = data[(data['x'] > xlow) & (data['x'] <= xhigh)]\n# Generate xhat and xhat_treated\ndata['xhat'] = data['x'] - cut\ndata['xhat_treated'] = data['xhat'] * data['treated']\n# Regression\nX = data[['xhat', 'treated', 'xhat_treated']]\nX = sm.add_constant(X)  # Add a constant term\ny = data['y']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.894\nModel:                            OLS   Adj. R-squared:                  0.891\nMethod:                 Least Squares   F-statistic:                     270.3\nDate:                ter, 24 set 2024   Prob (F-statistic):           1.14e-46\nTime:                        19:51:19   Log-Likelihood:                -310.60\nNo. Observations:                 100   AIC:                             629.2\nDf Residuals:                      96   BIC:                             639.6\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nconst           55.8306      1.537     36.329      0.000      52.780      58.881\nxhat             0.2943      0.054      5.445      0.000       0.187       0.402\ntreated         28.9392      2.207     13.114      0.000      24.559      33.320\nxhat_treated    -0.5159      0.076     -6.749      0.000      -0.668      -0.364\n==============================================================================\nOmnibus:                        0.995   Durbin-Watson:                   2.114\nProb(Omnibus):                  0.608   Jarque-Bera (JB):                1.079\nSkew:                          -0.221   Prob(JB):                        0.583\nKurtosis:                       2.747   Cond. No.                         151.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n\n\n:::\n:::\n\n\n### Stata\n\n\n::: {.cell layout-align=\"center\" output-location='default'}\n\n```{.stata .cell-code  code-fold=\"true\" code-summary=\"Stata\" code-line-numbers=\"true\"}\nimport excel \"files/RDD.xlsx\", firstrow clear\ngen treated = 0\nreplace treated = 1 if x >= 101\ngen cut = 100\ngen band = 50\ngen xlow = cut - band\ngen xhigh = cut + band\nkeep if x > xlow & x <= xhigh\ngen xhat = x - cut\ngen xhat_treated = xhat * treated\nregress y xhat treated xhat_treated\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(2 vars, 200 obs)\n\n\n(100 real changes made)\n\n\n\n\n\n(100 observations deleted)\n\n      Source |       SS           df       MS      Number of obs   =       100\n-------------+----------------------------------   F(3, 96)        =    270.35\n       Model |  24669.3025         3  8223.10084   Prob > F        =    0.0000\n    Residual |  2920.00749        96  30.4167447   R-squared       =    0.8942\n-------------+----------------------------------   Adj R-squared   =    0.8909\n       Total |    27589.31        99  278.679899   Root MSE        =    5.5151\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        xhat |   .2943097   .0540479     5.45   0.000     .1870255     .401594\n     treated |   28.93921   2.206717    13.11   0.000     24.55891    33.31951\nxhat_treated |  -.5158703   .0764353    -6.75   0.000    -.6675932   -.3641475\n       _cons |   55.83059   1.536805    36.33   0.000     52.78005    58.88112\n------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n:::\n\n\n\n\n## Example RDD  {.smaller background=\"#edecc0\"}\n\nThe coefficient of x before the cut is 0.29 (t-stat 5.45), and after the cut, it is -0.51 (t-stat -6.75). \n\nWe also have the coefficient of the treatment, which is measured by the \"jump\" that occurs near the cut: **an estimated coefficient of 28.9 (t-stat 13.11). **\n\nIf this were a real example, this would be the causal effect of receiving the treatment (i.e., being beyond the cut).\n\n\n\n\n\n\n\n\n\n\n# Final comments RDD {.smaller background=\"#f0eeb4\"}\n\n## Final comments RDD {.smaller background=\"#f0eeb4\"}\n\n\n**Sensitivity to specification**\n\nMisspecification can lead to a \"spurious jump\". **Do not mix nonlinearity with a discontinuity**.\n\n. . . \n\n**Sensitivity to window**\n\nAlso, need to check many alternative $h$. \n\n. . . \n\n**Smoothness of the running around the cut**\n\nThe distribution of X should be smooth around the cut. If it is not, it might indicate that the treatment assignment was not random. \n\n. . . \n\n**Test comparability of units around the cut**\n\nCovariates balance. You can check whether there are jumps in control variables as an additional robustness.\n\n. . . \n\n**Placebo tests**\n\nTest whether the treatment is zero when it should be zero.\n\n\n\n\n\n\n\n\n\n\n## **THANK YOU!** {background=\"#b1cafa\"}\n\n::: columns\n::: {.column width=\"60%\"}\n**QUESTIONS?**\n\n![](figs/qa2.png){width=\"150%\" heigth=\"150%\"}\n:::\n\n::: {.column width=\"40%\"}\n**Henrique C. Martins**\n\n-   [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)\n-   [Personal Website](https://henriquemartins.net/)\n-   [LinkedIn](https://www.linkedin.com/in/henriquecastror/)\n-   [Lattes](http://lattes.cnpq.br/6076997472159785)\n-   [Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)\\\n:::\n:::\n\n::: footer\n:::\n",
    "supporting": [
      "part_8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
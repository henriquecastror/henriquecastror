{
  "hash": "1394721f66dc835e13f976553f88c89f",
  "result": {
    "markdown": "\n\n# Econometrics (problems)\n\n\n\n\n\n\n\n**Master coding marathon (2020 Oct)**\n\n**This is part of my Master course: Empirical Corporate Finance and Governance**\n\nBefore we start, load the following packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plm)       \nlibrary(tseries)   \nlibrary(haven)\nlibrary(readxl)\nlibrary(AER)\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n\n\n\n## Problem 1\n\n**1) Using the dataset CRIME2.dta, provide an estimation and a THOROUGH interpretation of the following model:**\n\n\n$$crimes_{i,t}  = β_1+ β_2 Pop_{i,t}+β_3 unem+β_4 officers+γ_i+ε_t$$\n\n\n**Where γ_i = Area fixed effects**\n\n\n**The solution is:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list = ls())\ndata <- read_dta(\"files/CRIME2.DTA\")\ndatapanel <- pdata.frame(data, index=c(\"area\",\"year\"))\nEX_1 <- plm(crimes ~ pop + unem + officers , data=datapanel, model=\"within\")\nsummary(EX_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = crimes ~ pop + unem + officers, data = datapanel, \n    model = \"within\")\n\nBalanced Panel: n = 46, T = 2, N = 92\n\nResiduals:\n    Min.  1st Qu.   Median  3rd Qu.     Max. \n-18940.2  -2275.3      0.0   2275.3  18940.2 \n\nCoefficients:\n           Estimate Std. Error t-value Pr(>|t|)  \npop        0.096297   0.041652  2.3119  0.02564 *\nunem     153.656368 301.509194  0.5096  0.61292  \nofficers  16.864757   9.080762  1.8572  0.07014 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    3007200000\nResidual Sum of Squares: 2437400000\nR-Squared:      0.18947\nAdj. R-Squared: -0.7153\nF-statistic: 3.35062 on 3 and 43 DF, p-value: 0.027546\n```\n:::\n:::\n\n\n**Interpretation:** \n\n- An increase of 1 person in population is associated with an increase of 0.09 points of crime. The significance is at the 3% level.\n- The number of officers is positively associated with crime. The significance is at the 8 % level.\n- The remaining two variables are not significant. \n- R-squared seems ok, around 19%\n\n\n\n\n\n## Problem 2\n\n**2) Repeat exercise 1 using a first difference model.**\n\n**The solution is**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nEX_2 <- plm(crimes ~ pop +unem +officers , data=datapanel, model=\"fd\")\nsummary(EX_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOneway (individual) effect First-Difference Model\n\nCall:\nplm(formula = crimes ~ pop + unem + officers, data = datapanel, \n    model = \"fd\")\n\nBalanced Panel: n = 46, T = 2, N = 92\nObservations used in estimation: 46\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-23327.99  -4808.84   -434.39   4177.11  32626.66 \n\nCoefficients:\n              Estimate Std. Error t-value Pr(>|t|)  \n(Intercept) 6.6076e+03 2.5187e+03  2.6234  0.01208 *\npop         5.7103e-02 4.1825e-02  1.3653  0.17943  \nunem        1.1122e+03 4.6203e+02  2.4072  0.02055 *\nofficers    1.5668e+01 8.5291e+00  1.8370  0.07330 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    5577600000\nResidual Sum of Squares: 4188500000\nR-Squared:      0.24905\nAdj. R-Squared: 0.19541\nF-statistic: 4.64301 on 3 and 42 DF, p-value: 0.00683\n```\n:::\n:::\n\n\n\n**Fundamental interpretation:** \n\n- Now, unemployment is significant. The association is positive. Significance at the 3% level.\n- Pop and Officers are not significant\n- R-squared increases to 25%\n- Notice the number of observations. It is half the number if Exercise 1. This is because Exercise 2 is the first difference. You lose 1 observation per individual.\n\n\n\n\n\n\n\n\n\n## Problem 3\n\n**3)\tUsing the dataset DiD.xlsx, provide an estimation and a THOROUGH interpretation of a difference-in-difference model:**\n\n- Where: \n    - Treated: A and B groups\n    - Control: C to G groups\n    - The exogenous shock occurred in 2010\n    - Covariates: x1, x2 and x3.\n    - All variables are in levels (not logarithms)\n\n**The solution is:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list = ls())\n\ndataDiD  <- read_excel(\"files/DiD.xlsx\")\n\n# Creating a dummy (binary) variable to indicate time (post and before treatment)\ndataDiD$time  <- as.numeric(dataDiD$year >= 2010)\n\n# Creating a dummy to indicate treatment\ndataDiD$treated <- 0\ndataDiD$treated[dataDiD$group == \"A\"] <- 1  \ndataDiD$treated[dataDiD$group == \"B\"] <- 1  \n\n#* Generating the interaction between treated and time\ndataDiD$did = dataDiD$time*dataDiD$treated\n\n# Estimating the DD \ndid11 <- lm(y  ~ time + treated + did + x1 + x2 + x3, data = dataDiD)\nsummary(did11)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ time + treated + did + x1 + x2 + x3, data = dataDiD)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.76559 -0.53483 -0.07086  0.46097  2.93998 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.71417    0.21456   3.329  0.00113 ** \ntime         0.05300    0.20359   0.260  0.79501    \ntreated      1.14398    0.27761   4.121 6.60e-05 ***\ndid          0.27200    0.38088   0.714  0.47639    \nx1           0.35768    0.03506  10.201  < 2e-16 ***\nx2          -0.29309    0.06461  -4.536 1.26e-05 ***\nx3           0.11981    0.04133   2.899  0.00438 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.018 on 133 degrees of freedom\nMultiple R-squared:  0.5372,\tAdjusted R-squared:  0.5164 \nF-statistic: 25.73 on 6 and 133 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n**Fundamental interpretation:** \n\n- The treated group seem to have higher Y than the control group. The variable _treated_ is significant at the 0.01% level.\n- The shock does not seem to affect the treated group. The variable _did_ is not significant.\n- All covariates are significant at the 1% level.\n- Overall, the conclusion is that the shock does not \"work\", since _did_ is not significant.\n\n\n\n\n\n\n## Problem 4 \n\n**Using the dataset FERTIL2.rdata, provide an estimation and a THOROUGH interpretation of the following model by OLS:**\n\n\n$$children = β_1+ β_2 educ+β_3 age+β_4 age^2+μ $$\n\n\n**Additional comments:**\n\n- The variable frsthalf is a dummy marking if the woman was born during the first semester of a given year. Assuming that frsthalf is uncorrelated with the error term of eq. 1, check whether it is a reasonable IV for educ.\n- Estimate the model above, using frsthalf as an IV for educ. Compare the estimations with eq. 1.\n- Provide a comparison between the coefficients of educ in the OLS and the IV models\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list = ls())\nload(\"files/FERTIL2.RData\")\n# OLS Model\niv_1 <- lm(children ~ educ + age + agesq , data=FERTIL2)\nsummary(iv_1)     \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = children ~ educ + age + agesq, data = FERTIL2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8351 -0.7135 -0.0054  0.7141  7.5055 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -4.1383066  0.2405942 -17.200   <2e-16 ***\neduc        -0.0905755  0.0059207 -15.298   <2e-16 ***\nage          0.3324486  0.0165495  20.088   <2e-16 ***\nagesq       -0.0026308  0.0002726  -9.651   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.46 on 4357 degrees of freedom\nMultiple R-squared:  0.5687,\tAdjusted R-squared:  0.5684 \nF-statistic:  1915 on 3 and 4357 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n**Fundamental interpretation:** \n\n- One additional year of education is associated with 0.09 fewer children.\n- Age shows a non-linear relationship with children. The curve is inverted U-shaped\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2SLS estimation  - two-step\n# Fist-stage\niv2_1stage <- lm(educ ~ age + agesq + frsthalf  , data = FERTIL2)\nsummary(iv2_1stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = educ ~ age + agesq + frsthalf, data = FERTIL2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.9599 -2.4941  0.2663  2.2663 14.9934 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.6928643  0.5980686  16.207  < 2e-16 ***\nage         -0.1079504  0.0420402  -2.568   0.0103 *  \nagesq       -0.0005056  0.0006929  -0.730   0.4657    \nfrsthalf    -0.8522854  0.1128296  -7.554 5.12e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.711 on 4357 degrees of freedom\nMultiple R-squared:  0.1077,\tAdjusted R-squared:  0.107 \nF-statistic: 175.2 on 3 and 4357 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Predict Y hat\nY2hat <- fitted(iv2_1stage)\n# Second-stage\niv2_2stage <- lm(children ~ Y2hat + age + agesq, data = FERTIL2)\nsummary(iv2_2stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = children ~ Y2hat + age + agesq, data = FERTIL2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6519 -0.7580 -0.0187  0.7297  7.8906 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3.3878054  0.5503400  -6.156 8.14e-10 ***\nY2hat       -0.1714989  0.0533921  -3.212  0.00133 ** \nage          0.3236052  0.0179310  18.047  < 2e-16 ***\nagesq       -0.0026723  0.0002808  -9.516  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.497 on 4357 degrees of freedom\nMultiple R-squared:  0.5466,\tAdjusted R-squared:  0.5463 \nF-statistic:  1751 on 3 and 4357 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n**Fundamental interpretation:** \n\n- In the first-stage, when women were born during the first semester of a year, they receive less education. The IV seems good.\n- In the second-stage, one additional year of education is associated with 0.17 fewer children. This is a magnitude almost twice higher than the OLS results.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ivreg - one-step estimation\niv_2 <- ivreg(children ~ educ + age + agesq  | age + agesq + frsthalf  , data = FERTIL2)\nsummary(iv_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nivreg(formula = children ~ educ + age + agesq | age + agesq + \n    frsthalf, data = FERTIL2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-6.05272 -0.71481  0.06224  0.76236  7.23693 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3.3878054  0.5481502  -6.180 6.98e-10 ***\neduc        -0.1714989  0.0531796  -3.225  0.00127 ** \nage          0.3236052  0.0178596  18.119  < 2e-16 ***\nagesq       -0.0026723  0.0002797  -9.555  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.491 on 4357 degrees of freedom\nMultiple R-Squared: 0.5502,\tAdjusted R-squared: 0.5499 \nWald test:  1765 on 3 and 4357 DF,  p-value: < 2.2e-16 \n```\n:::\n:::\n\n\n**Important: The results are the same as those obtained in the second-step estimation. However, std. errors are different. This is not a problem here because it does not change the main interpretation. It could be a problem in other cases.** \n\n\n\n\n\n\n## Problem 5\n\n\n**5)\tUsing the dataset RDD.xlsx, provide an estimation and a THOROUGH interpretation of regression discontinuity design.**\n\n- **Hints:**\n    - Check for a discontinuity. \n    - Use 50 observations of each side of the cut. \n    - Check if both sides have similar trends.\n\n**This is the solution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list = ls())\ndataRDD  <- read_excel(\"files/RDD.xlsx\")\n\n# Generate a line graph - Including all observations together\nggplot(dataRDD, aes(x, y))  + \n  geom_point( size=1.25) + \n  labs(y = \"\", x=\"\", title = \"Evolution of Y - Control and Treatment groups\")+\n  theme(plot.title = element_text(color=\"black\", size=25, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 16),\n        axis.text.x = element_text(face=\"bold\", color=\"black\", size = 16),\n        legend.title = element_blank(),\n        legend.key.size = unit(2, \"cm\")) + \n  geom_smooth(method = \"lm\", fill = NA)\n```\n\n::: {.cell-output-display}\n![](3econometrics_problems_files/figure-html/evolution y-1.png){width=672}\n:::\n:::\n\n\n**It seems we have an abrupt discontinuity here. The cut seems to be when X = 100. This graph suggests that, ignoring the discontinuity, the association between X and Y is positive.**\n\n\n**Let's split the observations into two groups now, using X=100 as threshold:** \n\n::: {.cell}\n::: {.cell-output-display}\n![](3econometrics_problems_files/figure-html/rdd-1.png){width=672}\n:::\n:::\n\n\n**It becomes clear that, within each group, the association is negative.**\n\n**Let's look only for the observations close to the cut for a moment:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define cut\ncut <- 100\n# define the bandwidth - using 50 observations each side\nband <- 50\nxlow = cut - band\nxhigh = cut + band\n# subset the data for the bandwidth\ndata <- subset(dataRDD, x > xlow & x <= xhigh, select=c(x, y,  treated))\n# Generate a line graph - two groups\nggplot(data, aes(x, y, group=treated, color = factor(treated)))  + \n  geom_point( size=1.25) + \n  labs(y = \"\", x=\"\", title = \"RDD example\")+\n  theme(plot.title = element_text(color=\"black\", size=25, face=\"bold\"),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey95\"),\n        axis.text.y = element_text(face=\"bold\", color=\"black\", size = 16),\n        axis.text.x = element_text(face=\"bold\", color=\"black\", size = 16),\n        legend.title = element_blank(),\n        legend.key.size = unit(2, \"cm\")) +\n  geom_smooth(method = \"lm\", fill = NA)\n```\n\n::: {.cell-output-display}\n![](3econometrics_problems_files/figure-html/rdd2-1.png){width=672}\n:::\n:::\n\n\n**It seems that, close to the cut, the associations are different: it is positive when X < cut, and negative when X>cut. We may use this finding to define our RDD model below.**\n\n\n**Let's estimate the RDD now:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regression  - not RDD yet (this is the result of the first graph)\nrdd1 <- lm(y  ~ x   , data = data)\nsummary(rdd1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.1020  -7.0202  -0.3039   4.1966  25.8967 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 16.97302    3.55621   4.773 6.35e-06 ***\nx            0.46664    0.03401  13.721  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.817 on 98 degrees of freedom\nMultiple R-squared:  0.6576,\tAdjusted R-squared:  0.6542 \nF-statistic: 188.3 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Generating xhat - Now we are going to the RDD\ndata$xhat <- data$x - cut\n# Generating xhat * treated to allow different inclinations (we will use the findings of the last graph, i.e. that each group has a different trend.)\ndata$xhat_treated <- data$xhat * data$treated\n# RDD Assuming different trends\nrdd2 <- lm(y  ~ xhat + treated  + xhat_treated, data = data)\nsummary(rdd2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ xhat + treated + xhat_treated, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.9477  -3.2607   0.6875   3.2227  12.2004 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  55.83059    1.53681  36.329  < 2e-16 ***\nxhat          0.29431    0.05405   5.445 3.97e-07 ***\ntreated      28.93921    2.20672  13.114  < 2e-16 ***\nxhat_treated -0.51587    0.07644  -6.749 1.13e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.515 on 96 degrees of freedom\nMultiple R-squared:  0.8942,\tAdjusted R-squared:  0.8909 \nF-statistic: 270.3 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n**Interpretation:** \n\n- The treated group (i.e. the group at the right of the cut) shows 29 units of Y more than control group. This is a significant difference, suggesting that the treatment \"works\" \n- The trend is positive when X<cut. The coefficient is 0.29 and is significant.\n- The trend is negative when X>cut. The coefficient is -0.51 and is significant.\n\n",
    "supporting": [
      "3econometrics_problems_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
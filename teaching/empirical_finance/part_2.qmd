---
title: 'Empirical Methods in Finance'
subtitle: 'Part 2'
author: 'Henrique C. Martins'
format:
  revealjs: 
    slide-number: true
    theme: simple
    chalkboard: true
    preview-links: auto
    logo: figs/background8.png
    css: logo.css
    footer: '**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  '
    multiplex: true
    scrollable: true 
title-slide-attributes:
    data-background-color: "#b1cafa"
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
    });
    Reveal.addEventListener('slidechanged', (event) => {
      if (event.indexh === 0) {
        Reveal.configure({ slideNumber: null });
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
      if (event.indexh === 1) { 
        Reveal.configure({ slideNumber: 'c' });
        document.querySelector("div.has-logo > img.slide-logo").style.display = null;
      }
    });
  </script>

---



```{r setup}
#| include: false
#| warning: false


# library(reticulate)
# use_python("C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe")
library(reticulate)
library(Statamarkdown)
#reticulate::py_install("matplotlib")
#reticulate::py_install("seaborn")
#reticulate::py_install("pyfinance")
#reticulate::py_install("xlrd")
#reticulate::py_install("quandl")

```


















# The challenge {.smaller background="#b0aeae"}

## Correlation & Causality {.smaller background="#b0aeae"}


It is very common these days to hear someone say ‚Äú*correlation does not mean causality*.‚Äù 

In essence, that is true.

- *The killer struck during daylight. Had the sun not been out that day, the victim would have been safe.*

. . .

- There is a correlation, but it is clear there is no causation.







## Correlation & Causality  {.smaller background="#b0aeae"}

Sometimes, there is causality even when we do not observe correlation.

*The sailor is adjusting the rudder on a windy day to align the boat with the wind, but the boat is not changing direction.* ([Source: The Mixtape](https://mixtape.scunning.com/01-introduction#do-not-confuse-correlation-with-causality))


![](figs/scottboat.jpg)





::: {.callout-note}

In this example, the sailor is *endogenously* adjusting the course to balance the unobserved wind.

:::







## The challenge  {.smaller background="#b0aeae"}

- I will discuss some issues in using plain OLS models in Finance Research (mainly with panel data).

. . .

- I will avoid the word ‚Äúendogeneity‚Äù as much as I can

. . .

- I will also avoid the word ‚Äúidentification‚Äù because identification does not guarantee causality and vice-versa (Kahn and Whited 2017)

. . .

- The discussion is based on [Atanasov and Black (2016)](https://www.nowpublishers.com/article/Details/CFR-0036)

![](figs/slides1-empiricalissues-paper.png)








## The challenge  {.smaller background="#b0aeae"}

- Imagine that you want to investigate the effect of Governance on Q

    - You may have more covariates explaining Q (omitted  from slides)
  
 $ùë∏_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$

. . . 

 All the issues in the next slides will make it not possible to infer that __changing Gov will _CAUSE_ a change in Q__ 
 
 That is, cannot infer causality
 
![](figs/slides1-empiricalissues-wrong.jpg)








## 1) Reverse causation   {.smaller background="#b0aeae"}

_One source of bias is: reverse causation_

- Perhaps it is Q that causes Gov

- OLS based methods do not tell the difference between these two betas:

$ùëÑ_{i} = Œ± + ùú∑_{i} √ó Gov + Controls + error$

$Gov_{i} = Œ± + ùú∑_{i} √ó Q + Controls + error$

- If one Beta is significant, the other will most likely be significant too

- You need a sound theory!












## 2) Omitted variable bias (OVB)  {.smaller background="#b0aeae"}

_The second source of bias is: OVB_

- Imagine that you do not include an important ‚Äútrue‚Äù predictor of Q

- Let's say, long is:  $ùë∏_{i} = ùú∂_{long} + ùú∑_{long}* gov_{i} + Œ¥ * omitted + error$

- But you estimate short:  $ùë∏_{i} = ùú∂_{short} + ùú∑_{short}* gov_{i} + error$

- $ùú∑_{short}$ will be: 

    - $ùú∑_{short} = ùú∑_{long}$ +  bias

    - $ùú∑_{short} = ùú∑_{long}$ +  relationship between omitted (omitted) and included (Gov) * effect of omitted in long (Œ¥)

        - Where: relationship between omitted (omitted) and included (Gov) is: $Omitted = ùú∂ + œï *gov_{i} + u$

- Thus, OVB is: $ùú∑_{short} ‚Äì ùú∑_{long} = œï * Œ¥$














## 3) Specification error  {.smaller background="#b0aeae"}

_The third source of bias is: Specification error_

- Even if we could perfectly measure gov and all relevant covariates, we would not know for sure the functional form through which each influences q

    - Functional form: linear? Quadratic? Log-log? Semi-log?

- Misspecification of x‚Äôs is similar to OVB








## 4) Signaling   {.smaller background="#b0aeae"}

_The fourth source of bias is: Signaling_

- Perhaps, some individuals are signaling the existence of an X without truly having it:

    - For instance: firms signaling they have good governance without having it

- This is similar to the OVB because you cannot observe the full story









## 5) Simultaneity  {.smaller background="#b0aeae"}

_The fifth source of bias is: Simultaneity_

- Perhaps gov and some other variable x are determined simultaneously

- Perhaps there is bidirectional causation, with q causing gov and gov also causing q 

- In both cases, OLS regression will provide a biased estimate of the effect

- Also, the sign might be wrong










## 6) Heterogeneous effects   {.smaller background="#b0aeae"}

_The sixth source of bias is: Heterogeneous effects_

- Maybe the causal effect of gov on q depends on observed and unobserved firm characteristics:

    - Let's assume that firms seek to maximize q
    - Different firms have different optimal gov
    - Firms know their optimal gov
    - If we observed all factors that affect q, each firm would be at its own optimum and OLS regression would give a non-significant coefficient

- In such case, we may find a positive or negative relationship.

- Neither is the true causal relationship





## 7) Construct validity  {.smaller background="#b0aeae"}

_The seventh source of bias is: Construct validity_

- Some constructs (e.g. Corporate governance) are complex, and sometimes have conflicting mechanisms

- We usually don‚Äôt know for sure what ‚Äúgood‚Äù governance is, for instance

- It is common that we use imperfect proxies

- They may poorly fit the underlying concept







## 8) Measurement error   {.smaller background="#b0aeae"}

_The eighth source of bias is: Measurement error_

- "Classical" random measurement error for the outcome will inflate standard errors but will not lead to biased coefficients. 

    - $y^{*} = y + \sigma_{1}$
    - If you estimante $y^{*} = f(x)$, you have $y + \sigma_{1} = x + \epsilon$ 
    - $y = x + u$ 
        - where $u = \epsilon + \sigma_{1}$ 

- "Classical" random measurement error in x‚Äôs will bias coefficient estimates toward zero

    - $x^{*} = x + \sigma_{2}$
    - Imagine that $x^{*}$ is a bunch of noise
    - It would not explain anything
    - Thus, your results are biased toward zero


<!-- https://web.stanford.edu/class/polisci100a/regress5.pdf  --> 









## 9) Observation bias   {.smaller background="#b0aeae"}

_The ninth source of bias is: Observation bias_

- This is analogous to the Hawthorne effect, in which observed subjects behave differently because they are observed

- Firms which change gov may behave differently because their managers or employees think the change in gov matters, when in fact it has no direct effect










## 10) Interdependent effects   {.smaller background="#b0aeae"}

_The tenth source of bias is: Interdependent effects_

- Imagine that a governance reform that will not affect share prices for a single firm might be effective if several firms adopt

- Conversely, a reform that improves efficiency for a single firm might not improve profitability if adopted widely because the gains will be competed away

- "One swallow doesn't make a summer" 






## 11) Selection bias   {.smaller background="#b0aeae"}

_The eleventh source of bias is: Selection bias_

- If you run a regression with two types of companies

    - High gov (let's say they are the treated group)
    - Low gov (let's say they are the control group)

    
- Without any matching method, these companies are likely not comparable

- Thus, the estimated beta will contain selection bias

- The bias can be either be positive or negative

- It is similar to OVB


  

## 12) Self-Selection  {.smaller background="#b0aeae"}

_The twelfth source of bias is: Self-Selection_

- Self-selection is a type of selection bias

- Usually, firms decide which level of governance they adopt

- There are reasons why firms adopt high governance

    - If observable, you need to control for
    - If unobservable, you have a problem

- It is like they "self-select" into the treatment.

    - Units decide whether they receive the treatment or not

- Your coefficients will be biased.






## 13) Collider Bias (endog. selection bias) {.smaller background="#b0aeae"}


**Let's assume an arbitrary population.**

- Two variables describe the population: IQ and luck. 

- These variables are random and normally distributed.

- Let's say that after you reach a certain level of IQ and Luck, you become successful (i.e., upper-right quadrant).

- Because you are interested in successful people, you only investigate such subsample. 




## 13) Collider Bias (endog. selection bias) {.smaller background="#b0aeae"}

**A representation of the population**

::: panel-tabset

### R
```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
library(data.table)
library(ggplot2)
set.seed(100)
luck <- rnorm(1000, 100, 15)
iq   <- rnorm(1000, 100, 15)
pop <- data.frame(luck, iq)

ggplot(pop, aes(x = iq, y = luck)) + 
      geom_point() +
      labs(title = "The general population")  + 
  theme_minimal()
```



### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(100)

luck = np.random.normal(100, 15, 1000)
iq = np.random.normal(100, 15, 1000)
pop = pd.DataFrame({'luck': luck, 'iq': iq})

sns.set(style="whitegrid")  
plt.figure(figsize=(8, 6))
plt.scatter(pop['iq'], pop['luck'])
plt.title("The general population")
plt.xlabel("IQ")
plt.ylabel("Luck")
plt.show()

```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
set seed 100
set obs 1000
gen luck = rnormal(100, 15)
gen iq = rnormal(100, 15)
twoway (scatter luck iq), title("The general population") 
quietly graph export figs/collider1.svg, replace
```       

![](figs/collider1.svg)

:::





## 13) Collider Bias (endog. selection bias) {.smaller background="#b0aeae"}

::: {.callout-important}
**Analyzing only successful people will suggest a negative correlation between luck and IQ.**

- "Success" is a collider in this example. It "collides" with luck and IQ.
::: 

::: panel-tabset

### R
```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
library(data.table)
library(ggplot2)
set.seed(100)
luck <- rnorm(1000, 100, 15)
iq   <- rnorm(1000, 100, 15)
pop <- data.frame(luck, iq)

pop$comb <- pop$luck + pop$iq 
successfull <- pop[pop$comb > 240, ] 

ggplot() + 
  geom_point(data = pop, aes(x = iq, y = luck)) +  
  geom_point(data = successfull, aes(x = iq, y = luck), color = "red") +  
  labs(title = "The general population & successful subpopulation") + 
  theme_minimal()

```



### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(100)

luck = np.random.normal(100, 15, 1000)
iq = np.random.normal(100, 15, 1000)
pop = pd.DataFrame({'luck': luck, 'iq': iq})

pop['comb'] = pop['luck'] + pop['iq']

successful = pop[pop['comb'] > 240]

sns.set(style="whitegrid")  # Minimalistic theme similar to theme_minimal in ggplot2
plt.figure(figsize=(8, 6))
plt.scatter(pop['iq'], pop['luck'], label="General Population", alpha=0.5)
plt.scatter(successful['iq'], successful['luck'], color='red', label="Successful Subpopulation", alpha=0.7)
plt.title("The general population & successful subpopulation")
plt.xlabel("IQ")
plt.ylabel("Luck")
plt.legend()
plt.show()

```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"

set seed 100
set obs 1000
gen luck = rnormal(100, 15)
gen iq = rnormal(100, 15)
gen comb = luck + iq
gen successful = comb > 240
twoway (scatter luck iq if successful == 0)  (scatter luck iq if successful == 1, mcolor(red)) , title("The general population & successful subpopulation") 

quietly graph export figs/collider2.svg, replace
```       

![](figs/collider2.svg)

:::



















## Conclus√£o  {.smaller background="#b0aeae"}

**Pesquisa quantitativa tem a parte _quanti (m√©todos, modelos, etc.)_...**

**... Mas talvez a parte mais importante seja o desenho da pesquisa (design emp√≠rico)!**


















## Preocupa√ß√µes recentes em pesquisa   {.smaller background="#b0aeae"}

**P-Hacking**

![](figs/slides4-phacking.png) 

Artigo original [aqui](https://doi.org/10.1111/jofi.12530).










## Preocupa√ß√µes recentes em pesquisa  {.smaller background="#b0aeae"}

**Publication bias**

![](figs/slides4-Harvey-2017.png) 


Artigo original [aqui](https://doi.org/10.1111/jofi.12530).







 

## Preocupa√ß√µes recentes em pesquisa   {.smaller background="#b0aeae"}

**Crise de replica√ß√£o**


![](figs/slides4-aguinis.png) 


Artigo original [aqui](https://link.springer.com/article/10.1057/s41267-017-0081-0).





## Some fun stuff  {.smaller background="#b0aeae"}

![](figs/selection bias.png) 


## Some fun stuff  {.smaller background="#b0aeae"}

![](figs/fig1.jpg) 





## Some fun stuff  {.smaller background="#b0aeae"}


![](figs/hypothesis2.png) 






## Some fun stuff {.smaller background="#b0aeae"}


![](figs/confounding variables.png) 









## Some fun stuff {.smaller background="#b0aeae"}

![](figs/proxy variable.png) 

















## üôã‚Äç‚ôÇÔ∏è **Any Questions?**{ .smaller  background="#fdf6e3"}

::: columns
::: {.column width="50%"}
### Thank You!

![](figs/qa2.png){width="110%" style="box-shadow: none;"}

:::

::: {.column width="50%"}
<div style="text-align:right;">
  <img src="figs/avatar.jpg" width="120px" style="border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,.25);" />
</div>

### **Henrique C. Martins**

- üåê [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)  
- üíº [LinkedIn](https://www.linkedin.com/in/henriquecastror/)  
- üß† [Google Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)  
- üìÑ [Lattes CV](http://lattes.cnpq.br/6076997472159785)  
- üè† [Personal Website](https://henriquemartins.net/)  
:::
:::


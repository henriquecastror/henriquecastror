<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.549">

  <meta name="author" content="Henrique C. Martins">
  <title>Henrique Castro Martins - Empirical Methods in Finance</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="logo.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-771J5563G0"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-771J5563G0', { 'anonymize_ip': true});
  </script>
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta name="twitter:title" content="Henrique Castro Martins - Empirical Methods in Finance">
<meta name="twitter:description" content="Part 3">
<meta name="twitter:card" content="summary">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#b1cafa" class="quarto-title-block center">
  <h1 class="title">Empirical Methods in Finance</h1>
  <p class="subtitle">Part 3</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Henrique C. Martins 
</div>
</div>
</div>

</section>
<section>
<section id="conterfactuals" class="title-slide slide level1 smaller center" data-background="#b3eafc">
<h1>Conterfactuals</h1>

</section>
<section id="conterfactuals-1" class="slide level2 smaller" data-background="#b3eafc">
<h2>Conterfactuals</h2>
<ul>
<li><p>Imagine that John and Mary are moving to the north of Canada.</p></li>
<li><p>John has a history of respiratory disease and decide to buy insurance.</p></li>
<li><p>Mary does not have a history of respiratory disease and decide not to buy insurance.</p></li>
<li><p>What is the causal effect of buying insurance?</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th>Default</th>
<th style="text-align: left;">John</th>
<th style="text-align: right;">Mary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>State of insurance</td>
<td style="text-align: left;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td>Situation without insurance</td>
<td style="text-align: left;"><code>n.o.</code></td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Situation with insurance</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;"><code>n.o.</code></td>
</tr>
<tr class="even">
<td>Observed</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Effect</td>
<td style="text-align: left;">?</td>
<td style="text-align: right;">?</td>
</tr>
</tbody>
</table>
<p><a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source: Mastering Metrics</a></p>
</section>
<section id="conterfactuals-2" class="slide level2 smaller" data-background="#b3eafc">
<h2>Conterfactuals</h2>
<p><strong>Naïve calculation: comparing John com Mary</strong></p>
<p><span class="math display">\[Y_{john} - Y_{Mary} = 4 - 5 = -1\]</span></p>
<p>Conclusion: buying insurance has a negative effect on health.</p>
<div class="fragment">
<p><strong>This is wrong!</strong></p>
<p><a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source: Mastering Metrics</a></p>
</div>
</section>
<section id="conterfactuals-3" class="slide level2 smaller" data-background="#b3eafc">
<h2>Conterfactuals</h2>
<table>
<thead>
<tr class="header">
<th>Default</th>
<th style="text-align: left;">John</th>
<th style="text-align: right;">Mary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>State of insurance</td>
<td style="text-align: left;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td>Situation without insurance</td>
<td style="text-align: left;"><code>3</code></td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Situation with insurance</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;"><code>5</code></td>
</tr>
<tr class="even">
<td>Observed</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Effect</td>
<td style="text-align: left;">?</td>
<td style="text-align: right;">?</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5\]</span></p>
<p><strong>Conclusion:</strong> buying insurance has a positive effect of 1 in John’s health and average effect of 0.5 in the sample’s health (i.e.&nbsp;averages conditional on insurance status).</p>
<p><a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source: Mastering Metrics</a></p>
</section></section>
<section>
<section id="regressions" class="title-slide slide level1 smaller center" data-background="#dfe3f7">
<h1>Regressions</h1>

</section>
<section id="regression-source-mastering-metrics" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Regression <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source: Mastering Metrics</a></h2>
<p><strong>Let’s see how a regression could solve the problem.</strong> Imagine that you have the following data on students’ application. (<strong>Decisions in bold</strong>)</p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Student</th>
<th>Private</th>
<th>Private</th>
<th>Private</th>
<th>Public</th>
<th>Public</th>
<th>Public</th>
<th>Earnings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>Ivy</td>
<td>Leafy</td>
<td>Smart</td>
<td>State</td>
<td>Tall</td>
<td>Altered</td>
<td>110,000</td>
</tr>
<tr class="even">
<td>1</td>
<td></td>
<td>Reject</td>
<td><strong>Admit</strong></td>
<td></td>
<td>Admit</td>
<td></td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>2</td>
<td></td>
<td>Reject</td>
<td><strong>Admit</strong></td>
<td></td>
<td>Admit</td>
<td></td>
<td>100,000</td>
</tr>
<tr class="even">
<td>3</td>
<td></td>
<td>Reject</td>
<td>Admit</td>
<td></td>
<td><strong>Admit</strong></td>
<td></td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>4</td>
<td><strong>Admit</strong></td>
<td></td>
<td>Admit</td>
<td></td>
<td>Admit</td>
<td>Admit</td>
<td>60,000</td>
</tr>
<tr class="even">
<td>5</td>
<td>Admit</td>
<td></td>
<td>Admit</td>
<td></td>
<td>Admit</td>
<td><strong>Admit</strong></td>
<td>30,000</td>
</tr>
<tr class="odd">
<td>6</td>
<td></td>
<td><strong>Admit</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>115,000</td>
</tr>
<tr class="even">
<td>7</td>
<td></td>
<td><strong>Admit</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>75,000</td>
</tr>
<tr class="odd">
<td>8</td>
<td>Reject</td>
<td></td>
<td></td>
<td><strong>Admit</strong></td>
<td>Admit</td>
<td></td>
<td>90,000</td>
</tr>
<tr class="even">
<td>9</td>
<td>Reject</td>
<td></td>
<td></td>
<td>Admit</td>
<td><strong>Admit</strong></td>
<td></td>
<td>60,000</td>
</tr>
</tbody>
</table>
</section>
<section id="regression-source-mastering-metrics-1" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Regression <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source: Mastering Metrics</a></h2>
<p><strong>We can see from the table that:</strong></p>
<ul>
<li><p>Some students earn high salary, in both situations</p></li>
<li><p>Some students earn low salary, in both situations</p></li>
<li><p>There are clusters of students that applied for the same universities</p>
<ul>
<li>How likely are they to be similar? Can we benefit from the fact they believe they are similar?</li>
</ul></li>
</ul>
<div class="fragment">
<ul>
<li><p>If we compare earnings from the first three individuals:</p>
<ul>
<li>((110 + 100)/ 2 - 11000) = -5.000</li>
</ul></li>
<li><p>If we compare earnings from individuals 4 and 5:</p>
<ul>
<li>(60 - 30) = 30.000</li>
</ul></li>
<li><p>The average is:</p>
<ul>
<li>25.000/2 = 12.500</li>
</ul></li>
</ul>
</div>
</section>
<section id="regression-source" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Regression <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p>Let’s create a dataframe to run regressions with the previous student’s data.</p>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">R</a></li><li><a href="#tabset-1-2">Python</a></li><li><a href="#tabset-1-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a><span class="co"># Create the data frame</span></span>
<span id="cb1-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-3"><a></a>  <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>,</span>
<span id="cb1-4"><a></a>  <span class="at">earnings =</span> <span class="fu">c</span>(<span class="dv">110000</span>, <span class="dv">100000</span>, <span class="dv">110000</span>, <span class="dv">60000</span>, <span class="dv">30000</span>, <span class="dv">115000</span>, <span class="dv">75000</span>, <span class="dv">90000</span>, <span class="dv">60000</span>),</span>
<span id="cb1-5"><a></a>  <span class="at">school =</span> <span class="fu">c</span>(<span class="st">"private"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"private"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"public"</span>),</span>
<span id="cb1-6"><a></a>  <span class="at">private =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb1-7"><a></a>  <span class="at">group =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb1-8"><a></a>)</span>
<span id="cb1-9"><a></a><span class="fu">print</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  id earnings  school private group
1  1   110000 private       1     1
2  2   100000 private       1     1
3  3   110000  public       0     1
4  4    60000 private       1     2
5  5    30000  public       0     2
6  6   115000 private       1     3
7  7    75000 private       1     3
8  8    90000  public       0     4
9  9    60000  public       0     4</code></pre>
</div>
</div>
</div>
<div id="tabset-1-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb3-3"><a></a>    <span class="st">'id'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>),</span>
<span id="cb3-4"><a></a>    <span class="st">'earnings'</span>: [<span class="dv">110000</span>, <span class="dv">100000</span>, <span class="dv">110000</span>, <span class="dv">60000</span>, <span class="dv">30000</span>, <span class="dv">115000</span>, <span class="dv">75000</span>, <span class="dv">90000</span>, <span class="dv">60000</span>],</span>
<span id="cb3-5"><a></a>    <span class="st">'school'</span>: [<span class="st">"private"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"private"</span>, <span class="st">"private"</span>, <span class="st">"public"</span>, <span class="st">"public"</span>],</span>
<span id="cb3-6"><a></a>    <span class="st">'private'</span>: [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb3-7"><a></a>    <span class="st">'group'</span>: [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>]</span>
<span id="cb3-8"><a></a>})</span>
<span id="cb3-9"><a></a><span class="bu">print</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   id  earnings   school  private  group
0   1    110000  private        1      1
1   2    100000  private        1      1
2   3    110000   public        0      1
3   4     60000  private        1      2
4   5     30000   public        0      2
5   6    115000  private        1      3
6   7     75000  private        1      3
7   8     90000   public        0      4
8   9     60000   public        0      4</code></pre>
</div>
</div>
</div>
<div id="tabset-1-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb5-1"><a></a>input id earnings str7 school <span class="kw">private</span> <span class="fu">group</span></span>
<span id="cb5-2"><a></a>1 110000 <span class="st">"private"</span> 1 1</span>
<span id="cb5-3"><a></a>2 100000 <span class="st">"private"</span> 1 1</span>
<span id="cb5-4"><a></a>3 110000 <span class="st">"public"</span> 0 1</span>
<span id="cb5-5"><a></a>4 60000 <span class="st">"private"</span> 1 2</span>
<span id="cb5-6"><a></a>5 30000 <span class="st">"public"</span> 0 2</span>
<span id="cb5-7"><a></a>6 115000 <span class="st">"private"</span> 1 3</span>
<span id="cb5-8"><a></a>7 75000 <span class="st">"private"</span> 1 3</span>
<span id="cb5-9"><a></a>8 90000 <span class="st">"public"</span> 0 4</span>
<span id="cb5-10"><a></a>9 60000 <span class="st">"public"</span> 0 4</span>
<span id="cb5-11"><a></a><span class="kw">end</span></span>
<span id="cb5-12"><a></a><span class="ot">list</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>            id   earnings     school    private      group
  1. 1 110000 "private" 1 1
  2. 2 100000 "private" 1 1
  3. 3 110000 "public" 0 1
  4. 4 60000 "private" 1 2
  5. 5 30000 "public" 0 2
  6. 6 115000 "private" 1 3
  7. 7 75000 "private" 1 3
  8. 8 90000 "public" 0 4
  9. 9 60000 "public" 0 4
 10. end

     +-------------------------------------------+
     | id   earnings    school   private   group |
     |-------------------------------------------|
  1. |  1     110000   private         1       1 |
  2. |  2     100000   private         1       1 |
  3. |  3     110000    public         0       1 |
  4. |  4      60000   private         1       2 |
  5. |  5      30000    public         0       2 |
     |-------------------------------------------|
  6. |  6     115000   private         1       3 |
  7. |  7      75000   private         1       3 |
  8. |  8      90000    public         0       4 |
  9. |  9      60000    public         0       4 |
     +-------------------------------------------+</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="naive-regression-all-students-source" class="slide level2 smaller" data-background="#dfe3f7">
<h2>“Naive” regression all students <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \epsilon\]</span> <strong>What is the benefit of private education here?</strong></p>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">R</a></li><li><a href="#tabset-2-2">Python</a></li><li><a href="#tabset-2-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a><span class="co"># Create the data frame</span></span>
<span id="cb7-2"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(earnings <span class="sc">~</span> private, <span class="at">data =</span> data)</span>
<span id="cb7-3"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = earnings ~ private, data = data)

Residuals:
   Min     1Q Median     3Q    Max 
-42500 -17000   8000  18000  37500 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)    72500      14522   4.992  0.00158 **
private        19500      19484   1.001  0.35023   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 29040 on 7 degrees of freedom
Multiple R-squared:  0.1252,    Adjusted R-squared:  0.0002116 
F-statistic: 1.002 on 1 and 7 DF,  p-value: 0.3502</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a><span class="co">#pip install numpy scikit-learn statsmodels</span></span>
<span id="cb9-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb9-3"><a></a>X <span class="op">=</span> sm.add_constant(data[<span class="st">'private'</span>])  </span>
<span id="cb9-4"><a></a>y <span class="op">=</span> data[<span class="st">'earnings'</span>]</span>
<span id="cb9-5"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb9-6"><a></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.125
Model:                            OLS   Adj. R-squared:                  0.000
Method:                 Least Squares   F-statistic:                     1.002
Date:                qua, 11 set 2024   Prob (F-statistic):              0.350
Time:                        16:17:18   Log-Likelihood:                -104.13
No. Observations:                   9   AIC:                             212.3
Df Residuals:                       7   BIC:                             212.7
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        7.25e+04   1.45e+04      4.992      0.002    3.82e+04    1.07e+05
private      1.95e+04   1.95e+04      1.001      0.350   -2.66e+04    6.56e+04
==============================================================================
Omnibus:                        1.011   Durbin-Watson:                   2.352
Prob(Omnibus):                  0.603   Jarque-Bera (JB):                0.666
Skew:                          -0.263   Prob(JB):                        0.717
Kurtosis:                       1.776   Cond. No.                         2.77
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-2-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb11-1"><a></a>quiet input id earnings str7 school <span class="kw">private</span> <span class="fu">group</span></span>
<span id="cb11-2"><a></a>1 110000 <span class="st">"private"</span> 1 1</span>
<span id="cb11-3"><a></a>2 100000 <span class="st">"private"</span> 1 1</span>
<span id="cb11-4"><a></a>3 110000 <span class="st">"public"</span> 0 1</span>
<span id="cb11-5"><a></a>4 60000 <span class="st">"private"</span> 1 2</span>
<span id="cb11-6"><a></a>5 30000 <span class="st">"public"</span> 0 2</span>
<span id="cb11-7"><a></a>6 115000 <span class="st">"private"</span> 1 3</span>
<span id="cb11-8"><a></a>7 75000 <span class="st">"private"</span> 1 3</span>
<span id="cb11-9"><a></a>8 90000 <span class="st">"public"</span> 0 4</span>
<span id="cb11-10"><a></a>9 60000 <span class="st">"public"</span> 0 4</span>
<span id="cb11-11"><a></a><span class="kw">end</span></span>
<span id="cb11-12"><a></a></span>
<span id="cb11-13"><a></a><span class="kw">reg</span> earnings <span class="kw">private</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      Source |       SS           df       MS      Number of obs   =         9
-------------+----------------------------------   F(1, 7)         =      1.00
       Model |   845000000         1   845000000   Prob &gt; F        =    0.3502
    Residual |  5.9050e+09         7   843571429   R-squared       =    0.1252
-------------+----------------------------------   Adj R-squared   =    0.0002
       Total |  6.7500e+09         8   843750000   Root MSE        =     29044

------------------------------------------------------------------------------
    earnings | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     private |      19500   19483.51     1.00   0.350    -26571.18    65571.18
       _cons |      72500   14522.15     4.99   0.002     38160.57    106839.4
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="naive-regression-all-students-source-1" class="slide level2 smaller" data-background="#dfe3f7">
<h2>“Naive” regression all students <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \epsilon\]</span> <strong>What is the benefit of private education here?</strong></p>
<p>The coefficient of <code>private</code> is 19500, meaning that those that have private education earn 19500 more.</p>
<div class="fragment">
<p>The problem with this design is that 1) we are including all students, even those that do not bring any “information”, and 2) we are not controlling for the differences in students’ profiles.</p>
<p>Let’s fix the first problem first.</p>
<p><strong>What students should we not include in the model?</strong></p>
</div>
</section>
<section id="students-id5-source" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Students id&lt;=5 <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \epsilon \;,\; if\; i &lt;=5\]</span> <strong>What is the benefit of private education here?</strong></p>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">R</a></li><li><a href="#tabset-3-2">Python</a></li><li><a href="#tabset-3-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(earnings <span class="sc">~</span> private , <span class="at">data =</span> <span class="fu">subset</span>(data,id<span class="sc">&lt;=</span><span class="dv">5</span>))</span>
<span id="cb13-2"><a></a><span class="fu">summary</span>(model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = earnings ~ private, data = subset(data, id &lt;= 5))

Residuals:
     1      2      3      4      5 
 20000  10000  40000 -30000 -40000 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)    70000      27689   2.528   0.0856 .
private        20000      35746   0.560   0.6149  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 39160 on 3 degrees of freedom
Multiple R-squared:  0.09449,   Adjusted R-squared:  -0.2073 
F-statistic: 0.313 on 1 and 3 DF,  p-value: 0.6149</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="co">#pip install numpy scikit-learn statsmodels</span></span>
<span id="cb15-2"><a></a></span>
<span id="cb15-3"><a></a>subset_data <span class="op">=</span> data[data[<span class="st">'id'</span>] <span class="op">&lt;=</span> <span class="dv">5</span>]</span>
<span id="cb15-4"><a></a>X <span class="op">=</span> sm.add_constant(subset_data[<span class="st">'private'</span>]) </span>
<span id="cb15-5"><a></a>y <span class="op">=</span> subset_data[<span class="st">'earnings'</span>]</span>
<span id="cb15-6"><a></a>model2 <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb15-7"><a></a><span class="bu">print</span>(model2.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.094
Model:                            OLS   Adj. R-squared:                 -0.207
Method:                 Least Squares   F-statistic:                    0.3130
Date:                qua, 11 set 2024   Prob (F-statistic):              0.615
Time:                        16:17:20   Log-Likelihood:                -58.694
No. Observations:                   5   AIC:                             121.4
Df Residuals:                       3   BIC:                             120.6
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const           7e+04   2.77e+04      2.528      0.086   -1.81e+04    1.58e+05
private         2e+04   3.57e+04      0.560      0.615   -9.38e+04    1.34e+05
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   1.304
Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.520
Skew:                          -0.129   Prob(JB):                        0.771
Kurtosis:                       1.441   Cond. No.                         2.92
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-3-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb17-1"><a></a>quiet input id earnings str7 school <span class="kw">private</span> <span class="fu">group</span></span>
<span id="cb17-2"><a></a>1 110000 <span class="st">"private"</span> 1 1</span>
<span id="cb17-3"><a></a>2 100000 <span class="st">"private"</span> 1 1</span>
<span id="cb17-4"><a></a>3 110000 <span class="st">"public"</span> 0 1</span>
<span id="cb17-5"><a></a>4 60000 <span class="st">"private"</span> 1 2</span>
<span id="cb17-6"><a></a>5 30000 <span class="st">"public"</span> 0 2</span>
<span id="cb17-7"><a></a>6 115000 <span class="st">"private"</span> 1 3</span>
<span id="cb17-8"><a></a>7 75000 <span class="st">"private"</span> 1 3</span>
<span id="cb17-9"><a></a>8 90000 <span class="st">"public"</span> 0 4</span>
<span id="cb17-10"><a></a>9 60000 <span class="st">"public"</span> 0 4</span>
<span id="cb17-11"><a></a><span class="kw">end</span></span>
<span id="cb17-12"><a></a><span class="kw">reg</span> earnings <span class="kw">private</span> <span class="kw">if</span> id&lt;=5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      Source |       SS           df       MS      Number of obs   =         5
-------------+----------------------------------   F(1, 3)         =      0.31
       Model |   480000000         1   480000000   Prob &gt; F        =    0.6149
    Residual |  4.6000e+09         3  1.5333e+09   R-squared       =    0.0945
-------------+----------------------------------   Adj R-squared   =   -0.2073
       Total |  5.0800e+09         4  1.2700e+09   Root MSE        =     39158

------------------------------------------------------------------------------
    earnings | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     private |      20000   35746.02     0.56   0.615    -93759.78    133759.8
       _cons |      70000   27688.75     2.53   0.086    -18117.95    158117.9
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="students-id5-source-1" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Students id&lt;=5 <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \epsilon \;,\; if\; i &lt;=5\]</span> <strong>What is the benefit of private education here?</strong></p>
<p>Students 6 and 7 only applied to Private, while students 8 and 9 did not really had a choice. So we should exclude them.</p>
<div class="fragment">
<p>The benefit of private is now 20000.</p>
<p>The coefficient did not change much, but the design improved partially.</p>
</div>
<div class="fragment">
<p>We still have an uncontrolled “heterogeneity” in the groups of students. <strong>Students 1 to 3 seem to earn more no matter their decisions</strong>.</p>
</div>
</section>
<section id="apples-to-apples-source" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Apples-to-Apples <a href="https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845">Source</a></h2>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group+ \epsilon \;,\; if\; i &lt;=5\]</span> <strong>This is the best we can do.</strong></p>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">R</a></li><li><a href="#tabset-4-2">Python</a></li><li><a href="#tabset-4-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a></a>data<span class="sc">$</span>dummy <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(data<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb19-2"><a></a>data<span class="sc">$</span>dummy[data<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb19-3"><a></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(earnings <span class="sc">~</span> private <span class="sc">+</span> dummy, <span class="at">data =</span> <span class="fu">subset</span>(data,id<span class="sc">&lt;=</span><span class="dv">5</span>))</span>
<span id="cb19-4"><a></a><span class="fu">summary</span>(model3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = earnings ~ private + dummy, data = subset(data, 
    id &lt;= 5))

Residuals:
         1          2          3          4          5 
 1.182e-11 -1.000e+04  1.000e+04  1.000e+04 -1.000e+04 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)    40000      11952   3.347   0.0789 .
private        10000      13093   0.764   0.5248  
dummy          60000      13093   4.583   0.0445 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 14140 on 2 degrees of freedom
Multiple R-squared:  0.9213,    Adjusted R-squared:  0.8425 
F-statistic:  11.7 on 2 and 2 DF,  p-value: 0.07874</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a><span class="co">#pip install numpy scikit-learn statsmodels</span></span>
<span id="cb21-2"><a></a></span>
<span id="cb21-3"><a></a>data[<span class="st">'dummy'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-4"><a></a>data.loc[data[<span class="st">'group'</span>] <span class="op">==</span> <span class="dv">2</span>, <span class="st">'dummy'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-5"><a></a>subset_data <span class="op">=</span> data[data[<span class="st">'id'</span>] <span class="op">&lt;=</span> <span class="dv">5</span>]</span>
<span id="cb21-6"><a></a>X <span class="op">=</span> sm.add_constant(subset_data[[<span class="st">'private'</span>, <span class="st">'dummy'</span>]])</span>
<span id="cb21-7"><a></a>y <span class="op">=</span> subset_data[<span class="st">'earnings'</span>]</span>
<span id="cb21-8"><a></a>model3 <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb21-9"><a></a><span class="bu">print</span>(model3.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.921
Model:                            OLS   Adj. R-squared:                  0.843
Method:                 Least Squares   F-statistic:                     11.70
Date:                qua, 11 set 2024   Prob (F-statistic):             0.0787
Time:                        16:17:23   Log-Likelihood:                -52.589
No. Observations:                   5   AIC:                             111.2
Df Residuals:                       2   BIC:                             110.0
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const           4e+04    1.2e+04      3.347      0.079   -1.14e+04    9.14e+04
private         1e+04   1.31e+04      0.764      0.525   -4.63e+04    6.63e+04
dummy           6e+04   1.31e+04      4.583      0.044    3665.052    1.16e+05
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   2.250
Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.638
Skew:                           0.000   Prob(JB):                        0.727
Kurtosis:                       1.250   Cond. No.                         3.49
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-4-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb23-1"><a></a>quiet input id earnings str7 school <span class="kw">private</span> <span class="fu">group</span></span>
<span id="cb23-2"><a></a>1 110000 <span class="st">"private"</span> 1 1</span>
<span id="cb23-3"><a></a>2 100000 <span class="st">"private"</span> 1 1</span>
<span id="cb23-4"><a></a>3 110000 <span class="st">"public"</span> 0 1</span>
<span id="cb23-5"><a></a>4 60000 <span class="st">"private"</span> 1 2</span>
<span id="cb23-6"><a></a>5 30000 <span class="st">"public"</span> 0 2</span>
<span id="cb23-7"><a></a>6 115000 <span class="st">"private"</span> 1 3</span>
<span id="cb23-8"><a></a>7 75000 <span class="st">"private"</span> 1 3</span>
<span id="cb23-9"><a></a>8 90000 <span class="st">"public"</span> 0 4</span>
<span id="cb23-10"><a></a>9 60000 <span class="st">"public"</span> 0 4</span>
<span id="cb23-11"><a></a><span class="kw">end</span></span>
<span id="cb23-12"><a></a><span class="kw">gen</span>     dummy = 1 <span class="kw">if</span> <span class="fu">group</span> == 1</span>
<span id="cb23-13"><a></a><span class="kw">replace</span> dummy = 0 <span class="kw">if</span> <span class="fu">group</span> == 2</span>
<span id="cb23-14"><a></a><span class="kw">reg</span> earnings <span class="kw">private</span> dummy <span class="kw">if</span> id&lt;=5 </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(6 missing values generated)

(2 real changes made)

      Source |       SS           df       MS      Number of obs   =         5
-------------+----------------------------------   F(2, 2)         =     11.70
       Model |  4.6800e+09         2  2.3400e+09   Prob &gt; F        =    0.0787
    Residual |   400000000         2   200000000   R-squared       =    0.9213
-------------+----------------------------------   Adj R-squared   =    0.8425
       Total |  5.0800e+09         4  1.2700e+09   Root MSE        =     14142

------------------------------------------------------------------------------
    earnings | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     private |      10000   13093.07     0.76   0.525    -46334.95    66334.95
       dummy |      60000   13093.07     4.58   0.044     3665.052    116334.9
       _cons |      40000   11952.29     3.35   0.079    -11426.54    91426.54
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="regression" class="slide level2 smaller" data-background="#dfe3f7">
<h2>Regression</h2>
<p>The previous regression assumes that students 1 to 3 are different that students 4 and 5.</p>
<p>We will find many instances like that in empirical research. E.g., industry.</p>
<div class="fragment">
<p>The private school coefficient, in this case 10,000, implies a private-public earnings differential of this value.</p>
</div>
<div class="fragment">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>The Y above is used in monetary values.</p>
<p>Using a logged y, ln(Y) or ln(earnings), allows estimates to be interpreted as a percent change.</p>
<p>For instance if <span class="math inline">\(\beta=0.05\)</span>, it means that the earnings differential is 5% for those studying in private schools (conditional on the controls included in the model).</p>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="ovb-again" class="title-slide slide level1 smaller center" data-background="#f5caae">
<h1>OVB again</h1>

</section>
<section id="ovb-again-1" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<p>Regression is a way to make other things equal (ceteris paribus), but equality is generated only for variables included in the model as controls on the right-hand sided of the model.</p>
<p>Failure to include enough controls of the right controls still leave us with selection bias.</p>
<p>The regression version of the selection bias generated by the inadequate controls is called <strong>Omitted Variable Bias (OVB)</strong>.</p>
<p>The inclusion of a control that should not be included is called “<strong>Bad Controls</strong>” problem.</p>
</section>
<section id="ovb-again-2" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<p><strong>How could we calculate the OVB in this example?</strong></p>
<p><span class="math display">\[earnings_i = 70.000 + 20.000\times Private_i  \epsilon \]</span></p>
<p><span class="math display">\[earnings_i = 40.000 + 10.000 \times Private_i + 60.000 \times Group+ \epsilon\]</span></p>
<ul>
<li><span class="math inline">\(\beta\)</span> (1st regression) - <span class="math inline">\(\beta\)</span> (second regression).</li>
<li>The OVB here is 20.000 - 10.000 = 10.000.</li>
<li>Meaning that the <span class="math inline">\(\beta\)</span> (1st regression) is 10.000 higher than what it should be.</li>
</ul>
</section>
<section id="ovb-again-3" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<p><strong>How could we calculate the OVB in this example?</strong></p>
<p>We could calculate the bias by estimating:</p>
<p><span class="math display">\[Private=\alpha + \beta_{omitted} \times Group + \epsilon\]</span></p>
<p>Then,</p>
<p><span class="math display">\[\beta_{omitted} \times \beta_{missing} = 0.1667 * 60.000 = 10.000\]</span></p>
<p>The OVB is 10.000, meaning that the first model (the one with the omitted variable) estimates a Beta that is 10.000 higher than it should be.</p>
</section>
<section id="ovb-again-4" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-5-1">R</a></li><li><a href="#tabset-5-2">Python</a></li><li><a href="#tabset-5-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a></a>model4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(private <span class="sc">~</span> dummy , <span class="at">data =</span> <span class="fu">subset</span>(data,id<span class="sc">&lt;=</span><span class="dv">5</span>))</span>
<span id="cb25-2"><a></a><span class="fu">summary</span>(model4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = private ~ dummy, data = subset(data, id &lt;= 5))

Residuals:
      1       2       3       4       5 
 0.3333  0.3333 -0.6667  0.5000 -0.5000 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)   0.5000     0.4410   1.134    0.339
dummy         0.1667     0.5693   0.293    0.789

Residual standard error: 0.6236 on 3 degrees of freedom
Multiple R-squared:  0.02778,   Adjusted R-squared:  -0.2963 
F-statistic: 0.08571 on 1 and 3 DF,  p-value: 0.7888</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a></a>matrix2<span class="ot">&lt;-</span> <span class="fu">summary</span>(model4)<span class="sc">$</span>coefficients</span>
<span id="cb27-2"><a></a><span class="fu">sum</span>(<span class="fl">0.1667</span> <span class="sc">*</span> <span class="dv">60000</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10002</code></pre>
</div>
</div>
</div>
<div id="tabset-5-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a>subset_data <span class="op">=</span> data[data[<span class="st">'id'</span>] <span class="op">&lt;=</span> <span class="dv">5</span>]</span>
<span id="cb29-2"><a></a>model4 <span class="op">=</span> sm.OLS(subset_data[<span class="st">'private'</span>], sm.add_constant(subset_data[[<span class="st">'dummy'</span>]])).fit()</span>
<span id="cb29-3"><a></a><span class="bu">print</span>(model4.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                private   R-squared:                       0.028
Model:                            OLS   Adj. R-squared:                 -0.296
Method:                 Least Squares   F-statistic:                   0.08571
Date:                qua, 11 set 2024   Prob (F-statistic):              0.789
Time:                        16:17:25   Log-Likelihood:                -3.4565
No. Observations:                   5   AIC:                             10.91
Df Residuals:                       3   BIC:                             10.13
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.5000      0.441      1.134      0.339      -0.903       1.903
dummy          0.1667      0.569      0.293      0.789      -1.645       1.978
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   2.881
Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.749
Skew:                          -0.394   Prob(JB):                        0.688
Kurtosis:                       1.276   Cond. No.                         2.92
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a>bias <span class="op">=</span> <span class="fl">0.1667</span> <span class="op">*</span> <span class="dv">60000</span></span>
<span id="cb31-2"><a></a><span class="bu">print</span>(bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10002.0</code></pre>
</div>
</div>
</div>
<div id="tabset-5-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb33-1"><a></a>quiet input id earnings str7 school <span class="kw">private</span> <span class="fu">group</span></span>
<span id="cb33-2"><a></a>1 110000 <span class="st">"private"</span> 1 1</span>
<span id="cb33-3"><a></a>2 100000 <span class="st">"private"</span> 1 1</span>
<span id="cb33-4"><a></a>3 110000 <span class="st">"public"</span> 0 1</span>
<span id="cb33-5"><a></a>4 60000 <span class="st">"private"</span> 1 2</span>
<span id="cb33-6"><a></a>5 30000 <span class="st">"public"</span> 0 2</span>
<span id="cb33-7"><a></a>6 115000 <span class="st">"private"</span> 1 3</span>
<span id="cb33-8"><a></a>7 75000 <span class="st">"private"</span> 1 3</span>
<span id="cb33-9"><a></a>8 90000 <span class="st">"public"</span> 0 4</span>
<span id="cb33-10"><a></a>9 60000 <span class="st">"public"</span> 0 4</span>
<span id="cb33-11"><a></a><span class="kw">end</span></span>
<span id="cb33-12"><a></a><span class="kw">gen</span>     dummy = 1 <span class="kw">if</span> <span class="fu">group</span> == 1</span>
<span id="cb33-13"><a></a><span class="kw">replace</span> dummy = 0 <span class="kw">if</span> <span class="fu">group</span> == 2</span>
<span id="cb33-14"><a></a><span class="kw">reg</span> <span class="kw">private</span> dummy <span class="kw">if</span> id&lt;=5</span>
<span id="cb33-15"><a></a><span class="kw">di</span> .1666667 *  60000 </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(6 missing values generated)

(2 real changes made)

      Source |       SS           df       MS      Number of obs   =         5
-------------+----------------------------------   F(1, 3)         =      0.09
       Model |  .033333333         1  .033333333   Prob &gt; F        =    0.7888
    Residual |  1.16666667         3  .388888889   R-squared       =    0.0278
-------------+----------------------------------   Adj R-squared   =   -0.2963
       Total |         1.2         4          .3   Root MSE        =    .62361

------------------------------------------------------------------------------
     private | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       dummy |   .1666667    .569275     0.29   0.789    -1.645021    1.978354
       _cons |         .5   .4409586     1.13   0.339    -.9033269    1.903327
------------------------------------------------------------------------------

10000.002</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="ovb-again-5" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<p><strong>So what?</strong></p>
<ul>
<li><p>Anticipating the effect of the omitted variable on the non-omitted variable can tell you the sign of the bias.</p></li>
<li><p>Then you can know if the bias is attenuating or increasing the effect you are investigating.</p></li>
<li><p>If attenuating, the problem is smaller than if it is increasing</p></li>
</ul>
</section>
<section id="ovb-again-6" class="slide level2 smaller" data-background="#f5caae">
<h2>OVB again</h2>
<p><strong>Regressions</strong></p>
<ul>
<li><p>The previous examples show that we can run <strong>regressions and find correlations</strong> …</p></li>
<li><p>… And we can run regressions and find <strong>causal effects</strong>.</p></li>
<li><p>But we need to control for all relevant variables, otherwise we have the <em>OVB problem</em>.</p></li>
<li><p>Should you not look careful to your data, you’d miss the inclusion of the variable <code>group</code>.</p></li>
<li><p>The results show that you may estimate a spurious coefficient twice the size of the “true” coefficient.</p></li>
</ul>
</section></section>
<section>
<section id="bad-controls-problem" class="title-slide slide level1 smaller center" data-background="#dff2c7">
<h1>Bad Controls Problem</h1>

</section>
<section id="bad-controls-problem-1" class="slide level2 smaller" data-background="#dff2c7">
<h2>Bad Controls Problem</h2>
<p><strong>Bad controls</strong> are variables that are <strong>also outcome of the treatment</strong> being studied.</p>
<p>A <strong>Bad control</strong> could very well be a <strong>dependent variable</strong> of the treatment as well.</p>
<p><strong>Good controls</strong> are variables that <strong>you can think as being fixed</strong> at the time of the treatment.</p>
<div class="fragment">
<p>Let’s return to the model.</p>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group+ \epsilon \;,\; if\; i &lt;=5\]</span></p>
<p>Assuming you also have the occupation of the students at the time of earnings. Should you include <code>occupation</code> in the model?</p>
<p><span class="math display">\[earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group + \beta_3 Occupation + \epsilon \;,\; if\; i &lt;=5\]</span></p>
<p>Reasoning: “<em>We should use occupation as control because it would be wise to look at the effect of education on earnings only for those within an occupation</em>”.</p>
<p>What is the problem with this reasoning?</p>
</div>
</section>
<section id="bad-controls-problem-2" class="slide level2 smaller" data-background="#dff2c7">
<h2>Bad Controls Problem</h2>
<p>The problem is that studying in private would increase the chances of getting a white-collar occupation, i.e., <em>private education (treatment) affects the occupation (bad control)</em>.</p>
<p>In this case, should you include occupation as control, the coefficient of interest no longer has a causal interpretation.</p>
<div class="fragment">
<p><strong>This is a very common problem in empirical research</strong>.</p>
<p>It is not hard to come up with stories of why a control is a bad control.</p>
</div>
</section></section>
<section>
<section id="randomization" class="title-slide slide level1 smaller center" data-background="#ff9c6b">
<h1>Randomization</h1>

</section>
<section id="randomization-1" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<p><strong>Now I want to discuss the idea of randomization</strong></p>
<p>Suppose you have developed a treatment (e.g., a program) that you believe will increase the ‘motivation’ of employees of a factory.</p>
<p>You have 100 employees to use in an experiment to test your claim that the treatment will increase motivation.</p>
<div class="fragment">
<ul>
<li>You randomly allocate 50 employees to receive the treatment. The other 50 are part of the control group.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>You treat all employees in the same manner, except for the treatment.</li>
</ul>
</div>
<div class="fragment">
<p>Using the data available, this is the <strong>difference in motivation between the treatment and control groups (next slide):</strong></p>
</div>
</section>
<section id="randomization-2" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<div class="panel-tabset">
<ul id="tabset-6" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-6-1">R</a></li><li><a href="#tabset-6-2">Python</a></li><li><a href="#tabset-6-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a></a><span class="fu">library</span>(readxl)</span>
<span id="cb35-2"><a></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb35-3"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb35-4"><a></a><span class="fu">library</span>(dplyr)</span>
<span id="cb35-5"><a></a>data  <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"files/part_3_data.xlsx"</span>, <span class="at">range =</span> <span class="st">"A1:C101"</span>)</span>
<span id="cb35-6"><a></a><span class="co"># Box plot control vs treatment groups</span></span>
<span id="cb35-7"><a></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">y=</span>motivation, <span class="at">fill=</span>group)) <span class="sc">+</span>   </span>
<span id="cb35-8"><a></a>  <span class="fu">geom_boxplot</span>()<span class="sc">+</span></span>
<span id="cb35-9"><a></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">color=</span><span class="st">"black"</span>, <span class="at">size=</span><span class="dv">30</span>, <span class="at">face=</span><span class="st">"bold"</span>),</span>
<span id="cb35-10"><a></a>        <span class="at">panel.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">"grey95"</span>, <span class="at">colour =</span> <span class="st">"grey95"</span>),</span>
<span id="cb35-11"><a></a>        <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">face=</span><span class="st">"bold"</span>, <span class="at">color=</span><span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">18</span>),</span>
<span id="cb35-12"><a></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb35-13"><a></a>        <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb35-14"><a></a>        <span class="at">legend.key.size =</span> <span class="fu">unit</span>(<span class="dv">3</span>, <span class="st">"cm"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-16-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-6-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-2"><a></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb36-3"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-4"><a></a></span>
<span id="cb36-5"><a></a><span class="co"># Read data from Excel file</span></span>
<span id="cb36-6"><a></a>data <span class="op">=</span> pd.read_excel(<span class="st">"files/part_3_data.xlsx"</span>)</span>
<span id="cb36-7"><a></a></span>
<span id="cb36-8"><a></a><span class="co"># Create a box plot of control vs treatment groups using seaborn</span></span>
<span id="cb36-9"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb36-10"><a></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">'whitegrid'</span>)</span>
<span id="cb36-11"><a></a>sns.boxplot(x<span class="op">=</span><span class="st">'group'</span>, y<span class="op">=</span><span class="st">'motivation'</span>, data<span class="op">=</span>data, palette<span class="op">=</span><span class="st">'Set2'</span>)</span>
<span id="cb36-12"><a></a>plt.title(<span class="st">"Box Plot of Control vs Treatment Groups"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb36-13"><a></a>plt.xlabel(<span class="st">"Group"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb36-14"><a></a>plt.ylabel(<span class="st">"Motivation"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb36-15"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-17-1.png" class="quarto-figure quarto-figure-center" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-6-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb37-1"><a></a>import excel <span class="st">"files/part_3_data.xlsx"</span>, cellrange(A1:C101) firstrow <span class="kw">clear</span></span>
<span id="cb37-2"><a></a><span class="kw">graph</span> box motivation , <span class="bn">over</span>(<span class="fu">group</span>) box(1, <span class="kw">color</span>(<span class="bn">black</span>))     <span class="bn">ytitle</span>(<span class="st">"Motivation"</span>)  </span>
<span id="cb37-3"><a></a></span>
<span id="cb37-4"><a></a><span class="kw">quietly</span> <span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph3_5.svg"</span>, <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(3 vars, 100 obs)</code></pre>
</div>
</div>
<p><img data-src="files/graph3_5.svg"></p>
</div>
</div>
</div>
</section>
<section id="randomization-3" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<p>The calculated means are below. And they are statistically different.</p>
<div class="panel-tabset">
<ul id="tabset-7" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-7-1">R</a></li><li><a href="#tabset-7-2">Python</a></li><li><a href="#tabset-7-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a></a>data  <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"files/part_3_data.xlsx"</span>, <span class="at">range =</span> <span class="st">"A1:C101"</span>)</span>
<span id="cb39-2"><a></a><span class="fu">tapply</span>(data<span class="sc">$</span>motivation, data<span class="sc">$</span>group, summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>$Control
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  16.70   19.70   20.70   20.80   22.27   24.60 

$Treatment
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  17.60   20.52   22.50   22.27   23.77   26.50 </code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a></a><span class="fu">t.test</span>(motivation <span class="sc">~</span> group, <span class="at">data =</span> data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  motivation by group
t = -3.7301, df = 94.879, p-value = 0.0003258
alternative hypothesis: true difference in means between group Control and group Treatment is not equal to 0
95 percent confidence interval:
 -2.2493176 -0.6866824
sample estimates:
  mean in group Control mean in group Treatment 
                 20.800                  22.268 </code></pre>
</div>
</div>
</div>
<div id="tabset-7-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a>data <span class="op">=</span> pd.read_excel(<span class="st">"files/part_3_data.xlsx"</span>)</span>
<span id="cb43-2"><a></a>group_summary <span class="op">=</span> data.groupby(<span class="st">'group'</span>)[<span class="st">'motivation'</span>].describe()</span>
<span id="cb43-3"><a></a><span class="bu">print</span>(group_summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>           count    mean       std   min     25%   50%     75%   max
group                                                               
Control     50.0  20.800  1.780392  16.7  19.700  20.7  22.275  24.6
Treatment   50.0  22.268  2.138800  17.6  20.525  22.5  23.775  26.5</code></pre>
</div>
</div>
</div>
<div id="tabset-7-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb45-1"><a></a>import excel <span class="st">"files/part_3_data.xlsx"</span>, cellrange(A1:C101) firstrow <span class="kw">clear</span></span>
<span id="cb45-2"><a></a><span class="kw">bys</span> <span class="fu">group</span>  : <span class="kw">sum</span> motivation</span>
<span id="cb45-3"><a></a>estpost <span class="kw">ttest</span> motivation , <span class="kw">by</span>(<span class="fu">group</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(3 vars, 100 obs)


-------------------------------------------------------------------------------
-&gt; group = Control

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
  motivation |         50        20.8    1.780392       16.7       24.6

-------------------------------------------------------------------------------
-&gt; group = Treatment

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
  motivation |         50      22.268      2.1388       17.6       26.5

             |      e(b)   e(count)      e(se)       e(t)    e(df_t) 
-------------+-------------------------------------------------------
  motivation |    -1.468        100   .3935546  -3.730105         98 

             |    e(p_l)       e(p)     e(p_u)     e(N_1)    e(mu_1) 
-------------+-------------------------------------------------------
  motivation |  .0001604   .0003208   .9998396         50       20.8 

             |    e(N_2)    e(mu_2) 
-------------+----------------------
  motivation |        50     22.268 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="randomization-4" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<p><strong>Is there evidence that the program has increased motivation?</strong></p>
<div class="fragment">
<ul>
<li><p>well, if you randomly split a group of 100 people into two groups of 50, you certainly wouldn’t get the same mean motivation in both groups even if you treated them exactly alike.</p></li>
<li><p>Maybe the difference that we see is just such a difference?</p></li>
</ul>
<p><strong>How can we test this hypothesis?</strong></p>
</div>
</section>
<section id="randomization-5" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<p><strong>Solution</strong>:</p>
<ul>
<li><p>Suppose the treatment had no effect, and the employees developed their motivation independently of the treatment.</p></li>
<li><p>What is the chance that the 50 employees randomly assigned to the treatment group would have an average at least 1.47 (22.27 - 20.80) points higher than the average motivation of the employees randomly assigned to the control group?</p></li>
</ul>
</section>
<section id="randomization-6" class="slide level2 smaller scrollable" data-background="#ff9c6b">
<h2>Randomization</h2>
<p><strong>Steps</strong></p>
<ol type="1">
<li><p>Randomly split the 100 employees that we observed in this experiment into two groups of 50.</p></li>
<li><p>Note the difference in the mean motivation between the two groups.</p></li>
<li><p>Repeat 1 and 2 a total of 10,000 times.</p></li>
<li><p>Note the proportion of times the difference is at least 1.47 (22.27 - 20.80).</p></li>
</ol>
</section>
<section id="randomization-7" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<div class="panel-tabset">
<ul id="tabset-8" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-8-1">R</a></li><li><a href="#tabset-8-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a></a><span class="co"># Load necessary libraries</span></span>
<span id="cb47-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"files/part_3_data.xlsx"</span>, <span class="at">range =</span> <span class="st">"A1:C101"</span>)</span>
<span id="cb47-3"><a></a>comb <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb47-4"><a></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> comb))</span>
<span id="cb47-5"><a></a><span class="fu">colnames</span>(df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"order"</span> ,<span class="st">"diff"</span>)</span>
<span id="cb47-6"><a></a><span class="co"># Create the loop for randomization:</span></span>
<span id="cb47-7"><a></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">1</span>, <span class="at">to =</span> comb)) {</span>
<span id="cb47-8"><a></a>  <span class="fu">set.seed</span>(i)                               </span>
<span id="cb47-9"><a></a>  data<span class="sc">$</span>temp <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)  <span class="co"># Creating 100 random numbers 0 to 1</span></span>
<span id="cb47-10"><a></a>  data <span class="ot">&lt;-</span> data[<span class="fu">order</span>(data<span class="sc">$</span>temp),]            <span class="co"># Sorting data by the random numbers generated in the previous row</span></span>
<span id="cb47-11"><a></a>  data<span class="sc">$</span>rank <span class="ot">&lt;-</span> <span class="fu">rank</span>(data<span class="sc">$</span>temp)               <span class="co"># Ranking by the random numbers</span></span>
<span id="cb47-12"><a></a><span class="co"># The row below defines the treatment group based on the random numbers generated. This is where we guarantee randomization</span></span>
<span id="cb47-13"><a></a>data<span class="sc">$</span>status_rank <span class="ot">&lt;-</span> <span class="fu">case_when</span>(data<span class="sc">$</span>rank <span class="sc">&lt;=</span> <span class="dv">50</span> <span class="sc">~</span> <span class="st">"Control_rand"</span>, data<span class="sc">$</span>rank <span class="sc">&gt;</span> <span class="dv">50</span> <span class="sc">~</span> <span class="st">"Treated_rand"</span>)</span>
<span id="cb47-14"><a></a><span class="co"># Calculate the new means of the new groups. Need to transpose data.</span></span>
<span id="cb47-15"><a></a>means <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">as.data.frame</span>(<span class="fu">tapply</span>(data<span class="sc">$</span>motivation, data<span class="sc">$</span>status_rank, mean)))</span>
<span id="cb47-16"><a></a><span class="co"># Moving the new means to df. Each row is the difference of means</span></span>
<span id="cb47-17"><a></a>df[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> i</span>
<span id="cb47-18"><a></a>df[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> means[<span class="dv">1</span>, <span class="dv">2</span>] <span class="sc">-</span> means[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb47-19"><a></a><span class="fu">rm</span>(means) <span class="co"># Deleting value</span></span>
<span id="cb47-20"><a></a>data <span class="ot">=</span> <span class="fu">subset</span>(data, <span class="at">select =</span> <span class="sc">-</span><span class="fu">c</span>(temp, rank, status_rank)) <span class="co"># Deleting variables</span></span>
<span id="cb47-21"><a></a>}</span>
<span id="cb47-22"><a></a><span class="co"># Calculate a suitable binwidth for the histogram</span></span>
<span id="cb47-23"><a></a>binwidth <span class="ot">&lt;-</span> (<span class="fu">max</span>(df<span class="sc">$</span>diff) <span class="sc">-</span> <span class="fu">min</span>(df<span class="sc">$</span>diff)) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">length</span>(df<span class="sc">$</span>diff))</span>
<span id="cb47-24"><a></a><span class="co"># Create a histogram of the differences with the calculated binwidth</span></span>
<span id="cb47-25"><a></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> diff)) <span class="sc">+</span></span>
<span id="cb47-26"><a></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> binwidth, <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb47-27"><a></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Distribution of Differences"</span>, <span class="at">x =</span> <span class="st">"Difference"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-22-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-8-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb48-1"><a></a>import excel <span class="st">"files/part_3_data.xlsx"</span>, cellrange(A1:C101) firstrow <span class="kw">clear</span></span>
<span id="cb48-2"><a></a><span class="kw">set</span> <span class="dv">seed</span> 472195         </span>
<span id="cb48-3"><a></a><span class="kw">sort</span> <span class="fu">group</span>       </span>
<span id="cb48-4"><a></a><span class="kw">set</span> <span class="kw">obs</span> 10000                </span>
<span id="cb48-5"><a></a><span class="kw">egen</span> fin_order = <span class="fu">seq</span>() </span>
<span id="cb48-6"><a></a><span class="kw">sort</span> fin_order               </span>
<span id="cb48-7"><a></a><span class="kw">summarize</span>                   </span>
<span id="cb48-8"><a></a><span class="kw">gen</span> av_diff=.</span>
<span id="cb48-9"><a></a></span>
<span id="cb48-10"><a></a><span class="kw">local</span> i = 1</span>
<span id="cb48-11"><a></a><span class="kw">while</span> <span class="ot">`i'</span>&lt;=10000 {</span>
<span id="cb48-12"><a></a></span>
<span id="cb48-13"><a></a>    <span class="kw">sort</span> fin_order</span>
<span id="cb48-14"><a></a>    <span class="kw">gen</span> rand_num<span class="ot">`i'</span> = uniform() <span class="kw">if</span> !<span class="fu">missing</span>(motivation)</span>
<span id="cb48-15"><a></a>    <span class="kw">egen</span> ordering<span class="ot">`i'</span> = <span class="fu">rank</span>(rand_num<span class="ot">`i'</span>)</span>
<span id="cb48-16"><a></a>    <span class="kw">sort</span> ordering<span class="ot">`i'</span></span>
<span id="cb48-17"><a></a></span>
<span id="cb48-18"><a></a>    <span class="kw">gen</span> group<span class="ot">`i'</span> = <span class="st">""</span></span>
<span id="cb48-19"><a></a>    <span class="kw">replace</span> group<span class="ot">`i'</span> = <span class="st">"T"</span> <span class="kw">if</span> ordering &lt;= 50</span>
<span id="cb48-20"><a></a>    <span class="kw">replace</span> group<span class="ot">`i'</span> = <span class="st">"C"</span> <span class="kw">if</span> ordering &gt; 50 &amp; ordering&lt;=100</span>
<span id="cb48-21"><a></a>    </span>
<span id="cb48-22"><a></a>    <span class="kw">qui</span> summ motivation <span class="kw">if</span> group<span class="ot">`i'</span>==<span class="st">"T"</span></span>
<span id="cb48-23"><a></a>    <span class="fu">scalar</span> avT = <span class="ot">`r(mean)'</span></span>
<span id="cb48-24"><a></a>    <span class="kw">qui</span> summ motivation <span class="kw">if</span> group<span class="ot">`i'</span>==<span class="st">"C"</span></span>
<span id="cb48-25"><a></a>    <span class="fu">scalar</span> avC = <span class="ot">`r(mean)'</span></span>
<span id="cb48-26"><a></a>    </span>
<span id="cb48-27"><a></a>    <span class="kw">sort</span> fin_order</span>
<span id="cb48-28"><a></a>    <span class="kw">replace</span> av_diff = avT-avC <span class="kw">in</span> <span class="ot">`i'</span></span>
<span id="cb48-29"><a></a>    </span>
<span id="cb48-30"><a></a>    <span class="kw">drop</span> rand_num<span class="ot">`i'</span> ordering<span class="ot">`i'</span> group<span class="ot">`i'</span></span>
<span id="cb48-31"><a></a>    <span class="kw">local</span> i = <span class="ot">`i'</span> + 1</span>
<span id="cb48-32"><a></a>}</span>
<span id="cb48-33"><a></a><span class="kw">histogram</span> av_diff, <span class="kw">frequency</span> <span class="kw">kdensity</span>  </span>
<span id="cb48-34"><a></a><span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph3_6.png"</span> , <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="files/graph3_6.png" width="800" height="450"></p>
</div>
</div>
</div>
</section>
<section id="randomization-8" class="slide level2 smaller" data-background="#ff9c6b">
<h2>Randomization</h2>
<p>The mean difference was as far from 0 as 1.5 for only a few out of the 10,000 random divisions of the data into two groups of 50.</p>
<ul>
<li><p>Thus, <strong>the difference between the mean motivation would almost always be less than the observed difference of 1.47 (22.27 - 20.80) if the treatment had no effect.</strong></p></li>
<li><p>It seems reasonable to believe that the treatment caused the difference in motivation.</p></li>
</ul>
</section></section>
<section>
<section id="measurement-error-problem" class="title-slide slide level1 smaller center" data-background="#f2e9b6">
<h1>Measurement Error problem</h1>

</section>
<section id="measurement-error-problem-1" class="slide level2 smaller" data-background="#f2e9b6">
<h2>Measurement Error problem</h2>
<p>The measurement error problem has a similar statistical structure to the omitted variable bias (OVB).</p>
<ul>
<li><p>“Classical” random measurement error for the <span class="math inline">\(y\)</span> will inflate standard errors but will not lead to biased coefficients.</p>
<ul>
<li><span class="math inline">\(y^{*} = y + \sigma_{1}\)</span></li>
<li>If you estimante <span class="math inline">\(y^{*} = f(x)\)</span>, you have <span class="math inline">\(y + \sigma_{1} = x + \epsilon\)</span></li>
<li><span class="math inline">\(y = x + u\)</span>
<ul>
<li>where <span class="math inline">\(u = \epsilon - \sigma_{1}\)</span></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="measurement-error-problem-2" class="slide level2 smaller" data-background="#f2e9b6">
<h2>Measurement Error problem</h2>
<ul>
<li><p>“Classical” random measurement error in x’s will bias coefficient estimates toward zero.</p></li>
<li><p><span class="math inline">\(x^*=x+\sigma_2\)</span></p></li>
<li><p>Imagine that <span class="math inline">\(x^*\)</span> is a bunch of noise. It would not explain anything. Thus, your results are biased toward zero.</p></li>
</ul>
</section>
<section id="measurement-error-problem-3" class="slide level2 smaller" data-background="#f2e9b6">
<h2>Measurement Error problem</h2>
<p>A example using one of the Wooldridge’s datasets.</p>
<div class="panel-tabset">
<ul id="tabset-9" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-9-1">R</a></li><li><a href="#tabset-9-2">Python</a></li><li><a href="#tabset-9-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a></a><span class="fu">library</span>(foreign) </span>
<span id="cb49-2"><a></a><span class="fu">library</span>(jtools)</span>
<span id="cb49-3"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb49-4"><a></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb49-5"><a></a>data<span class="sc">$</span>salary_noise <span class="ot">&lt;-</span> data<span class="sc">$</span>salary <span class="sc">+</span> <span class="fu">runif</span>(<span class="fu">length</span>((data<span class="sc">$</span>salary)), <span class="at">min=</span><span class="sc">-</span><span class="dv">100</span>, <span class="at">max=</span> <span class="dv">100</span>)</span>
<span id="cb49-6"><a></a>data<span class="sc">$</span>roe_noise <span class="ot">&lt;-</span> data<span class="sc">$</span>roe <span class="sc">+</span> <span class="fu">runif</span>(<span class="fu">length</span>((data<span class="sc">$</span>roe)), <span class="at">min=</span><span class="sc">-</span><span class="dv">100</span>, <span class="at">max=</span> <span class="dv">100</span>)</span>
<span id="cb49-7"><a></a><span class="co"># OLS model </span></span>
<span id="cb49-8"><a></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(data<span class="sc">$</span>salary <span class="sc">~</span> data<span class="sc">$</span>roe)</span>
<span id="cb49-9"><a></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(data<span class="sc">$</span>salary <span class="sc">~</span> data<span class="sc">$</span>roe_noise)</span>
<span id="cb49-10"><a></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(data<span class="sc">$</span>salary_noise <span class="sc">~</span> data<span class="sc">$</span>roe)</span>
<span id="cb49-11"><a></a><span class="co">#summary(model1)</span></span>
<span id="cb49-12"><a></a><span class="co">#summary(model2)</span></span>
<span id="cb49-13"><a></a><span class="co">#summary(model3)</span></span>
<span id="cb49-14"><a></a><span class="fu">export_summs</span>(model1, model2, model3, <span class="at">digits =</span> <span class="dv">3</span> , <span class="at">model.names =</span> <span class="fu">c</span>(<span class="st">"Roe"</span>, <span class="st">"Roe (X) with noise"</span>, <span class="st">"Salary (y) with noise"</span>) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table id="tab:unnamed-chunk-24" class="huxtable" data-quarto-postprocess="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  ">
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;"></td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Roe</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Roe (X) with noise</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Salary (y) with noise</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(Intercept)</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">963.191 ***</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1269.739 ***</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">964.058 ***</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;"></td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(213.240)&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(97.356)&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(214.588)&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">data$roe</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">18.501&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">18.318&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;"></td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(11.123)&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(11.194)&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">data$roe_noise</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0.868&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;"></td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">(1.593)&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">N</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">209&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">209&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">209&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">R2</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0.013&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0.001&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="text-align: right; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0.013&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr class="even">
<td colspan="4" data-quarto-table-cell-role="th" style="text-align: left; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
<div id="tabset-9-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb50-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb50-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb50-4"><a></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb50-5"><a></a><span class="im">from</span> statsmodels.iolib.summary2 <span class="im">import</span> summary_col</span>
<span id="cb50-6"><a></a></span>
<span id="cb50-7"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb50-8"><a></a>np.random.seed(<span class="dv">2</span>)</span>
<span id="cb50-9"><a></a><span class="co"># Add noise to the 'salary' and 'roe' columns</span></span>
<span id="cb50-10"><a></a>data[<span class="st">'salary_noise'</span>] <span class="op">=</span> data[<span class="st">'salary'</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span>, <span class="bu">len</span>(data))</span>
<span id="cb50-11"><a></a>data[<span class="st">'roe_noise'</span>] <span class="op">=</span> data[<span class="st">'roe'</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span>, <span class="bu">len</span>(data))</span>
<span id="cb50-12"><a></a><span class="co"># OLS model</span></span>
<span id="cb50-13"><a></a>model1 <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'salary ~ roe'</span>, data<span class="op">=</span>data).fit()</span>
<span id="cb50-14"><a></a>model2 <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'salary ~ roe_noise'</span>, data<span class="op">=</span>data).fit()</span>
<span id="cb50-15"><a></a>model3 <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'salary_noise ~ roe'</span>, data<span class="op">=</span>data).fit()</span>
<span id="cb50-16"><a></a><span class="co"># Create a summary table for all regressions</span></span>
<span id="cb50-17"><a></a>results <span class="op">=</span> summary_col([model1, model2, model3], </span>
<span id="cb50-18"><a></a>                      model_names<span class="op">=</span>[<span class="st">'Reg 1'</span>, <span class="st">'Reg 2'</span>, <span class="st">'Reg 3'</span>],</span>
<span id="cb50-19"><a></a>                      stars<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb50-20"><a></a>                      float_format<span class="op">=</span><span class="st">'</span><span class="sc">%0.2f</span><span class="st">'</span>)</span>
<span id="cb50-21"><a></a><span class="co"># Print the summary table</span></span>
<span id="cb50-22"><a></a><span class="bu">print</span>(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
=============================================
                 Reg 1     Reg 2      Reg 3  
---------------------------------------------
Intercept      963.19*** 1262.12*** 966.97***
               (213.24)  (98.19)    (213.37) 
R-squared      0.01      0.00       0.01     
R-squared Adj. 0.01      -0.00      0.01     
roe            18.50*               17.92    
               (11.12)              (11.13)  
roe_noise                1.25                
                         (1.63)              
=============================================
Standard errors in parentheses.
* p&lt;.1, ** p&lt;.05, ***p&lt;.01</code></pre>
</div>
</div>
</div>
<div id="tabset-9-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb52-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.dta"</span>, <span class="kw">clear</span></span>
<span id="cb52-2"><a></a><span class="kw">set</span> <span class="dv">seed</span> 2</span>
<span id="cb52-3"><a></a><span class="kw">gen</span> salary_noise = salary + runiform() * 200 - 100</span>
<span id="cb52-4"><a></a><span class="kw">gen</span> roe_noise = roe + runiform() * 200 - 100</span>
<span id="cb52-5"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> salary roe</span>
<span id="cb52-6"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> salary roe_noise</span>
<span id="cb52-7"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> salary_noise roe</span>
<span id="cb52-8"><a></a>esttab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(est1 stored)

(est2 stored)

(est3 stored)


------------------------------------------------------------
                      (1)             (2)             (3)   
                   salary          salary    salary_noise   
------------------------------------------------------------
roe                 18.50                           18.14   
                   (1.66)                          (1.63)   

roe_noise                          0.0336                   
                                   (0.02)                   

_cons               963.2***       1280.4***        966.1***
                   (4.52)         (12.71)          (4.53)   
------------------------------------------------------------
N                     209             209             209   
------------------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="more-about-regressions" class="title-slide slide level1 smaller center" data-background="#454343">
<h1>More about Regressions</h1>

</section>
<section id="regression-1" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p>Linear regressions are the workhorse tool in econometrics</p>
<ul>
<li><strong>Simplicity</strong>: straightforward to understand, implement, and visualize.</li>
</ul>
<div class="fragment">
<ul>
<li><strong>Interpretability</strong>: coefficients have clear interpretations.
<ul>
<li>represents the change in the Y for a one-unit change in the X, holding all other variables constant.</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Versatility</strong>: simple linear regression or <em>multiple linear regression</em>.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Assumptions</strong>: linearity, independence of errors, homoscedasticity, and normality of errors.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Baseline Model</strong>: You can compare the performance of more advanced models to linear regression.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Estimation</strong>: provides clear estimates of the coefficients’ confidence intervals and hypothesis testing.</li>
</ul>
</div>
</section>
<section id="regression-2" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p>In this setting, the variables <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> can have several names.</p>
<table>
<thead>
<tr class="header">
<th>Y</th>
<th>X</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dependent variable</td>
<td>Independent variable</td>
</tr>
<tr class="even">
<td>Explained variable</td>
<td>Explanatory variable</td>
</tr>
<tr class="odd">
<td>Response variable</td>
<td>Control variable</td>
</tr>
<tr class="even">
<td>Predicted variable</td>
<td>Predictor variable</td>
</tr>
<tr class="odd">
<td>Regressand</td>
<td>Regressor</td>
</tr>
</tbody>
</table>
</section>
<section id="regression-3" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p>Broadly, we are interested in how y is explained by x?</p>
<ul>
<li><span class="math inline">\(y_i = \alpha + \beta_1 x_i + \epsilon\)</span></li>
</ul>
<div class="fragment">
<p>Perhaps <span class="math inline">\(\epsilon\)</span> is the most important part of a regression.</p>
<p>The interpretation is “<em>everything that is not explained by X and that explains Y</em>”.</p>
</div>
<div class="fragment">
<p>A comment</p>
<ul>
<li><p>Usually, the literature uses <span class="math inline">\(\epsilon\)</span> for the “estimated” residual.</p></li>
<li><p>And <span class="math inline">\(\mu\)</span> for the “true” residual, which necessarily implies that the assumptions hold.</p></li>
<li><p>At the end od the day, you don’t need to worry to much with the notation of this term because we are always in the “estimated world”, and almost never in the “true world”.</p></li>
<li><p>The “true world” implies that you are studying the population or that you have a true random sample of the population</p>
<ul>
<li><span class="math inline">\(y_i = \alpha + \beta_1 x_i + \mu\)</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="regression-4" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p><strong>Remember</strong></p>
<ul>
<li><span class="math inline">\(y, x\)</span>, and <span class="math inline">\(\mu\)</span> are random variables</li>
<li><span class="math inline">\(y and x\)</span> are observable</li>
<li><span class="math inline">\(\mu\)</span> and <span class="math inline">\(\beta\)</span> are unobservable</li>
<li><span class="math inline">\(\mu\)</span> captures everything that determines y after accounting for x</li>
</ul>
<p>Our goal is to estimate β</p>
</section>
<section id="regression-5" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p>There are some assumptions/requirements about <span class="math inline">\(\mu\)</span> in a OLS</p>
<p><strong>First assumption</strong></p>
<ul>
<li><p>E(<span class="math inline">\(\mu\)</span>) = 0</p>
<ul>
<li>This is a simple assumption, not strong at all.</li>
<li>It simply assumes that the average of <span class="math inline">\(\mu\)</span> is zero in the population.</li>
<li>Basically, any non-zero mean is absorbed by the intercept
<ul>
<li>Say that E(<span class="math inline">\(\mu\)</span>) = k</li>
<li>We could rewrite <span class="math inline">\(\mu = k + w\)</span>, where E(w)=0</li>
<li>Then, model becomes <span class="math inline">\(y=(\alpha +𝑘) + \beta𝑥+𝑤\)</span></li>
<li>Intercept is now just (α + k), and error, w, is mean zero</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="regression-6" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p><strong>Second assumption</strong></p>
<ul>
<li>E(<span class="math inline">\(\mu\)</span>|x) = E(<span class="math inline">\(\mu\)</span>) for all values of x
<ul>
<li>It says that the average value of <span class="math inline">\(\mu\)</span> does not depend on the value of x (i.e., the slice of the population you are looking at).</li>
<li>We say that <span class="math inline">\(\mu\)</span> is mean-independent of x.</li>
<li>This is true if the X and the <span class="math inline">\(\mu\)</span> are independent to each other.</li>
<li>Implies that x and <span class="math inline">\(\mu\)</span> are <em>uncorrelated</em>.</li>
<li><strong>Conditional Mean Independence (CMI)</strong>.</li>
<li>This is one of the keys assumption to <em>causal inference</em>.</li>
</ul></li>
</ul>
</section>
<section id="regression-7" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p><strong>Second assumption</strong></p>
<p><strong>Example</strong></p>
<p>Let’s say the model is:</p>
<p><span class="math display">\[wage = \alpha + \beta Schooling_{years} + \epsilon\]</span></p>
<ul>
<li>where <span class="math inline">\(\epsilon\)</span> represents <em>unobserved ability</em>.</li>
</ul>
<p>Does CMI hold?</p>
<p>That is E(ability|x=8)=E(ability|x=10)=E(ability|x=12)?</p>
<div class="fragment">
<p><strong>Probably not</strong>, because the unobserved ability should depend on the years of schooling.</p>
<p>The solution (not trivial) would be to include ability as a new X.</p>
</div>
</section>
<section id="regression-8" class="slide level2 smaller scrollable" data-background="#454343">
<h2>Regression</h2>
<p><strong>Another example</strong></p>
<p>Consider the following model (with only one X)</p>
<p><span class="math display">\[Leverage_i = \alpha + \beta_1 Profitability_i + \mu_i\]</span></p>
<ul>
<li><p>CMI says that, to every firm <em>i</em>, <span class="math inline">\(\mu\)</span> is the same, even when firms have different profitability.</p></li>
<li><p>Can you think on examples when this assumption may not hold in this model?</p></li>
</ul>
<div class="fragment">
<ol type="1">
<li><p>unprofitable firms have higher bankruptcy risk, which should make them to have lower leverage (tradeoff theory).</p></li>
<li><p>unprofitable firms have low cash, which should make them to have more leverage (pecking order theory).</p></li>
</ol>
</div>
</section>
<section id="regression-9" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p><strong>The discussion of whether the CMI holds is the origin of the “endogeneity” problem.</strong></p>
<p>You will face reviewers arguing reasons of why the CMI might not hold in your case.</p>
<ul>
<li><p>Many will criticize a model by saying it has an “endogeneity problem”, whithout explaining more.</p>
<ul>
<li>This is very generic. <strong>Don’t do that!</strong></li>
</ul></li>
</ul>
<div class="fragment">
<p>They should explain what is the source of the problem that is making the model violate CMI.</p>
<ul>
<li>OVB, selection bias, reverse causality, simultaneity, etc?</li>
</ul>
</div>
<div class="fragment">
<p>Generally speaking, endogeneity refers to a violation of CMI, meaning that <span class="math inline">\(x\)</span> and <span class="math inline">\(\mu\)</span> are correlated.</p>
<p>This is always a plausible possibility, since <span class="math inline">\(\mu\)</span> carries a lot of stuff (something must be correlated with X).</p>
</div>
</section>
<section id="regression-10" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p><strong>Third assumption</strong></p>
<p>Combining 1 and 2 leads to</p>
<ul>
<li>E(<span class="math inline">\(\mu\)</span>|x) = 0
<ul>
<li>This is a very important assumption called <strong>zero conditional mean assumption</strong>.</li>
</ul></li>
</ul>
</section>
<section id="ordinary-least-squares" class="slide level2 smaller" data-background="#454343">
<h2>Ordinary Least Squares</h2>
<p>Our focus is to find estimates for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Should we have access to the population, it would be easy. We could write:</p>
<p><span class="math display">\[y_i= \alpha + \beta_1x_i + \mu\]</span></p>
<div class="fragment">
<p>But remember that,</p>
<p><span class="math display">\[E(u) = 0\]</span> <span class="math display">\[E(u|x) = 0\]</span></p>
<p>The second bullet implies that the correlation between x and <span class="math inline">\(\mu\)</span> is zero (we can write that as E(x,u) = 0).</p>
</div>
<div class="fragment">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>Remember: <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are parameters to be estimated (i.e., constants), while <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are variables</p>
</div>
</div>
</div>
</div>
</section>
<section id="regression-11" class="slide level2 smaller" data-background="#454343">
<h2>Regression</h2>
<p>So we can write that (in the <strong>population</strong>)</p>
<p><span class="math inline">\(E(y - \alpha - \beta_1x ) = 0\)</span></p>
<p><span class="math inline">\((x[y - \alpha - \beta_1x ]) = 0\)</span></p>
<div class="fragment">
<p>So we can write that (in the <strong>sample</strong>)</p>
<p><span class="math inline">\(\frac{1}{n} \sum_{i=1}^n (y_i - \hat{\alpha} - \hat{\beta_1} x_i ) = 0\)</span> , We will use this to find <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math inline">\(\frac{1}{n} \sum_{i=1}^n (x_i [y_i - \hat{\alpha} - \hat{\beta_1} x_i ]) = 0\)</span> , We will use this to find <span class="math inline">\(\beta\)</span>:</p>
</div>
</section>
<section id="finding-alpha" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\alpha\)</span></h2>
<p>From before:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - \hat{\alpha} - \hat{\beta_1} x_i ) =0\]</span></p>
<div class="fragment">
<p>Passing the sum operator through</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i=1}^n(y_i) - \frac{1}{n}\sum_{i=1}^n(\hat{\alpha})  - \frac{1}{n} \sum_{i=1}^n(\hat{\beta_1} x_i )=0\]</span></p>
</div>
<div class="fragment">
<p>Coefficients are constants, so we can get rid of the sum operator.</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i=1}^n(y_i) - \hat{\alpha}  - \hat{\beta_1} \frac{1}{n}  \sum_{i=1}^n(\ x_i )=0\]</span></p>
</div>
</section>
<section id="finding-alpha-1" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\alpha\)</span></h2>
<ul>
<li>We know that <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n(y_i)\)</span> is <span class="math inline">\(\bar{y_i}\)</span> (the mean)</li>
</ul>
<p><span class="math display">\[\bar{y_i} - \hat{\alpha}  - \hat{\beta_1}  \bar{x_i}=0\]</span></p>
<div class="fragment">
<p>So we write:</p>
<p><span class="math display">\[\hat{\alpha}  = \bar{y_i} -  \hat{\beta_1}   \bar{x_i}\]</span></p>
</div>
<div class="fragment">
<p><strong>Easy Peasy</strong> 😀</p>
</div>
</section>
<section id="finding-beta" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\beta\)</span></h2>
<p>From before:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (x_i [y_i - \hat{\alpha} - \hat{\beta_1} x_i ]) = 0\]</span></p>
<div class="fragment">
<p>But now we have:</p>
<p><span class="math display">\[\hat{\alpha}  = \bar{y_i} -  \hat{\beta_1}   \bar{x_i}\]</span></p>
</div>
<div class="fragment">
<p>Thus,</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (x_i [y_i - (\bar{y_i} -  \hat{\beta_1}   \bar{x_i}) - \hat{\beta_1} x_i ]) = 0\]</span></p>
</div>
</section>
<section id="finding-beta-1" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\beta\)</span></h2>
<p>Turning into</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (x_i [y_i - \bar{y_i} ])  -  \frac{1}{n} \sum_{i=1}^n (x_i [\hat{\beta_1} x_i - \hat{\beta_1} \bar{x_i} ]) = 0\]</span></p>
<div class="fragment">
<p>Or</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (x_i [y_i - \bar{y_i} ])  =  \hat{\beta_1} \frac{1}{n} \sum_{i=1}^n (x_i [ x_i  - \bar{x_i} ]) \]</span></p>
</div>
<div class="fragment">
<p>Last step (I am skipping some steps here)</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x} )(y_i - \bar{y_i} )  =  \hat{\beta_1} \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x_i} )^2 \]</span></p>
</div>
</section>
<section id="finding-beta-2" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\beta\)</span></h2>
<p>If the variance of x is not zero, we can write <span class="math inline">\(\beta\)</span> as</p>
<p><span class="math display">\[\hat{\beta_1} = \frac{\sum_i^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_i^n (x_i - \bar{x})^2} = \frac{Covariance(x_i,y_i)}{Variance(x_i)}\]</span></p>
</section>
<section id="finding-mu" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\mu\)</span></h2>
<p>Now that we have <span class="math inline">\(\hat{Y_i}=\hat{\alpha} + \hat{\beta_1} X_i\)</span>, we can estimate the residual <span class="math inline">\(\mu\)</span></p>
<p><span class="math display">\[\hat{\mu} = Y_i - \hat{Y_i}\]</span></p>
<p>Which is the same as:</p>
<p><span class="math display">\[\hat{\mu} = Y_i - \hat{\alpha} - \hat{\beta_1}x_i\]</span></p>
<p>Most residuals will not be 0, meaning they do not lie on the best fitting line.</p>
</section>
<section id="finding-mu-1" class="slide level2 smaller" data-background="#454343">
<h2>Finding <span class="math inline">\(\mu\)</span></h2>
<p>The job of an OLS model is find the parameters to minimize the squared error (i.e., to find the best fitting line).</p>
<p><span class="math display">\[\sum_{i=1}^n \hat{\mu}^2 = \sum_{i=1}^n(Y_i - \hat{Y_i})^2\]</span></p>
</section>
<section id="regression-source-1" class="slide level2 smaller" data-background="#454343">
<h2>Regression (<a href="https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares">Source</a>)</h2>
<p>Another example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.</p>
<div class="panel-tabset">
<ul id="tabset-10" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-10-1">R</a></li><li><a href="#tabset-10-2">Python</a></li><li><a href="#tabset-10-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb54-2"><a></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb54-3"><a></a>tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb54-4"><a></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb54-5"><a></a>  <span class="at">u =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb54-6"><a></a>  <span class="at">y =</span> <span class="fl">5.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">12</span><span class="sc">*</span>u <span class="co"># notice that I am defining the beta1 here. The 5.5 is the "true" beta we want to estimate.</span></span>
<span id="cb54-7"><a></a>) </span>
<span id="cb54-8"><a></a>reg_tb <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>tb) </span>
<span id="cb54-9"><a></a><span class="fu">summary</span>(reg_tb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = tb)

Residuals:
    Min      1Q  Median      3Q     Max 
-51.528  -8.152  -0.173   7.978  44.718 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.04991    0.11890   -0.42    0.675    
x            5.55690    0.11745   47.31   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 11.89 on 9998 degrees of freedom
Multiple R-squared:  0.1829,    Adjusted R-squared:  0.1828 
F-statistic:  2238 on 1 and 9998 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
<div id="tabset-10-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb56-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb56-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb56-4"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb56-5"><a></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb56-6"><a></a></span>
<span id="cb56-7"><a></a>obs <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb56-8"><a></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb56-9"><a></a>    <span class="st">'x'</span>: np.random.normal(size<span class="op">=</span>obs),</span>
<span id="cb56-10"><a></a>    <span class="st">'u'</span>: np.random.normal(size<span class="op">=</span>obs),</span>
<span id="cb56-11"><a></a>})</span>
<span id="cb56-12"><a></a>data[<span class="st">'y'</span>] <span class="op">=</span> <span class="fl">5.5</span> <span class="op">*</span> data[<span class="st">'x'</span>] <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> data[<span class="st">'u'</span>]</span>
<span id="cb56-13"><a></a></span>
<span id="cb56-14"><a></a>X <span class="op">=</span> sm.add_constant(data[<span class="st">'x'</span>])</span>
<span id="cb56-15"><a></a>model <span class="op">=</span> sm.OLS(data[<span class="st">'y'</span>], X).fit()</span>
<span id="cb56-16"><a></a></span>
<span id="cb56-17"><a></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.183
Model:                            OLS   Adj. R-squared:                  0.183
Method:                 Least Squares   F-statistic:                     2237.
Date:                qua, 11 set 2024   Prob (F-statistic):               0.00
Time:                        16:19:51   Log-Likelihood:                -39049.
No. Observations:               10000   AIC:                         7.810e+04
Df Residuals:                    9998   BIC:                         7.812e+04
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.1114      0.120      0.927      0.354      -0.124       0.347
x              5.6887      0.120     47.293      0.000       5.453       5.924
==============================================================================
Omnibus:                        0.640   Durbin-Watson:                   2.050
Prob(Omnibus):                  0.726   Jarque-Bera (JB):                0.672
Skew:                          -0.012   Prob(JB):                        0.715
Kurtosis:                       2.968   Cond. No.                         1.01
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-10-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb58-1"><a></a><span class="kw">set</span> <span class="dv">seed</span> 1 </span>
<span id="cb58-2"><a></a><span class="kw">set</span> <span class="kw">obs</span> 10000 </span>
<span id="cb58-3"><a></a><span class="kw">gen</span> x = rnormal() </span>
<span id="cb58-4"><a></a><span class="kw">gen</span> u  = rnormal() </span>
<span id="cb58-5"><a></a><span class="kw">gen</span> <span class="fu">y</span>  = 5.5*x + 12*u </span>
<span id="cb58-6"><a></a><span class="kw">reg</span> <span class="fu">y</span> x </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of observations (_N) was 0, now 10,000.

      Source |       SS           df       MS      Number of obs   =    10,000
-------------+----------------------------------   F(1, 9998)      =   2206.80
       Model |  327141.413         1  327141.413   Prob &gt; F        =    0.0000
    Residual |   1482125.8     9,998  148.242229   R-squared       =    0.1808
-------------+----------------------------------   Adj R-squared   =    0.1807
       Total |  1809267.22     9,999  180.944816   Root MSE        =    12.175

------------------------------------------------------------------------------
           y | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
           x |   5.598296    .119172    46.98   0.000     5.364695    5.831897
       _cons |  -.0750109   .1217548    -0.62   0.538    -.3136748     .163653
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="regression-source-2" class="slide level2 smaller" data-background="#454343">
<h2>Regression (<a href="https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares">Source</a>)</h2>
<p>Another example of regression. The differences in the coefficients are due to the differences in the seed of the random variables generator.</p>
<div class="panel-tabset">
<ul id="tabset-11" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-11-1">R</a></li><li><a href="#tabset-11-2">Python</a></li><li><a href="#tabset-11-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-11-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb60-2"><a></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb60-3"><a></a>tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb60-4"><a></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb60-5"><a></a>  <span class="at">u =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb60-6"><a></a>  <span class="at">y =</span> <span class="fl">5.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">12</span><span class="sc">*</span>u <span class="co"># notice that I am defining the beta1 here. The 5.5 is the "true" beta we want to estimate.</span></span>
<span id="cb60-7"><a></a>) </span>
<span id="cb60-8"><a></a>reg_tb <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>tb) </span>
<span id="cb60-9"><a></a>tb <span class="sc">%&gt;%</span> </span>
<span id="cb60-10"><a></a>  <span class="fu">lm</span>(y <span class="sc">~</span> x, .) <span class="sc">%&gt;%</span> </span>
<span id="cb60-11"><a></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb60-12"><a></a>  <span class="fu">ggtitle</span>(<span class="st">"OLS Regression Line"</span>) <span class="sc">+</span></span>
<span id="cb60-13"><a></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.05</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb60-14"><a></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb60-15"><a></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y =</span> <span class="dv">30</span>, <span class="at">color =</span> <span class="st">"red"</span>, </span>
<span id="cb60-16"><a></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Intercept = "</span>, reg_tb<span class="sc">$</span>coefficients[<span class="dv">1</span>])) <span class="sc">+</span></span>
<span id="cb60-17"><a></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">1.5</span>, <span class="at">y =</span> <span class="sc">-</span><span class="dv">30</span>, <span class="at">color =</span> <span class="st">"blue"</span>, </span>
<span id="cb60-18"><a></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Slope ="</span>, reg_tb<span class="sc">$</span>coefficients[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-30-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-11-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb61-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb61-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb61-4"><a></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb61-5"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb61-6"><a></a></span>
<span id="cb61-7"><a></a><span class="co"># Create a scatterplot with the OLS regression line using Seaborn</span></span>
<span id="cb61-8"><a></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">'whitegrid'</span>)</span>
<span id="cb61-9"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb61-10"><a></a>sns.scatterplot(x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, data<span class="op">=</span>data, color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb61-11"><a></a>sns.regplot(x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, data<span class="op">=</span>data, color<span class="op">=</span><span class="st">'black'</span>, scatter<span class="op">=</span><span class="va">False</span>, line_kws<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'black'</span>})</span>
<span id="cb61-12"><a></a>plt.title(<span class="st">'OLS Regression Line'</span>)</span>
<span id="cb61-13"><a></a>plt.annotate(<span class="ss">f'Intercept = </span><span class="sc">{</span>model<span class="sc">.</span>params[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">30</span>), color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb61-14"><a></a>plt.annotate(<span class="ss">f'Slope = </span><span class="sc">{</span>model<span class="sc">.</span>params[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="fl">1.5</span>, <span class="op">-</span><span class="dv">30</span>), color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb61-15"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-31-1.png" class="quarto-figure quarto-figure-center" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-11-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb62-1"><a></a><span class="kw">set</span> <span class="dv">seed</span> 1 </span>
<span id="cb62-2"><a></a><span class="kw">set</span> <span class="kw">obs</span> 10000 </span>
<span id="cb62-3"><a></a><span class="kw">gen</span> x = rnormal() </span>
<span id="cb62-4"><a></a><span class="kw">gen</span> u  = rnormal() </span>
<span id="cb62-5"><a></a><span class="kw">gen</span> <span class="fu">y</span>  = 5.5*x + 12*u </span>
<span id="cb62-6"><a></a><span class="kw">reg</span> <span class="fu">y</span> x </span>
<span id="cb62-7"><a></a><span class="kw">predict</span> yhat1 </span>
<span id="cb62-8"><a></a><span class="kw">gen</span> yhat2 = -0.0750109  + 5.598296*x </span>
<span id="cb62-9"><a></a><span class="kw">predict</span> uhat1, residual </span>
<span id="cb62-10"><a></a><span class="kw">gen</span> uhat2=<span class="fu">y</span>-yhat2 </span>
<span id="cb62-11"><a></a><span class="kw">qui</span> <span class="kw">sum</span> uhat* </span>
<span id="cb62-12"><a></a><span class="kw">twoway</span> (<span class="kw">lfit</span> <span class="fu">y</span> x, lcolor(<span class="bn">black</span>) lwidth(medium)) (<span class="kw">scatter</span> <span class="fu">y</span> x, mcolor(<span class="bn">black</span>) msize(tiny) <span class="bn">msymbol</span>(point)), <span class="bn">title</span>(OLS Regression Line) </span>
<span id="cb62-13"><a></a><span class="kw">qui</span> <span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph3.svg"</span>, <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="files/graph3.svg"></p>
</div>
</div>
</div>
</section>
<section id="regression-source-3" class="slide level2 smaller scrollable" data-background="#454343">
<h2>Regression (<a href="https://mixtape.scunning.com/02-probability_and_regression#ordinary-least-squares">Source</a>)</h2>
<p>Using the previous regressions, we can show that:</p>
<ol type="1">
<li><p><span class="math inline">\(\hat{y_i} = \hat{\alpha} + \hat{\beta_1} x_i\)</span></p></li>
<li><p><span class="math inline">\(\hat{\mu_i} = y_i - \hat{y_i}\)</span></p></li>
</ol>
<div class="panel-tabset">
<ul id="tabset-12" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-12-1">R</a></li><li><a href="#tabset-12-2">Python</a></li><li><a href="#tabset-12-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-12-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb63-2"><a></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb63-3"><a></a>tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb63-4"><a></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb63-5"><a></a>  <span class="at">u =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb63-6"><a></a>  <span class="at">y =</span> <span class="fl">5.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">12</span><span class="sc">*</span>u <span class="co"># notice that I am defining the beta1 here. The 5.5 is the "true" beta we want to estimate.</span></span>
<span id="cb63-7"><a></a>) </span>
<span id="cb63-8"><a></a>reg_tb <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>tb) </span>
<span id="cb63-9"><a></a></span>
<span id="cb63-10"><a></a>tb <span class="ot">&lt;-</span> tb <span class="sc">%&gt;%</span> </span>
<span id="cb63-11"><a></a>  <span class="fu">mutate</span>(</span>
<span id="cb63-12"><a></a>    <span class="at">yhat1 =</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb63-13"><a></a>    <span class="at">yhat2 =</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>x, </span>
<span id="cb63-14"><a></a>    <span class="at">uhat1 =</span> <span class="fu">residuals</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb63-15"><a></a>    <span class="at">uhat2 =</span> y <span class="sc">-</span> yhat2</span>
<span id="cb63-16"><a></a>  )</span>
<span id="cb63-17"><a></a><span class="fu">summary</span>(tb[<span class="sc">-</span><span class="dv">1</span><span class="sc">:-</span><span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     yhat1               yhat2               uhat1              uhat2         
 Min.   :-20.45096   Min.   :-20.45096   Min.   :-51.5275   Min.   :-51.5275  
 1st Qu.: -3.79189   1st Qu.: -3.79189   1st Qu.: -8.1520   1st Qu.: -8.1520  
 Median : -0.13842   Median : -0.13842   Median : -0.1727   Median : -0.1727  
 Mean   : -0.08624   Mean   : -0.08624   Mean   :  0.0000   Mean   :  0.0000  
 3rd Qu.:  3.71578   3rd Qu.:  3.71578   3rd Qu.:  7.9778   3rd Qu.:  7.9778  
 Max.   : 21.12342   Max.   : 21.12342   Max.   : 44.7176   Max.   : 44.7176  </code></pre>
</div>
</div>
</div>
<div id="tabset-12-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb65-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb65-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb65-4"><a></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb65-5"><a></a>obs <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb65-6"><a></a>x <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb65-7"><a></a>u <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb65-8"><a></a>y <span class="op">=</span> <span class="fl">5.5</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> u</span>
<span id="cb65-9"><a></a></span>
<span id="cb65-10"><a></a>X <span class="op">=</span> sm.add_constant(x)</span>
<span id="cb65-11"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb65-12"><a></a></span>
<span id="cb65-13"><a></a>tb <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: x, <span class="st">'u'</span>: u, <span class="st">'y'</span>: y})</span>
<span id="cb65-14"><a></a>tb[<span class="st">'yhat1'</span>] <span class="op">=</span> model.predict(X)</span>
<span id="cb65-15"><a></a>tb[<span class="st">'uhat1'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat1'</span>]</span>
<span id="cb65-16"><a></a>tb[<span class="st">'yhat2'</span>] <span class="op">=</span> model.params[<span class="dv">0</span>] <span class="op">+</span> model.params[<span class="dv">1</span>] <span class="op">*</span> x</span>
<span id="cb65-17"><a></a>tb[<span class="st">'uhat2'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat2'</span>]</span>
<span id="cb65-18"><a></a></span>
<span id="cb65-19"><a></a><span class="bu">print</span>(tb[[<span class="st">'yhat1'</span>,<span class="st">'yhat2'</span>, <span class="st">'uhat1'</span>,<span class="st">'uhat2'</span>]].describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>              yhat1         yhat2         uhat1         uhat2
count  10000.000000  10000.000000  1.000000e+04  1.000000e+04
mean       0.166975      0.166975 -1.691092e-16 -1.691092e-16
std        5.682040      5.682040  1.201339e+01  1.201339e+01
min      -20.688875    -20.688875 -4.142425e+01 -4.142425e+01
25%       -3.659775     -3.659775 -8.199882e+00 -8.199882e+00
50%        0.159473      0.159473  4.497835e-02  4.497835e-02
75%        3.933075      3.933075  8.147307e+00  8.147307e+00
max       23.018769     23.018769  5.000751e+01  5.000751e+01</code></pre>
</div>
</div>
</div>
<div id="tabset-12-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb67-1"><a></a><span class="kw">set</span> <span class="dv">seed</span> 1 </span>
<span id="cb67-2"><a></a><span class="kw">clear</span> </span>
<span id="cb67-3"><a></a><span class="kw">qui</span> <span class="kw">set</span> <span class="kw">obs</span> 10000 </span>
<span id="cb67-4"><a></a><span class="kw">gen</span> x = rnormal() </span>
<span id="cb67-5"><a></a><span class="kw">gen</span> u  = rnormal() </span>
<span id="cb67-6"><a></a><span class="kw">gen</span> <span class="fu">y</span>  = 5.5*x + 12*u </span>
<span id="cb67-7"><a></a><span class="kw">qui</span> <span class="kw">reg</span> <span class="fu">y</span> x </span>
<span id="cb67-8"><a></a><span class="kw">predict</span> uhat1, residual </span>
<span id="cb67-9"><a></a><span class="kw">predict</span> yhat1 </span>
<span id="cb67-10"><a></a><span class="kw">gen</span> yhat2 = -0.0750109  + 5.598296*x </span>
<span id="cb67-11"><a></a><span class="kw">gen</span> uhat2=<span class="fu">y</span>-yhat2 </span>
<span id="cb67-12"><a></a><span class="kw">sum</span> yhat*  uhat* </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(option xb assumed; fitted values)

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
       yhat1 |     10,000   -.0797351    5.719914  -23.06927   22.47639
       yhat2 |     10,000   -.0797351    5.719913  -23.06927   22.47639
       uhat1 |     10,000   -3.53e-09    12.17487   -49.8996   42.15174
       uhat2 |     10,000   -1.72e-08    12.17487   -49.8996   42.15174</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="properties-of-ols" class="title-slide slide level1 smaller center" data-background="#bfc4d9">
<h1>Properties of OLS</h1>

</section>
<section id="properties-of-ols-1" class="slide level2 smaller" data-background="#bfc4d9">
<h2>Properties of OLS</h2>
<p>We can easily show that (remember from before)</p>
<p><span class="math display">\[\sum_i^n(y_i - \hat{\alpha} - \hat{\beta_1} x_i) = 0\]</span></p>
<p>And that</p>
<p><span class="math display">\[\sum_i^n \hat{\mu}  = 0\]</span></p>
<p>The graphs next slide shows a spherical figure, suggesting that the residual is not correlated with the the fitted values (<span class="math inline">\(\hat{y_i}\)</span>)</p>
</section>
<section id="properties-of-ols-2" class="slide level2 smaller" data-background="#bfc4d9">
<h2>Properties of OLS</h2>
<div class="panel-tabset">
<ul id="tabset-13" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-13-1">R</a></li><li><a href="#tabset-13-2">Python</a></li><li><a href="#tabset-13-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-13-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb69-2"><a></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb69-3"><a></a>tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb69-4"><a></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb69-5"><a></a>  <span class="at">u =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb69-6"><a></a>  <span class="at">y =</span> <span class="fl">5.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">12</span><span class="sc">*</span>u <span class="co"># notice that I am defining the beta1 here. The 5.5 is the "true" beta we want to estimate.</span></span>
<span id="cb69-7"><a></a>) </span>
<span id="cb69-8"><a></a>reg_tb <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>tb) </span>
<span id="cb69-9"><a></a>tb <span class="ot">&lt;-</span> tb <span class="sc">%&gt;%</span> </span>
<span id="cb69-10"><a></a>  <span class="fu">mutate</span>(</span>
<span id="cb69-11"><a></a>    <span class="at">yhat1 =</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb69-12"><a></a>    <span class="at">yhat2 =</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>x, </span>
<span id="cb69-13"><a></a>    <span class="at">uhat1 =</span> <span class="fu">residuals</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb69-14"><a></a>    <span class="at">uhat2 =</span> y <span class="sc">-</span> yhat2</span>
<span id="cb69-15"><a></a>  )</span>
<span id="cb69-16"><a></a>tb <span class="sc">%&gt;%</span> </span>
<span id="cb69-17"><a></a>  <span class="fu">lm</span>(uhat1 <span class="sc">~</span> yhat1 , .) <span class="sc">%&gt;%</span> </span>
<span id="cb69-18"><a></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>yhat1, <span class="at">y=</span>uhat1)) <span class="sc">+</span> </span>
<span id="cb69-19"><a></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb69-20"><a></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">color =</span> <span class="st">"black"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-36-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-13-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb70-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb70-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb70-4"><a></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb70-5"><a></a>obs <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb70-6"><a></a>x <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb70-7"><a></a>u <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb70-8"><a></a>y <span class="op">=</span> <span class="fl">5.5</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> u</span>
<span id="cb70-9"><a></a></span>
<span id="cb70-10"><a></a>X <span class="op">=</span> sm.add_constant(x)</span>
<span id="cb70-11"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb70-12"><a></a></span>
<span id="cb70-13"><a></a>tb <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: x, <span class="st">'u'</span>: u, <span class="st">'y'</span>: y})</span>
<span id="cb70-14"><a></a>tb[<span class="st">'yhat1'</span>] <span class="op">=</span> model.predict(X)</span>
<span id="cb70-15"><a></a>tb[<span class="st">'uhat1'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat1'</span>]</span>
<span id="cb70-16"><a></a>tb[<span class="st">'yhat2'</span>] <span class="op">=</span> model.params[<span class="dv">0</span>] <span class="op">+</span> model.params[<span class="dv">1</span>] <span class="op">*</span> x</span>
<span id="cb70-17"><a></a>tb[<span class="st">'uhat2'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat2'</span>]</span>
<span id="cb70-18"><a></a>model <span class="op">=</span> sm.OLS(tb[<span class="st">'uhat1'</span>], sm.add_constant(tb[<span class="st">'yhat1'</span>])).fit()</span>
<span id="cb70-19"><a></a><span class="co"># Create a scatter plot with a regression line</span></span>
<span id="cb70-20"><a></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">"whitegrid"</span>)</span>
<span id="cb70-21"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="fl">4.5</span>))</span>
<span id="cb70-22"><a></a>sns.scatterplot(x<span class="op">=</span><span class="st">'yhat1'</span>, y<span class="op">=</span><span class="st">'uhat1'</span>, data<span class="op">=</span>tb, size<span class="op">=</span><span class="fl">0.05</span>, color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb70-23"><a></a>sns.regplot(x<span class="op">=</span><span class="st">'yhat1'</span>, y<span class="op">=</span><span class="st">'uhat1'</span>, data<span class="op">=</span>tb, scatter<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb70-24"><a></a>plt.xlabel(<span class="st">'yhat1'</span>)</span>
<span id="cb70-25"><a></a>plt.ylabel(<span class="st">'uhat1'</span>)</span>
<span id="cb70-26"><a></a>plt.title(<span class="st">'Scatter Plot of uhat1 vs. yhat1'</span>)</span>
<span id="cb70-27"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-37-1.png" class="quarto-figure quarto-figure-center" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-13-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb71-1"><a></a><span class="kw">set</span> <span class="dv">seed</span> 1 </span>
<span id="cb71-2"><a></a><span class="kw">set</span> <span class="kw">obs</span> 10000 </span>
<span id="cb71-3"><a></a><span class="kw">gen</span> x = rnormal() </span>
<span id="cb71-4"><a></a><span class="kw">gen</span> u  = rnormal() </span>
<span id="cb71-5"><a></a><span class="kw">gen</span> <span class="fu">y</span>  = 5.5*x + 12*u </span>
<span id="cb71-6"><a></a><span class="kw">qui</span> <span class="kw">reg</span> <span class="fu">y</span> x </span>
<span id="cb71-7"><a></a><span class="kw">predict</span> yhat1 </span>
<span id="cb71-8"><a></a><span class="kw">predict</span> uhat1, residual </span>
<span id="cb71-9"><a></a><span class="kw">twoway</span> (<span class="kw">lfit</span> uhat1 yhat1 , lcolor(<span class="bn">black</span>) lwidth(large)) (<span class="kw">scatter</span> uhat1 yhat1 , mcolor(<span class="bn">black</span>)  <span class="bn">msymbol</span>(point))</span>
<span id="cb71-10"><a></a><span class="kw">qui</span> <span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph4.svg"</span>, <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="files/graph4.svg"></p>
</div>
</div>
</div>
</section>
<section id="properties-of-ols-3" class="slide level2 smaller" data-background="#bfc4d9">
<h2>Properties of OLS</h2>
<p>Similarly, we can easily show that</p>
<p><span class="math display">\[\sum_i^nx_i(y_i - \hat{\alpha} - \hat{\beta_1} x_i) = 0\]</span></p>
<p>And that</p>
<p><span class="math display">\[\sum_i^nx_i\hat{\mu}  = 0\]</span></p>
<p>Meaning that the sample covariance between the X and the residual will be always zero.</p>
</section>
<section id="properties-of-ols-4" class="slide level2 smaller" data-background="#bfc4d9">
<h2>Properties of OLS</h2>
<div class="panel-tabset">
<ul id="tabset-14" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-14-1">R</a></li><li><a href="#tabset-14-2">Python</a></li><li><a href="#tabset-14-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-14-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb72-2"><a></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb72-3"><a></a>tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb72-4"><a></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb72-5"><a></a>  <span class="at">u =</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>),</span>
<span id="cb72-6"><a></a>  <span class="at">y =</span> <span class="fl">5.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">12</span><span class="sc">*</span>u <span class="co"># notice that I am defining the beta1 here. The 5.5 is the "true" beta we want to estimate.</span></span>
<span id="cb72-7"><a></a>) </span>
<span id="cb72-8"><a></a>reg_tb <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>tb) </span>
<span id="cb72-9"><a></a>tb <span class="ot">&lt;-</span> tb <span class="sc">%&gt;%</span> </span>
<span id="cb72-10"><a></a>  <span class="fu">mutate</span>(</span>
<span id="cb72-11"><a></a>    <span class="at">yhat1 =</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb72-12"><a></a>    <span class="at">yhat2 =</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> reg_tb<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>x, </span>
<span id="cb72-13"><a></a>    <span class="at">uhat1 =</span> <span class="fu">residuals</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, .)),</span>
<span id="cb72-14"><a></a>    <span class="at">uhat2 =</span> y <span class="sc">-</span> yhat2</span>
<span id="cb72-15"><a></a>  )</span>
<span id="cb72-16"><a></a>tb <span class="sc">%&gt;%</span> </span>
<span id="cb72-17"><a></a>  <span class="fu">lm</span>(uhat1 <span class="sc">~</span> x , .) <span class="sc">%&gt;%</span> </span>
<span id="cb72-18"><a></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>uhat1)) <span class="sc">+</span> </span>
<span id="cb72-19"><a></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb72-20"><a></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">color =</span> <span class="st">"black"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-39-3.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-14-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb73-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb73-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb73-4"><a></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb73-5"><a></a>obs <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb73-6"><a></a>x <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb73-7"><a></a>u <span class="op">=</span> np.random.normal(size<span class="op">=</span>obs)</span>
<span id="cb73-8"><a></a>y <span class="op">=</span> <span class="fl">5.5</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> u</span>
<span id="cb73-9"><a></a></span>
<span id="cb73-10"><a></a>X <span class="op">=</span> sm.add_constant(x)</span>
<span id="cb73-11"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb73-12"><a></a></span>
<span id="cb73-13"><a></a>tb <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: x, <span class="st">'u'</span>: u, <span class="st">'y'</span>: y})</span>
<span id="cb73-14"><a></a>tb[<span class="st">'yhat1'</span>] <span class="op">=</span> model.predict(X)</span>
<span id="cb73-15"><a></a>tb[<span class="st">'uhat1'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat1'</span>]</span>
<span id="cb73-16"><a></a>tb[<span class="st">'yhat2'</span>] <span class="op">=</span> model.params[<span class="dv">0</span>] <span class="op">+</span> model.params[<span class="dv">1</span>] <span class="op">*</span> x</span>
<span id="cb73-17"><a></a>tb[<span class="st">'uhat2'</span>] <span class="op">=</span> y <span class="op">-</span> tb[<span class="st">'yhat2'</span>]</span>
<span id="cb73-18"><a></a>model <span class="op">=</span> sm.OLS(tb[<span class="st">'uhat1'</span>], sm.add_constant(tb[<span class="st">'yhat1'</span>])).fit()</span>
<span id="cb73-19"><a></a><span class="co"># Create a scatter plot with a regression line</span></span>
<span id="cb73-20"><a></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">"whitegrid"</span>)</span>
<span id="cb73-21"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="fl">4.5</span>))</span>
<span id="cb73-22"><a></a>sns.scatterplot(x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'uhat1'</span>, data<span class="op">=</span>tb, size<span class="op">=</span><span class="fl">0.05</span>, color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb73-23"><a></a>sns.regplot(x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'uhat1'</span>, data<span class="op">=</span>tb, scatter<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb73-24"><a></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb73-25"><a></a>plt.ylabel(<span class="st">'uhat1'</span>)</span>
<span id="cb73-26"><a></a>plt.title(<span class="st">'Scatter Plot of uhat1 vs. x'</span>)</span>
<span id="cb73-27"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-40-1.png" class="quarto-figure quarto-figure-center" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-14-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb74-1"><a></a><span class="kw">set</span> <span class="dv">seed</span> 1 </span>
<span id="cb74-2"><a></a><span class="kw">set</span> <span class="kw">obs</span> 10000 </span>
<span id="cb74-3"><a></a><span class="kw">gen</span> x = rnormal() </span>
<span id="cb74-4"><a></a><span class="kw">gen</span> u  = rnormal() </span>
<span id="cb74-5"><a></a><span class="kw">gen</span> <span class="fu">y</span>  = 5.5*x + 12*u </span>
<span id="cb74-6"><a></a><span class="kw">qui</span> <span class="kw">reg</span> <span class="fu">y</span> x </span>
<span id="cb74-7"><a></a><span class="kw">predict</span> yhat1 </span>
<span id="cb74-8"><a></a><span class="kw">predict</span> uhat1, residual </span>
<span id="cb74-9"><a></a><span class="kw">twoway</span> (<span class="kw">lfit</span> uhat1 x , lcolor(<span class="bn">black</span>) lwidth(large)) (<span class="kw">scatter</span> uhat1 x , mcolor(<span class="bn">black</span>) <span class="bn">msymbol</span>(point))</span>
<span id="cb74-10"><a></a><span class="kw">qui</span> <span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph5.svg"</span>, <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="files/graph5.svg"></p>
</div>
</div>
</div>
</section>
<section id="properties-of-ols-5" class="slide level2 smaller" data-background="#bfc4d9">
<h2>Properties of OLS</h2>
<p>Let’s say you estimate a model and find the <span class="math inline">\(\hat{\mu}\)</span>.</p>
<p>If you calculate the correlation between the X and <span class="math inline">\(\hat{\mu}\)</span>, you will find zero.</p>
<p><strong>This is by construction!</strong> It is not an evidence that CMI is nos violated.</p>
<p>In fact, the OLS “assumes” and “forces” zero correlation.</p>
<p><strong>It is intuitive: if you are “forcing” zero correlation when the correlation is not in fact zero, your coefficients will be biased.</strong></p>
<p>The previous graphs actually show zero correlation. But that is expected and does not suggest the model is not violating CMI.</p>
<p><strong>At the end of the day, CMI is untestable and unverifiable</strong>.</p>
</section></section>
<section>
<section id="goodness-of-fit" class="title-slide slide level1 smaller center" data-background="#dff2c7">
<h1>Goodness-of-fit</h1>

</section>
<section id="goodness-of-fit-1" class="slide level2 smaller" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>
<p><strong>Understanding what SSR, SSE and SST mean</strong></p>
<ul>
<li>SSE = Sum of Squares Explained = <span class="math inline">\(\sum_i^n(\hat{y_i}-\bar{y})^2\)</span></li>
<li>SSR = Sum of Squares Residuals = <span class="math inline">\(\sum_i^n\hat{\mu}^2\)</span></li>
<li>SST = Sum of Squares Total = SSE + SSR = <span class="math inline">\(\sum_i^n(y_i-\hat{y_i})^2\)</span></li>
</ul>
<p>R-squared is simply the ratio of portion explained over the total that could be explained.</p>
<p><span class="math display">\[R^2 = \frac{SSE}{SST} = 1-\frac{SSR}{SST}\]</span></p>
</section>
<section id="goodness-of-fit-2" class="slide level2 smaller" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>

<img data-src="figs/R2.jpg" class="r-stretch"></section>
<section id="goodness-of-fit-3" class="slide level2 smaller scrollable" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>
<p>You can think this way:</p>
<ol type="1">
<li>If X does not explain Y, then the best predictor of Y is <span class="math inline">\(\bar{y}\)</span>. In that case, your model does not explain anything of Y, thus <span class="math inline">\(R^2\)</span> is zero, and <span class="math inline">\(\hat{y_i}=\bar{y}\)</span></li>
</ol>
<div class="fragment">
<ol start="2" type="1">
<li>If X partially explains Y, then <span class="math inline">\(\hat{y_i} \neq \bar{y}\)</span>, meaning that <span class="math inline">\(\hat{y_i}\)</span> has some inclination (like the figure next slide). This means that <span class="math inline">\(SSE&gt;0\)</span> and your <span class="math inline">\(R^2&gt;0\)</span> but <span class="math inline">\(R^2&lt;1\)</span></li>
</ol>
</div>
<div class="fragment">
<ol start="3" type="1">
<li>Whatever is not explained by <span class="math inline">\(\hat{y_i}\)</span> is left to <span class="math inline">\(\sum_i^2\hat{\mu}^2\)</span>, meaning that SSR will be non-zero.</li>
</ol>
</div>
<div class="fragment">
<ol start="4" type="1">
<li>The ratio of the portion that you can explain by <span class="math inline">\(\hat{y_i}\)</span> over the total that is to be explained <span class="math inline">\(y_i-\hat{y_i}\)</span> if the <span class="math inline">\(R^2\)</span>.</li>
</ol>
</div>
</section>
<section id="goodness-of-fit-4" class="slide level2 smaller" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>
<div class="panel-tabset">
<ul id="tabset-15" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-15-1">R</a></li><li><a href="#tabset-15-2">Python</a></li><li><a href="#tabset-15-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-15-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a></a><span class="fu">library</span>(foreign) <span class="co"># importing dataset from a stata dta file</span></span>
<span id="cb75-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb75-3"><a></a><span class="fu">attach</span>(data)</span>
<span id="cb75-4"><a></a><span class="co"># Statistics of salary </span></span>
<span id="cb75-5"><a></a><span class="fu">mean</span>(salary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1281.12</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a></a><span class="co"># OLS model</span></span>
<span id="cb77-2"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb77-3"><a></a>salaryhat <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model)                      <span class="co"># Predict values for dependent variable</span></span>
<span id="cb77-4"><a></a>uhat <span class="ot">&lt;-</span> <span class="fu">resid</span>(model)                            <span class="co"># Predict regression residuals</span></span>
<span id="cb77-5"><a></a>salarymean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(salary),<span class="fu">length</span>(salary))  <span class="co"># Generating the mean of salary </span></span>
<span id="cb77-6"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = salary ~ roe)

Residuals:
    Min      1Q  Median      3Q     Max 
-1160.2  -526.0  -254.0   138.8 13499.9 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   963.19     213.24   4.517 1.05e-05 ***
roe            18.50      11.12   1.663   0.0978 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1367 on 207 degrees of freedom
Multiple R-squared:  0.01319,   Adjusted R-squared:  0.008421 
F-statistic: 2.767 on 1 and 207 DF,  p-value: 0.09777</code></pre>
</div>
</div>
</div>
<div id="tabset-15-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb79-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb79-3"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb79-4"><a></a><span class="bu">print</span>(data[<span class="st">'salary'</span>].mean())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1281.1196172248804</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a></a><span class="co"># OLS model</span></span>
<span id="cb81-2"><a></a>X <span class="op">=</span> data[<span class="st">'roe'</span>]</span>
<span id="cb81-3"><a></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb81-4"><a></a>y <span class="op">=</span> data[<span class="st">'salary'</span>]</span>
<span id="cb81-5"><a></a></span>
<span id="cb81-6"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()  <span class="co"># Fit the linear regression model</span></span>
<span id="cb81-7"><a></a>salaryhat <span class="op">=</span> model.fittedvalues  <span class="co"># Predicted values for the dependent variable</span></span>
<span id="cb81-8"><a></a>uhat <span class="op">=</span> model.resid  <span class="co"># Predict regression residuals</span></span>
<span id="cb81-9"><a></a>salarymean <span class="op">=</span> pd.Series([y.mean()] <span class="op">*</span> <span class="bu">len</span>(y))  <span class="co"># Generating the mean of salary</span></span>
<span id="cb81-10"><a></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.013
Model:                            OLS   Adj. R-squared:                  0.008
Method:                 Least Squares   F-statistic:                     2.767
Date:                qua, 11 set 2024   Prob (F-statistic):             0.0978
Time:                        16:20:17   Log-Likelihood:                -1804.5
No. Observations:                 209   AIC:                             3613.
Df Residuals:                     207   BIC:                             3620.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        963.1913    213.240      4.517      0.000     542.790    1383.592
roe           18.5012     11.123      1.663      0.098      -3.428      40.431
==============================================================================
Omnibus:                      311.096   Durbin-Watson:                   2.105
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31120.902
Skew:                           6.915   Prob(JB):                         0.00
Kurtosis:                      61.158   Cond. No.                         43.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-15-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb83-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb83-2"><a></a><span class="kw">sum</span> salary </span>
<span id="cb83-3"><a></a><span class="kw">reg</span> salary roe </span>
<span id="cb83-4"><a></a><span class="kw">predict</span> salaryhat , <span class="kw">xb</span>              </span>
<span id="cb83-5"><a></a><span class="kw">predict</span> uhat, <span class="kw">resid</span>                 </span>
<span id="cb83-6"><a></a><span class="kw">egen</span> salarymean = <span class="kw">mean</span>(salary)      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
      salary |        209     1281.12    1372.345        223      14822

      Source |       SS           df       MS      Number of obs   =       209
-------------+----------------------------------   F(1, 207)       =      2.77
       Model |  5166419.04         1  5166419.04   Prob &gt; F        =    0.0978
    Residual |   386566563       207  1867471.32   R-squared       =    0.0132
-------------+----------------------------------   Adj R-squared   =    0.0084
       Total |   391732982       208  1883331.64   Root MSE        =    1366.6

------------------------------------------------------------------------------
      salary | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
         roe |   18.50119   11.12325     1.66   0.098    -3.428196    40.43057
       _cons |   963.1913   213.2403     4.52   0.000     542.7902    1383.592
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="goodness-of-fit-5" class="slide level2 smaller" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>
<div class="panel-tabset">
<ul id="tabset-16" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-16-1">R</a></li><li><a href="#tabset-16-2">Python</a></li><li><a href="#tabset-16-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-16-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a></a><span class="fu">library</span>(foreign) <span class="co"># importing dataset from a stata dta file</span></span>
<span id="cb85-2"><a></a>mydata <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb85-3"><a></a><span class="fu">attach</span>(mydata)</span>
<span id="cb85-4"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb85-5"><a></a>salaryhat <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model)                      <span class="co"># Predict values for dependent variable</span></span>
<span id="cb85-6"><a></a>uhat <span class="ot">&lt;-</span> <span class="fu">resid</span>(model)                            <span class="co"># Predict regression residuals</span></span>
<span id="cb85-7"><a></a>salarymean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(salary),<span class="fu">length</span>(salary))  <span class="co"># Generating the mean of salary </span></span>
<span id="cb85-8"><a></a><span class="co"># r-squared is simply the ratio of portion explained over total that could be explained - Understanding what SSR, SSE and SST mean </span></span>
<span id="cb85-9"><a></a><span class="fu">plot</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb85-10"><a></a><span class="fu">abline</span>(<span class="fu">lm</span>(salary <span class="sc">~</span> roe), <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb85-11"><a></a><span class="fu">abline</span>(<span class="fu">lm</span>(salarymean <span class="sc">~</span> roe), <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-45-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-16-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb86-2"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb86-3"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb86-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb86-5"><a></a>X <span class="op">=</span> data[[<span class="st">'roe'</span>]]</span>
<span id="cb86-6"><a></a>y <span class="op">=</span> data[<span class="st">'salary'</span>]</span>
<span id="cb86-7"><a></a>salarymean <span class="op">=</span> np.repeat(y.mean(), <span class="bu">len</span>(y))</span>
<span id="cb86-8"><a></a>X_mean <span class="op">=</span> X.mean()</span>
<span id="cb86-9"><a></a>y_mean <span class="op">=</span> y.mean()</span>
<span id="cb86-10"><a></a>slope <span class="op">=</span> np.<span class="bu">sum</span>((X <span class="op">-</span> X_mean) <span class="op">*</span> (y <span class="op">-</span> y_mean)) <span class="op">/</span> np.<span class="bu">sum</span>((X <span class="op">-</span> X_mean) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb86-11"><a></a>intercept <span class="op">=</span> y_mean <span class="op">-</span> slope <span class="op">*</span> X_mean</span>
<span id="cb86-12"><a></a>salaryhat <span class="op">=</span> slope <span class="op">*</span> X <span class="op">+</span> intercept</span>
<span id="cb86-13"><a></a><span class="co"># Plotting the data and regression lines</span></span>
<span id="cb86-14"><a></a>plt.scatter(X, y,  alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb86-15"><a></a>plt.plot(X, salaryhat,  color<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb86-16"><a></a>plt.plot(X, salarymean, color<span class="op">=</span><span class="st">'red'</span>,  linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb86-17"><a></a>plt.xlabel(<span class="st">'roe'</span>)</span>
<span id="cb86-18"><a></a>plt.ylabel(<span class="st">'salary'</span>)</span>
<span id="cb86-19"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-46-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-16-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb87-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb87-2"><a></a><span class="kw">sum</span> salary , <span class="kw">d</span></span>
<span id="cb87-3"><a></a><span class="kw">reg</span> salary roe </span>
<span id="cb87-4"><a></a><span class="kw">predict</span> salaryhat , <span class="kw">xb</span>              </span>
<span id="cb87-5"><a></a><span class="kw">predict</span> uhat, <span class="kw">resid</span>                 </span>
<span id="cb87-6"><a></a><span class="kw">egen</span> salarymean = <span class="kw">mean</span>(salary)      </span>
<span id="cb87-7"><a></a></span>
<span id="cb87-8"><a></a><span class="kw">twoway</span> (<span class="kw">scatter</span> salary roe) (<span class="kw">lfit</span> salary roe) (<span class="kw">lfit</span> salarymean roe) </span>
<span id="cb87-9"><a></a><span class="kw">qui</span> <span class="kw">graph</span> <span class="kw">export</span> <span class="st">"files/graph4_6.svg"</span>, <span class="kw">replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="files/graph4_6.svg"></p>
</div>
</div>
</div>
</section>
<section id="goodness-of-fit-6" class="slide level2 smaller" data-background="#dff2c7">
<h2>Goodness-of-fit</h2>
<p>Manually calculating <span class="math inline">\(R^2\)</span></p>
<div class="panel-tabset">
<ul id="tabset-17" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-17-1">R</a></li><li><a href="#tabset-17-2">Python</a></li><li><a href="#tabset-17-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-17-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a></a><span class="fu">library</span>(foreign) <span class="co"># importing dataset from a stata dta file</span></span>
<span id="cb88-2"><a></a>mydata <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb88-3"><a></a><span class="fu">attach</span>(mydata)</span>
<span id="cb88-4"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb88-5"><a></a>salaryhat <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model)                      <span class="co"># Predict values for dependent variable</span></span>
<span id="cb88-6"><a></a>uhat <span class="ot">&lt;-</span> <span class="fu">resid</span>(model)                            <span class="co"># Predict regression residuals</span></span>
<span id="cb88-7"><a></a>salarymean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(salary),<span class="fu">length</span>(salary))  <span class="co"># Generating the mean of salary </span></span>
<span id="cb88-8"><a></a></span>
<span id="cb88-9"><a></a><span class="co"># r-squared is simply the ratio of portion explained over total that could be explained</span></span>
<span id="cb88-10"><a></a>ssr  <span class="ot">&lt;-</span> <span class="fu">sum</span>(uhat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-11"><a></a>ssrB <span class="ot">&lt;-</span> <span class="fu">sum</span>((salary    <span class="sc">-</span> salaryhat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-12"><a></a>sst  <span class="ot">&lt;-</span> <span class="fu">sum</span>((salary    <span class="sc">-</span> salarymean)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-13"><a></a>sse  <span class="ot">&lt;-</span> <span class="fu">sum</span>((salaryhat <span class="sc">-</span> salarymean)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-14"><a></a>sse <span class="sc">/</span> sst</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.01318862</code></pre>
</div>
</div>
</div>
<div id="tabset-17-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb90-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb90-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb90-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb90-5"><a></a>X <span class="op">=</span> data[<span class="st">'roe'</span>]</span>
<span id="cb90-6"><a></a>y <span class="op">=</span> data[<span class="st">'salary'</span>]</span>
<span id="cb90-7"><a></a>X <span class="op">=</span> sm.add_constant(X)  <span class="co"># Add a constant term (intercept)</span></span>
<span id="cb90-8"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb90-9"><a></a>salaryhat <span class="op">=</span> model.fittedvalues</span>
<span id="cb90-10"><a></a>uhat <span class="op">=</span> model.resid</span>
<span id="cb90-11"><a></a>salarymean <span class="op">=</span> np.repeat(y.mean(), <span class="bu">len</span>(y))</span>
<span id="cb90-12"><a></a><span class="co"># Calculate R-squared</span></span>
<span id="cb90-13"><a></a>ssr <span class="op">=</span> np.<span class="bu">sum</span>(uhat<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb90-14"><a></a>ssrB <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> salaryhat)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb90-15"><a></a>sst <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> salarymean)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb90-16"><a></a>sse <span class="op">=</span> np.<span class="bu">sum</span>((salaryhat <span class="op">-</span> salarymean)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb90-17"><a></a>rsquared <span class="op">=</span> sse <span class="op">/</span> sst</span>
<span id="cb90-18"><a></a><span class="bu">print</span>(rsquared)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.013188624081034118</code></pre>
</div>
</div>
</div>
<div id="tabset-17-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb92-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb92-2"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe </span>
<span id="cb92-3"><a></a><span class="kw">predict</span> salaryhat , <span class="kw">xb</span>              </span>
<span id="cb92-4"><a></a><span class="kw">predict</span> uhat, <span class="kw">resid</span>                 </span>
<span id="cb92-5"><a></a><span class="kw">egen</span> salarymean = <span class="kw">mean</span>(salary)      </span>
<span id="cb92-6"><a></a><span class="kw">egen</span> sst  = <span class="kw">total</span>((salary    - salarymean)^2)  </span>
<span id="cb92-7"><a></a><span class="kw">egen</span> ssr  = <span class="kw">total</span>((salary    - salaryhat)^2)</span>
<span id="cb92-8"><a></a><span class="kw">egen</span> ssrB = <span class="kw">total</span>(uhat^2)                   </span>
<span id="cb92-9"><a></a><span class="kw">egen</span> sse  = <span class="kw">total</span>((salaryhat - salarymean)^2)   </span>
<span id="cb92-10"><a></a><span class="kw">di</span> sse / sst</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>.01318862</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="variance-of-coefficients" class="title-slide slide level1 smaller center" data-background="#c4f5d7">
<h1>Variance of coefficients</h1>

</section>
<section id="variance-of-coefficients-1" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p>When we estimate coefficients we have some “error of estimation”.</p>
<ul>
<li><p>Basically, you are searching the “true” coefficient using a sample, which should be representative of the population but it is not the population itself.</p></li>
<li><p>This means that the coefficient estimated is estimated with error.</p></li>
<li><p>We would like (e.g., we will need) to impose some “structure” to that error.</p></li>
</ul>
</section>
<section id="variance-of-coefficients-2" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p><strong>Standard error and T-stat</strong></p>
<p>To assess if the variables are significantly related, you need to assess the significance of <span class="math inline">\(\beta\)</span> coefficients.</p>
<p>Using the example from Wooldridge, we know that the Beta of ROE is <code>18.591</code>, while the standard error of ROE is <code>11.123</code>.</p>
<div class="fragment">
<ul>
<li><p>The standard error is a measure of the accuracy of your estimate. If you find a large standard error, your estimate does not have good accuracy.</p></li>
<li><p>Ideally, you would find small standard errors, meaning that your coefficient is accurately estimated.</p></li>
<li><p>However, you do not have good control over the magnitude of the standard errors.</p></li>
</ul>
</div>
</section>
<section id="variance-of-coefficients-3" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p><strong>Standard error and T-stat</strong></p>
<p>If you have a large standard error, probably you coefficient will not be significantly different from zero. You can test whether your coefficient is significantly different from zero computing the t-statistics as follows:</p>
<p><span class="math display">\[t_{\beta} = \frac{\hat{\beta}}{se(\hat{\beta})}\]</span></p>
<p>If <span class="math inline">\(t_{\beta}\)</span> is large enough, you can say that <span class="math inline">\(\beta\)</span> is significantly different from zero. Usually, <span class="math inline">\(t_{\beta}\)</span> larger than 2 is enough to be significant.</p>
</section>
<section id="variance-of-coefficients-4" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p>In the previous example, you can find the t-stat manually as follows (<span class="math inline">\(t_{\beta} =\frac{\hat{\beta}}{se(\hat{\beta})}\)</span>):</p>
<div class="panel-tabset">
<ul id="tabset-18" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-18-1">R</a></li><li><a href="#tabset-18-2">Python</a></li><li><a href="#tabset-18-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-18-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a></a><span class="fu">library</span>(foreign) <span class="co"># importing dataset from a stata dta file</span></span>
<span id="cb94-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb94-3"><a></a><span class="fu">attach</span>(data)</span>
<span id="cb94-4"><a></a><span class="co"># OLS model</span></span>
<span id="cb94-5"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb94-6"><a></a><span class="fu">summary</span>(model)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>] <span class="sc">/</span> <span class="fu">summary</span>(model)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>] </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.663289</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a></a><span class="fu">summary</span>(model)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.663289</code></pre>
</div>
</div>
</div>
<div id="tabset-18-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb98-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb98-3"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb98-4"><a></a><span class="co"># OLS model</span></span>
<span id="cb98-5"><a></a>X <span class="op">=</span> data[<span class="st">'roe'</span>]</span>
<span id="cb98-6"><a></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb98-7"><a></a>y <span class="op">=</span> data[<span class="st">'salary'</span>]</span>
<span id="cb98-8"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()  </span>
<span id="cb98-9"><a></a><span class="co"># Extract and calculate specific coefficients</span></span>
<span id="cb98-10"><a></a>coef_beta <span class="op">=</span> model.params[<span class="st">'roe'</span>]</span>
<span id="cb98-11"><a></a>coef_std_error <span class="op">=</span> model.bse[<span class="st">'roe'</span>]</span>
<span id="cb98-12"><a></a><span class="co"># Calculate t-value</span></span>
<span id="cb98-13"><a></a>t_value <span class="op">=</span> coef_beta <span class="op">/</span> coef_std_error</span>
<span id="cb98-14"><a></a><span class="co"># Print the coefficient and t-value</span></span>
<span id="cb98-15"><a></a><span class="bu">print</span>(<span class="st">"Coefficient (beta):"</span>, coef_beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficient (beta): 18.501186345214933</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a></a><span class="bu">print</span>(<span class="st">"Standard Error:"</span>, coef_std_error)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error: 11.123250903287634</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a></a><span class="bu">print</span>(<span class="st">"t-value:"</span>, t_value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>t-value: 1.6632894920806511</code></pre>
</div>
</div>
</div>
<div id="tabset-18-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb104-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb104-2"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe </span>
<span id="cb104-3"><a></a><span class="kw">local</span> beta = _b[roe]</span>
<span id="cb104-4"><a></a><span class="kw">local</span> std_error = _se[roe]</span>
<span id="cb104-5"><a></a><span class="kw">local</span> t_value = <span class="ot">`beta'</span> / <span class="ot">`std_error'</span></span>
<span id="cb104-6"><a></a><span class="kw">display</span> <span class="st">"Coefficient (beta): "</span> <span class="ot">`beta'</span></span>
<span id="cb104-7"><a></a><span class="kw">display</span> <span class="st">"Standard Error: "</span> <span class="ot">`std_error'</span></span>
<span id="cb104-8"><a></a><span class="kw">display</span> <span class="st">"t-value: "</span> <span class="ot">`t_value'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficient (beta): 18.501186

Standard Error: 11.123251

t-value: 1.6632895</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="variance-of-coefficients-5" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p>Naturally, the previous analysis requires an estimate of <span class="math inline">\(\beta\)</span> and an estimate of the <span class="math inline">\(\beta\)</span>’s standard error.</p>
<p>The standard error can be defined as:</p>
<p><span class="math display">\[se(\hat{\beta_1})=\frac{\hat{\sigma}}{\sqrt{SST_x}}\]</span></p>
<ul>
<li>Where <span class="math inline">\(\hat{\sigma}\)</span> is the standard deviation of the error term in the regression, which can be calculated as:</li>
</ul>
<p><span class="math display">\[\hat{\sigma} = \sqrt{\frac{SSR}{n-2}}\]</span></p>
<pre><code>- The $n-2$ here is an adjustment for the degrees of freedom in the regression.</code></pre>
<ul>
<li>SST is defined as before <span class="math inline">\(\sum_i^n(y_i-\hat{y_i})^2\)</span></li>
</ul>
</section>
<section id="variance-of-coefficients-6" class="slide level2 smaller" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<div class="panel-tabset">
<ul id="tabset-19" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-19-1">R</a></li><li><a href="#tabset-19-2">Python</a></li><li><a href="#tabset-19-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-19-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a></a><span class="fu">library</span>(foreign) <span class="co"># importing dataset from a stata dta file</span></span>
<span id="cb107-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb107-3"><a></a><span class="fu">attach</span>(data)</span>
<span id="cb107-4"><a></a><span class="co"># OLS model</span></span>
<span id="cb107-5"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe)</span>
<span id="cb107-6"><a></a><span class="co"># Extract the standard error of the coefficient for 'roe'</span></span>
<span id="cb107-7"><a></a><span class="fu">summary</span>(model)<span class="sc">$</span>coefficients[<span class="st">"roe"</span>, <span class="st">"Std. Error"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.12325</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a></a><span class="co">#calculating manually</span></span>
<span id="cb109-2"><a></a><span class="co"># Extract the residuals</span></span>
<span id="cb109-3"><a></a>residuals <span class="ot">&lt;-</span> <span class="fu">resid</span>(model)</span>
<span id="cb109-4"><a></a><span class="co"># Number of observations (n)</span></span>
<span id="cb109-5"><a></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(residuals)</span>
<span id="cb109-6"><a></a><span class="co"># Calculate the mean of the independent variable (roe)</span></span>
<span id="cb109-7"><a></a>roe_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(roe)</span>
<span id="cb109-8"><a></a><span class="co"># Calculate the sum of squared deviations of roe from its mean (SXX)</span></span>
<span id="cb109-9"><a></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>((roe <span class="sc">-</span> roe_mean)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb109-10"><a></a><span class="co"># Calculate the sum of squared errors (SSE)</span></span>
<span id="cb109-11"><a></a>SSR <span class="ot">&lt;-</span> <span class="fu">sum</span>(residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb109-12"><a></a><span class="co"># Calculate the standard error of beta</span></span>
<span id="cb109-13"><a></a>Sd_beta <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(SSR <span class="sc">/</span> ((n <span class="sc">-</span> <span class="dv">2</span>)))</span>
<span id="cb109-14"><a></a><span class="co"># Calculate S.E</span></span>
<span id="cb109-15"><a></a>Se_beta <span class="ot">&lt;-</span> Sd_beta <span class="sc">/</span> <span class="fu">sqrt</span>(SST)</span>
<span id="cb109-16"><a></a><span class="co"># Print the standard error of beta</span></span>
<span id="cb109-17"><a></a><span class="fu">print</span>(Se_beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.12325</code></pre>
</div>
</div>
</div>
<div id="tabset-19-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb111-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb111-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb111-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.dta"</span>)</span>
<span id="cb111-5"><a></a>X <span class="op">=</span> data[<span class="st">'roe'</span>]</span>
<span id="cb111-6"><a></a>y <span class="op">=</span> data[<span class="st">'salary'</span>]</span>
<span id="cb111-7"><a></a>X <span class="op">=</span> sm.add_constant(X)  </span>
<span id="cb111-8"><a></a>model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb111-9"><a></a><span class="co"># Extract the standard error of the coefficient for 'roe'</span></span>
<span id="cb111-10"><a></a>beta_se_summary <span class="op">=</span> model.bse[<span class="st">'roe'</span>]</span>
<span id="cb111-11"><a></a><span class="bu">print</span>(<span class="st">"Standard Error (from summary):"</span>, beta_se_summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (from summary): 11.123250903287634</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a></a><span class="co"># Calculate it manually</span></span>
<span id="cb113-2"><a></a><span class="co"># Extract the residuals</span></span>
<span id="cb113-3"><a></a>residuals <span class="op">=</span> model.resid</span>
<span id="cb113-4"><a></a><span class="co"># Number of observations (n)</span></span>
<span id="cb113-5"><a></a>n <span class="op">=</span> <span class="bu">len</span>(residuals)</span>
<span id="cb113-6"><a></a><span class="co"># Calculate the mean of the independent variable (roe)</span></span>
<span id="cb113-7"><a></a>roe_mean <span class="op">=</span> X[<span class="st">'roe'</span>].mean()</span>
<span id="cb113-8"><a></a><span class="co"># Calculate the sum of squared deviations of roe from its mean (SST)</span></span>
<span id="cb113-9"><a></a>SST <span class="op">=</span> np.<span class="bu">sum</span>((X[<span class="st">'roe'</span>] <span class="op">-</span> roe_mean) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb113-10"><a></a><span class="co"># Calculate the sum of squared errors (SSE)</span></span>
<span id="cb113-11"><a></a>SSE <span class="op">=</span> np.<span class="bu">sum</span>(residuals <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb113-12"><a></a><span class="co"># Calculate the standard error of beta (Sd_beta)</span></span>
<span id="cb113-13"><a></a>Sd_beta <span class="op">=</span> np.sqrt(SSE <span class="op">/</span> (n <span class="op">-</span> <span class="dv">2</span>))</span>
<span id="cb113-14"><a></a><span class="co"># Calculate SE_beta</span></span>
<span id="cb113-15"><a></a>SE_beta <span class="op">=</span> Sd_beta <span class="op">/</span> np.sqrt(SST)</span>
<span id="cb113-16"><a></a><span class="bu">print</span>(<span class="st">"Standard Error (manually calculated):"</span>, SE_beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (manually calculated): 11.123250601798315</code></pre>
</div>
</div>
</div>
<div id="tabset-19-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb115-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb115-2"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe </span>
<span id="cb115-3"><a></a><span class="kw">gen</span> beta_se_summary = _se[roe]</span>
<span id="cb115-4"><a></a><span class="kw">gen</span> n = _N</span>
<span id="cb115-5"><a></a><span class="kw">predict</span> residuals, residuals</span>
<span id="cb115-6"><a></a><span class="kw">sum</span> roe, <span class="kw">meanonly</span></span>
<span id="cb115-7"><a></a><span class="kw">gen</span> roe_diff = roe - <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb115-8"><a></a><span class="kw">egen</span> roe_diff_sq = <span class="kw">total</span>(roe_diff^2)</span>
<span id="cb115-9"><a></a><span class="kw">gen</span> residuals_sq = residuals^2</span>
<span id="cb115-10"><a></a><span class="kw">egen</span> residuals_sq_sum = <span class="kw">total</span>(residuals_sq)</span>
<span id="cb115-11"><a></a><span class="kw">gen</span> Sd_beta = <span class="fu">sqrt</span>(residuals_sq_sum / (n - 2))</span>
<span id="cb115-12"><a></a><span class="kw">gen</span> SE_beta = Sd_beta / <span class="fu">sqrt</span>(roe_diff_sq)</span>
<span id="cb115-13"><a></a><span class="kw">display</span> <span class="st">"Standard Error (from summary): "</span> <span class="kw">sum</span>(beta_se_summary)</span>
<span id="cb115-14"><a></a><span class="kw">display</span> <span class="st">"Standard Error (manually calculated): "</span> <span class="kw">sum</span>(SE_beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (from summary): 11.123251

Standard Error (manually calculated): 11.123251</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="variance-of-coefficients-7" class="slide level2 smaller scrollable" data-background="#c4f5d7">
<h2>Variance of coefficients</h2>
<p><strong>Another comment:</strong></p>
<p><span class="math display">\[se(\hat{\beta_1})=\frac{\hat{\sigma}}{\sqrt{SST_x}}\]</span></p>
<ol type="1">
<li><p>The larger <span class="math inline">\(\hat{\sigma}\)</span> is, the larger the variance of <span class="math inline">\(\beta\)</span>. That is, the more “noise” in the association between x and Y, the harder it is to learn something about <span class="math inline">\(\beta\)</span>.</p></li>
<li><p>However, more variation in x, the larger the SST, so the smaller is the variance of <span class="math inline">\(\beta\)</span>.</p></li>
</ol>
</section></section>
<section>
<section id="robust-standard-errors" class="title-slide slide level1 smaller center" data-background="#e0cafc">
<h1>Robust standard errors</h1>

</section>
<section id="robust-standard-errors-1" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p>Looking at both equations below:</p>
<p><span class="math display">\[t_{\beta} = \frac{\hat{\beta}}{se(\hat{\beta})}\]</span></p>
<p><span class="math display">\[se(\hat{\beta_1})=\frac{\hat{\sigma}}{\sqrt{SST_x}}\]</span></p>
<p><strong>What happens if <span class="math inline">\(\hat{\sigma}\)</span> is not constant (for the values of x)?</strong></p>
<p><strong>In other words, how realistic is to assume that the variance in the errors is the same for all slices of x?</strong></p>
<p><strong>Can you think of an example where that may happen?</strong></p>
</section>
<section id="robust-standard-errors-2" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p><strong>Earnings = f(education)</strong></p>
<p>PhD have a higher variance of earnings than non-educated people.</p>
<div class="fragment">
<p><strong>Leveragge=f(Size)</strong></p>
<p>It is quite possible that small firms will have less options of leverage than large companies.</p>
<p>This means that a sub-sample of large companies will have higher variance in the leverage decisions (and thus the error terms) than the sub-sample of small firms</p>
</div>
</section>
<section id="robust-standard-errors-3" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p>One of the key assumptions in OLS estimators is homoscedasticity</p>
<p>That is, the assumption is that the variance of the errors is homoscedastic (constant variance in all slices of X).</p>
<p>It means that throughout all observations, the error term shows the <strong>same variance</strong>.</p>
<p>If errors are not homoscedastic, we have the heteroscedasticity problem.</p>
<div class="fragment">
<p>Heteroskedasticity <strong>does not cause bias or inconsistency in the OLS estimators</strong> of the <span class="math inline">\(\beta\)</span> like the OVB would.</p>
<p>It also does not affect the <span class="math inline">\(R^2\)</span>.</p>
<p><strong>What Heteroscedasticity does is to bias the standard errors of the estimates.</strong></p>
</div>
</section>
<section id="robust-standard-errors-4" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>

<img data-src="files/homoscedasticity.png" class="r-stretch"></section>
<section id="robust-standard-errors-5" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>

<img data-src="files/heteroscedasticity.png" class="r-stretch"></section>
<section id="robust-standard-errors-6" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p><strong>Homoskedascticity</strong> = Constant <span class="math inline">\(\hat{\sigma}\)</span> to all slices of X.</p>
<p><strong>Heteroskedascticity</strong> = Non-constant <span class="math inline">\(\hat{\sigma}\)</span> to all slices of X.</p>
<p><strong>Without homoskedascticity, OLS no longer has the minimum mean squared errors</strong>, which means that the <em>estimated standard errors are biased</em>, which in turn creates bias in the t-stat and the inference you’ll make with your model.</p>
<div class="fragment">
<p>Fortunately, we have an easy solution for that.</p>
<p><span class="math display">\[Var(\hat{\beta_1}) = \frac{\sum_i^n(x_i-\bar{x})^2\hat{\mu}^2}{SST^2_x}\]</span></p>
<p>This formula simply “includes” the heteroskedascticity in the calculation of <span class="math inline">\(Var(\hat{\beta_1})\)</span>, meaning this correct the estimated standard deviation to heteroskedascticity.</p>
<p>We call this correction as <strong>Robust Standard Errors</strong> (White Robust).</p>
</div>
<div class="fragment">
<p>In other words, you should always use Robust Standard Errors. It is easy to use it with R.</p>
</div>
</section>
<section id="robust-standard-errors-7" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p><strong>Using Robust Standard-errors.</strong></p>
<div class="panel-tabset">
<ul id="tabset-20" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-20-1">R</a></li><li><a href="#tabset-20-2">Python</a></li><li><a href="#tabset-20-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-20-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a></a><span class="fu">library</span>(sandwich)</span>
<span id="cb117-2"><a></a><span class="fu">library</span>(foreign) </span>
<span id="cb117-3"><a></a><span class="fu">library</span>(lmtest)</span>
<span id="cb117-4"><a></a></span>
<span id="cb117-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.DTA"</span>)</span>
<span id="cb117-6"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe, <span class="at">data =</span> data)</span>
<span id="cb117-7"><a></a>robust_model <span class="ot">&lt;-</span> <span class="fu">coeftest</span>(model, <span class="at">vcov =</span> <span class="fu">vcovHC</span>(model, <span class="at">type =</span> <span class="st">"HC3"</span>))</span>
<span id="cb117-8"><a></a>SE_beta_robust <span class="ot">&lt;-</span> robust_model[<span class="st">"roe"</span>, <span class="st">"Std. Error"</span>]</span>
<span id="cb117-9"><a></a><span class="fu">cat</span>(<span class="st">"Robust Standard Error :"</span>, SE_beta_robust, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Robust Standard Error : 6.899434 </code></pre>
</div>
</div>
</div>
<div id="tabset-20-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb119-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb119-3"><a></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb119-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.DTA"</span>)</span>
<span id="cb119-5"><a></a>model <span class="op">=</span> smf.ols(<span class="st">"salary ~ roe"</span>, data<span class="op">=</span>data)</span>
<span id="cb119-6"><a></a>results <span class="op">=</span> model.fit(cov_type<span class="op">=</span><span class="st">'HC3'</span>)  </span>
<span id="cb119-7"><a></a>SE_beta_robust <span class="op">=</span> results.bse[<span class="st">'roe'</span>]</span>
<span id="cb119-8"><a></a><span class="bu">print</span>(<span class="st">"Robust Standard Error :"</span>, SE_beta_robust)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Robust Standard Error : 6.899433834797476</code></pre>
</div>
</div>
</div>
<div id="tabset-20-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb121-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb121-2"><a></a></span>
<span id="cb121-3"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe </span>
<span id="cb121-4"><a></a><span class="kw">gen</span> beta_se_non = _se[roe]</span>
<span id="cb121-5"><a></a></span>
<span id="cb121-6"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe , <span class="kw">robust</span></span>
<span id="cb121-7"><a></a><span class="kw">gen</span> beta_se_summary = _se[roe]</span>
<span id="cb121-8"><a></a></span>
<span id="cb121-9"><a></a><span class="kw">di</span> <span class="st">"Standard Error (non-robust): "</span> <span class="kw">sum</span>(beta_se_non)</span>
<span id="cb121-10"><a></a><span class="kw">di</span> <span class="st">"Standard Error (robust): "</span> <span class="kw">sum</span>(beta_se_summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (non-robust): 11.123251

Standard Error (robust): 6.8294482</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="robust-standard-errors-8" class="slide level2 smaller" data-background="#e0cafc">
<h2>Robust standard errors</h2>
<p>Notice that the standard errors have changed quite significantly in this example.</p>
<p>Usually, the robust standard errors are larger than the traditional ones in empirical works.</p>
<p><strong>But, in this example, they are smaller.</strong></p>
<div class="fragment">
<p>Perhaps more importantly:</p>
<p><strong>Once the S.e. change, you should expect that the t-stat of the estimates also change.</strong></p>
</div>
<div class="fragment">
<p><strong>Final comment</strong>: robust standard errors are robust in the case of homoskedasticity.</p>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p>Thus, you should always use robust S.E.</p>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="clustered-standard-errors" class="title-slide slide level1 smaller center" data-background="#edc5d1">
<h1>Clustered standard errors</h1>

</section>
<section id="clustered-standard-errors-1" class="slide level2 smaller" data-background="#edc5d1">
<h2>Clustered standard errors</h2>
<p>Almost always, someone will ask you whether you clustered your standard errors.</p>
<p><strong>The intuition is the following:</strong></p>
<ul>
<li><p>When you do not cluster, you are assuming that all observations are independently and identically distributed (i.i.d.), which may or may not be true.</p></li>
<li><p>Imagine you are studying the effect of class size on students achievement.</p></li>
<li><p>How much of a effect would <strong>have the teacher of a class</strong>?</p></li>
</ul>
<div class="fragment">
<ul>
<li><p>In this design, the teacher influences the achievement of all the students in the same class, and one teacher cannot be at two classes at the same time.</p></li>
<li><p>Thus, it would be wise to cluster the errors at the class-level. This assumes that the residual of each individual is clustered with the other individuals in the same class.</p></li>
</ul>
</div>
<div class="fragment">
<p>In principle, clustering solves any form of dependence of the residuals in your data.</p>
</div>
</section>
<section id="clustered-standard-errors-2" class="slide level2 smaller" data-background="#edc5d1">
<h2>Clustered standard errors</h2>
<p>In corporate finance/accounting research panel data research, the tradition is to cluster at the <strong>firm-level</strong>.</p>
<ul>
<li>The reason is that the observations of the same firm are not independent trough time, thus are correlated.</li>
</ul>
<p>But, there is a lot of debate about this decision.</p>
<div class="fragment">
<p>The tip is to cluster where the <strong>randomness exist</strong>. That is quite subjective. In the class size example, the <strong>randomness</strong> comes out of the teacher, since each teacher has their own ways of teaching (materials, resources, etc.).</p>
</div>
<div class="fragment">
<p>But, it is a good practice to stress this decision a bit in your own research by <strong>also showing results with clustered s.e. at the industry-level</strong>.</p>
</div>
<div class="fragment">
<p><strong>Final tip</strong>: usually the minimum number of cluster is about 30. Less than that might be insufficient (but, again, the guidance in this topic is very subjective).</p>
</div>
</section>
<section id="clustered-standard-errors-3" class="slide level2 smaller" data-background="#edc5d1">
<h2>Clustered standard errors</h2>
<p>The clustered standard errors are different because I am fabricating the clusters here for the sake of the coding.</p>
<p>In your real research, you would have the cluster at hands.</p>
<div class="panel-tabset">
<ul id="tabset-21" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-21-1">R</a></li><li><a href="#tabset-21-2">Python</a></li><li><a href="#tabset-21-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-21-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a></a><span class="fu">library</span>(sandwich)</span>
<span id="cb123-2"><a></a><span class="fu">library</span>(foreign) </span>
<span id="cb123-3"><a></a><span class="fu">library</span>(lmtest)</span>
<span id="cb123-4"><a></a><span class="fu">library</span>(plm)</span>
<span id="cb123-5"><a></a></span>
<span id="cb123-6"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/CEOSAL1.DTA"</span>)</span>
<span id="cb123-7"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> roe, <span class="at">data =</span> data)</span>
<span id="cb123-8"><a></a>robust_model <span class="ot">&lt;-</span> <span class="fu">coeftest</span>(model, <span class="at">vcov =</span> <span class="fu">vcovHC</span>(model, <span class="at">type =</span> <span class="st">"HC3"</span>))</span>
<span id="cb123-9"><a></a><span class="co">#clustered</span></span>
<span id="cb123-10"><a></a>data<span class="sc">$</span>cluster <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">35</span>, <span class="at">length.out =</span> <span class="fu">nrow</span>(data))</span>
<span id="cb123-11"><a></a>model <span class="ot">&lt;-</span> <span class="fu">plm</span>(salary <span class="sc">~</span> roe, <span class="at">data =</span> data, <span class="at">index =</span> <span class="fu">c</span>(<span class="st">"cluster"</span>))</span>
<span id="cb123-12"><a></a></span>
<span id="cb123-13"><a></a>clustered_se <span class="ot">&lt;-</span> <span class="fu">vcovHC</span>(model, <span class="at">type =</span> <span class="st">"HC3"</span>, <span class="at">cluster =</span> <span class="st">"group"</span>)</span>
<span id="cb123-14"><a></a>SE_beta_clustered <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(clustered_se[<span class="st">"roe"</span>, <span class="st">"roe"</span>])</span>
<span id="cb123-15"><a></a></span>
<span id="cb123-16"><a></a><span class="fu">cat</span>(<span class="st">"Standard Error (robust):"</span>, SE_beta_robust, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (robust): 6.899434 </code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a></a><span class="fu">cat</span>(<span class="st">"Standard Error (clustered)::"</span>, SE_beta_clustered, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (clustered):: 12.98492 </code></pre>
</div>
</div>
</div>
<div id="tabset-21-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb127-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb127-3"><a></a></span>
<span id="cb127-4"><a></a><span class="co"># Read the dataset</span></span>
<span id="cb127-5"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CEOSAL1.DTA"</span>)</span>
<span id="cb127-6"><a></a></span>
<span id="cb127-7"><a></a><span class="co"># Create a new variable 'cluster' with cluster numbers ranging from 1 to 35</span></span>
<span id="cb127-8"><a></a>data[<span class="st">'cluster'</span>] <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">36</span>)) <span class="op">*</span> (<span class="bu">len</span>(data) <span class="op">//</span> <span class="dv">35</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Length of values (175) does not match length of index (209)</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a></a><span class="co"># Fit the linear regression model</span></span>
<span id="cb129-2"><a></a>model <span class="op">=</span> sm.OLS(data[<span class="st">'salary'</span>], sm.add_constant(data[<span class="st">'roe'</span>])).fit()</span>
<span id="cb129-3"><a></a></span>
<span id="cb129-4"><a></a><span class="co"># Compute robust standard errors</span></span>
<span id="cb129-5"><a></a>robust_model <span class="op">=</span> model.get_robustcov_results(cov_type<span class="op">=</span><span class="st">'HC3'</span>)</span>
<span id="cb129-6"><a></a>SE_beta_robust <span class="op">=</span> robust_model.cov_params().loc[<span class="st">'roe'</span>, <span class="st">'roe'</span>] <span class="op">**</span> <span class="fl">0.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>'numpy.ndarray' object has no attribute 'loc'</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a></a><span class="co"># Fit the linear regression model with clustered standard errors</span></span>
<span id="cb131-2"><a></a>model_clustered <span class="op">=</span> sm.OLS(data[<span class="st">'salary'</span>], sm.add_constant(data[<span class="st">'roe'</span>])).fit(cov_type<span class="op">=</span><span class="st">'cluster'</span>, cov_kwds<span class="op">=</span>{<span class="st">'groups'</span>: data[<span class="st">'cluster'</span>]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>'cluster'</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a></a><span class="co"># Extract the clustered standard errors for 'roe'</span></span>
<span id="cb133-2"><a></a>clustered_se <span class="op">=</span> model_clustered.HC3_se.loc[<span class="st">'roe'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>name 'model_clustered' is not defined</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a></a><span class="bu">print</span>(<span class="st">"Robust Standard Error (HC3):"</span>, SE_beta_robust)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Robust Standard Error (HC3): 6.899433834797476</code></pre>
</div>
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a></a><span class="bu">print</span>(<span class="st">"Clustered Standard Error (HC3):"</span>, clustered_se)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>name 'clustered_se' is not defined</code></pre>
</div>
</div>
</div>
<div id="tabset-21-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb139-1"><a></a><span class="kw">use</span> <span class="st">"files/CEOSAL1.DTA"</span> , <span class="kw">replace</span></span>
<span id="cb139-2"><a></a></span>
<span id="cb139-3"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe </span>
<span id="cb139-4"><a></a><span class="kw">gen</span> beta_se_non = _se[roe]</span>
<span id="cb139-5"><a></a></span>
<span id="cb139-6"><a></a><span class="kw">qui</span> <span class="kw">reg</span> salary roe , <span class="kw">robust</span></span>
<span id="cb139-7"><a></a><span class="kw">gen</span> beta_se_summary = _se[roe]</span>
<span id="cb139-8"><a></a></span>
<span id="cb139-9"><a></a><span class="kw">egen</span> <span class="kw">cluster</span> = <span class="fu">seq</span>(), block(6)</span>
<span id="cb139-10"><a></a><span class="kw">qui</span> <span class="kw">regress</span> salary roe , <span class="kw">vce</span>(<span class="kw">cluster</span> <span class="kw">cluster</span>)</span>
<span id="cb139-11"><a></a><span class="kw">gen</span> SE_beta_clustered = _se[roe]</span>
<span id="cb139-12"><a></a></span>
<span id="cb139-13"><a></a><span class="kw">di</span> <span class="st">"Standard Error (non-robust): "</span> <span class="kw">sum</span>(beta_se_non)</span>
<span id="cb139-14"><a></a><span class="kw">di</span> <span class="st">"Standard Error (robust): "</span> <span class="kw">sum</span>(beta_se_summary)</span>
<span id="cb139-15"><a></a><span class="kw">di</span> <span class="st">"Standard Error (clustered): "</span> <span class="kw">sum</span>(SE_beta_clustered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard Error (non-robust): 11.123251

Standard Error (robust): 6.8294482

Standard Error (clustered): 6.4122176</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="panel-data" class="title-slide slide level1 smaller center" data-background="#dff5ce">
<h1>Panel Data</h1>

</section>
<section id="panel-data-1" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>As explained previously, OVB is a significant source of “endogeneity” in empirical research.</p>
<p>OVB is a problem because of the considerable heterogeneity in many empirical settings.</p>
<p><strong>Many of the omitted variables are unobservable to the researcher.</strong></p>
<p>Panel data can sometimes offer a partial.</p>
</section>
<section id="panel-data-2" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>We start defining the following:</p>
<p><span class="math display">\[y_{i,t} = \alpha + \beta_1 x_{i,t} + \epsilon_{i,t}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(i = 1, . . . , N\)</span></li>
<li><span class="math inline">\(t = 1, . . . , T\)</span></li>
</ul>
<div class="fragment">
<p>Imagine that the residual can be decomposed in:</p>
<p><span class="math display">\[\epsilon_{i,t} = c_i + \mu_{i,t}\]</span></p>
<p>The term <span class="math inline">\(c_i\)</span> is constant.</p>
</div>
</section>
<section id="panel-data-3" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>The term <span class="math inline">\(c_i\)</span> is constant.</p>
<p><strong>It captures the aggregate effect of all of the unobservable, time-invariant explanatory variables for <span class="math inline">\(y_{it}\)</span>.</strong></p>
<p>To focus attention on the issues specific to panel data, we assume that <span class="math inline">\(e_{it}\)</span> has a zero mean conditional on <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> for all <span class="math inline">\(t\)</span>.</p>
<div class="fragment">
<p>The most important thing here is whether <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are correlated.</p>
<p><strong>Why?</strong></p>
</div>
</section>
<section id="panel-data-4" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>The most important thing here is whether <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are correlated.</p>
<ul>
<li><p>If <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are correlated, then <span class="math inline">\(c_i\)</span> is referred to as a “fixed effect”.</p>
<ul>
<li>It there is correlation, there is violation of the <em>Conditional Mean Independence</em> (CMI) assumption.</li>
</ul></li>
<li><p>If <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are not correlated, then <span class="math inline">\(c_i\)</span> is referred to as a “random effect”.</p>
<ul>
<li>Endogeneity is not a concern; however, the computation of standard errors is affected.</li>
</ul></li>
</ul>
</section>
<section id="panel-data-5" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p><strong>Why might fixed effects arise?</strong></p>
<p>FE are any time-invariant unit characteristic that cannot be observed in the data.</p>
<ul>
<li>education level,</li>
<li>firm’s culture,</li>
<li>technology,</li>
<li>managerial talent,</li>
<li>investment opportunities,</li>
<li>location (economic development, institutions, etc.),</li>
<li>etc.</li>
</ul>
</section>
<section id="panel-data-6" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p><strong>We say things like (you have to understand that they refer to FE):</strong></p>
<ul>
<li>“<em>Time-invariant heterogeneity at the unit-level</em>”</li>
<li>“<em>Unobserved variation that occur at the unit-level that do not vary over time</em>”</li>
</ul>
<p><strong>Important</strong>: with FE, you are capturing <strong>all</strong> unobserved heterogeneity that do not vary over time.</p>
</section>
<section id="panel-data-7" class="slide level2 smaller scrollable" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>Definition of <em>Panel Data</em>:</p>
<p>You have multiple observations per unit (individual, firm, etc.)</p>
<p>In datasets, it is “one panel below the other” not “one panel beside the other”.</p>
<div class="fragment">
<p><strong>Four main topics in Panel Data:</strong></p>
<ol type="1">
<li><p>Pooled cross-sectional</p></li>
<li><p>Fixed Effect models (including multidimensional FE)</p></li>
<li><p>Random Effects model</p></li>
<li><p>First differences</p></li>
<li><p>Lagged models</p></li>
</ol>
</div>
</section>
<section id="panel-data-8" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p>Formal definition</p>
<p><span class="math display">\[y_{i,t} = \alpha + \beta_1 x_{i,t} + \delta FE +  \epsilon_{i,t}\]</span></p>
<ul>
<li><p><span class="math inline">\(E(\epsilon_{i,t}) = 0\)</span></p></li>
<li><p><span class="math inline">\(corr(x_{i,t},FE) \neq 0\)</span></p></li>
<li><p><span class="math inline">\(corr(FE, \epsilon_{i,t}) = 0\)</span></p></li>
<li><p><span class="math inline">\(corr(x_{i,t},epsilon_{i,t}) = 0\)</span>, for all t</p></li>
</ul>
<p>The last assumption is called <em>strict exogeneity assumption</em> and means that the residual of any t is uncorrelated with x of any t.</p>
<p><em>That is, under a strict exogeneity assumption on the explanatory variables, the fixed effects estimator is unbiased: the idiosyncratic error should be uncorrelated with each explanatory variable across all time periods.</em></p>
<div class="fragment">
<p><strong>Remember that if we ignore FE, we have OVB.</strong></p>
</div>
</section>
<section id="panel-data-9" class="slide level2 smaller" data-background="#dff5ce">
<h2>Panel Data</h2>
<p><strong>Before we continue…</strong></p>
<p><strong>Comment #1</strong></p>
<p><em>The standard errors in this framework must be “clustered” by panel unit (e.g., individual) to allow for correlation in the residual for the same person over time. This yields valid inference as long as the number of clusters is “large.”</em></p>
<div class="fragment">
<p><strong>Comment #2</strong></p>
<p><em>FE cannot solve reverse causality, it might help you with OVB.</em></p>
</div>
<div class="fragment">
<p><strong>Comment #3</strong></p>
<p><em>Three main types of FE:</em></p>
<ul>
<li>Pooled</li>
<li>Within-transformation (when someone says FE, it is usually this one)</li>
<li>Random Effects</li>
</ul>
</div>
</section></section>
<section>
<section id="pooling-cross-sections" class="title-slide slide level1 smaller center" data-background="#e0cafc">
<h1>Pooling Cross-sections</h1>

</section>
<section id="pooling-cross-sections-1" class="slide level2 smaller" data-background="#e0cafc">
<h2>Pooling Cross-Sections</h2>
<p>When you have two periods of the same unit, but the periods are not consecutive, you have a pooled cross-sectional data.</p>
<p>This is common in survey data.</p>
<p>If you use only one period, you might find biased results.</p>
<div class="fragment">
<p>Let’s practice with the dataset CRIME2 from Wooldridge.</p>
<p>This dataset contains data (many cities) on the crime rate, unemployment rate and many other city-related variables.</p>
<p>There are two years, 82 and 87 (this is pooled cross-section).</p>
</div>
</section>
<section id="pooling-cross-sections-2" class="slide level2 smaller" data-background="#e0cafc">
<h2>Pooling Cross-Sections</h2>
<p>If we estimate only using the year 87, we would interpret that unemployment leads to lower crime rate.</p>
<div class="panel-tabset">
<ul id="tabset-22" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-22-1">R</a></li><li><a href="#tabset-22-2">Python</a></li><li><a href="#tabset-22-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-22-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a></a><span class="fu">library</span>(haven) </span>
<span id="cb141-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/CRIME2.dta"</span>)</span>
<span id="cb141-3"><a></a>data1 <span class="ot">&lt;-</span> <span class="fu">subset</span>(data, year <span class="sc">==</span> <span class="dv">87</span>)</span>
<span id="cb141-4"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(crmrte <span class="sc">~</span> unem, <span class="at">data =</span> data1)</span>
<span id="cb141-5"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = crmrte ~ unem, data = data1)

Residuals:
   Min     1Q Median     3Q    Max 
-57.55 -27.01 -10.56  18.01  79.75 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  128.378     20.757   6.185  1.8e-07 ***
unem          -4.161      3.416  -1.218     0.23    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 34.6 on 44 degrees of freedom
Multiple R-squared:  0.03262,   Adjusted R-squared:  0.01063 
F-statistic: 1.483 on 1 and 44 DF,  p-value: 0.2297</code></pre>
</div>
</div>
</div>
<div id="tabset-22-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb143-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb143-3"><a></a></span>
<span id="cb143-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CRIME2.dta"</span>)</span>
<span id="cb143-5"><a></a>data1 <span class="op">=</span> data[data[<span class="st">'year'</span>] <span class="op">==</span> <span class="dv">87</span>]</span>
<span id="cb143-6"><a></a>model <span class="op">=</span> sm.OLS(data1[<span class="st">'crmrte'</span>], sm.add_constant(data1[<span class="st">'unem'</span>])).fit()</span>
<span id="cb143-7"><a></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 crmrte   R-squared:                       0.033
Model:                            OLS   Adj. R-squared:                  0.011
Method:                 Least Squares   F-statistic:                     1.483
Date:                qua, 11 set 2024   Prob (F-statistic):              0.230
Time:                        16:20:39   Log-Likelihood:                -227.27
No. Observations:                  46   AIC:                             458.5
Df Residuals:                      44   BIC:                             462.2
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        128.3781     20.757      6.185      0.000      86.546     170.210
unem          -4.1611      3.416     -1.218      0.230     -11.047       2.724
==============================================================================
Omnibus:                        3.902   Durbin-Watson:                   1.106
Prob(Omnibus):                  0.142   Jarque-Bera (JB):                3.681
Skew:                           0.641   Prob(JB):                        0.159
Kurtosis:                       2.473   Cond. No.                         25.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-22-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb145-1"><a></a><span class="kw">use</span> <span class="st">"files/CRIME2.dta"</span> , <span class="kw">clear</span></span>
<span id="cb145-2"><a></a><span class="kw">reg</span> crmrte une <span class="kw">if</span> <span class="fu">year</span> ==87</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      Source |       SS           df       MS      Number of obs   =        46
-------------+----------------------------------   F(1, 44)        =      1.48
       Model |  1775.90928         1  1775.90928   Prob &gt; F        =    0.2297
    Residual |  52674.6428        44  1197.15097   R-squared       =    0.0326
-------------+----------------------------------   Adj R-squared   =    0.0106
       Total |  54450.5521        45  1210.01227   Root MSE        =      34.6

------------------------------------------------------------------------------
      crmrte | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
        unem |  -4.161134   3.416456    -1.22   0.230    -11.04655     2.72428
       _cons |   128.3781   20.75663     6.18   0.000     86.54589    170.2104
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="pooling-cross-sections-3" class="slide level2 smaller" data-background="#e0cafc">
<h2>Pooling Cross-Sections</h2>
<p>When we consider a panel, we get the expected positive sign. This is evidence that the previous model suffered from OVB. Still, the coefficient of unem is not significant probably because of time-invariant unobserved heterogeneity in the cities.</p>
<div class="panel-tabset">
<ul id="tabset-23" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-23-1">R</a></li><li><a href="#tabset-23-2">Python</a></li><li><a href="#tabset-23-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-23-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb147-1"><a></a><span class="fu">library</span>(haven) </span>
<span id="cb147-2"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/CRIME2.dta"</span>)</span>
<span id="cb147-3"><a></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(crmrte <span class="sc">~</span> d87<span class="sc">+</span> unem, <span class="at">data =</span> data)</span>
<span id="cb147-4"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = crmrte ~ d87 + unem, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-53.474 -21.794  -6.266  18.297  75.113 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  93.4203    12.7395   7.333 9.92e-11 ***
d87           7.9404     7.9753   0.996    0.322    
unem          0.4265     1.1883   0.359    0.720    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 29.99 on 89 degrees of freedom
Multiple R-squared:  0.01221,   Adjusted R-squared:  -0.009986 
F-statistic: 0.5501 on 2 and 89 DF,  p-value: 0.5788</code></pre>
</div>
</div>
</div>
<div id="tabset-23-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb149-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb149-3"><a></a></span>
<span id="cb149-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/CRIME2.dta"</span>)</span>
<span id="cb149-5"><a></a>model <span class="op">=</span> sm.OLS(data[<span class="st">'crmrte'</span>], sm.add_constant(data[[<span class="st">'d87'</span>,<span class="st">'unem'</span>]])).fit()</span>
<span id="cb149-6"><a></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 crmrte   R-squared:                       0.012
Model:                            OLS   Adj. R-squared:                 -0.010
Method:                 Least Squares   F-statistic:                    0.5501
Date:                qua, 11 set 2024   Prob (F-statistic):              0.579
Time:                        16:20:42   Log-Likelihood:                -441.90
No. Observations:                  92   AIC:                             889.8
Df Residuals:                      89   BIC:                             897.4
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         93.4203     12.739      7.333      0.000      68.107     118.733
d87            7.9404      7.975      0.996      0.322      -7.906      23.787
unem           0.4265      1.188      0.359      0.720      -1.935       2.788
==============================================================================
Omnibus:                        8.350   Durbin-Watson:                   1.157
Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.771
Skew:                           0.756   Prob(JB):                       0.0125
Kurtosis:                       2.935   Cond. No.                         40.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
</div>
<div id="tabset-23-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb151-1"><a></a><span class="kw">use</span> <span class="st">"files/CRIME2.dta"</span> , <span class="kw">clear</span></span>
<span id="cb151-2"><a></a><span class="kw">reg</span> crmrte  d87 une </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      Source |       SS           df       MS      Number of obs   =        92
-------------+----------------------------------   F(2, 89)        =      0.55
       Model |  989.717314         2  494.858657   Prob &gt; F        =    0.5788
    Residual |  80055.7864        89  899.503218   R-squared       =    0.0122
-------------+----------------------------------   Adj R-squared   =   -0.0100
       Total |  81045.5037        91  890.609931   Root MSE        =    29.992

------------------------------------------------------------------------------
      crmrte | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
         d87 |   7.940413   7.975324     1.00   0.322    -7.906386    23.78721
        unem |   .4265461   1.188279     0.36   0.720    -1.934539    2.787631
       _cons |   93.42026   12.73947     7.33   0.000      68.1072    118.7333
------------------------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="pooling-cross-sections-4" class="slide level2 smaller" data-background="#e0cafc">
<h2>Pooling Cross-Sections</h2>
<p>This shows us that we should also control for the year variable.</p>
<p>We call this, <strong>Year Fixed Effects.</strong></p>
<p>We still most likely have OVB due to the unobserved heterogeneity in cities, that is, we still would need to include <strong>cities FE</strong>.</p>
</section></section>
<section>
<section id="demeaned-variables" class="title-slide slide level1 smaller center" data-background="#fccad9">
<h1>Demeaned variables</h1>

</section>
<section id="demeaned-variables-1" class="slide level2 smaller" data-background="#fccad9">
<h2>Demeaned variables</h2>
<p><strong>A first way to eliminate the FE is by demeaning the data.</strong></p>
<p>Consider the following:</p>
<p><span class="math display">\[\bar{y_i} = \alpha +\beta \bar{x_i} + \delta FE + \bar{\epsilon_i}\]</span></p>
<p><span class="math display">\[\frac{1}{T}\sum{y_{i,t}} = \alpha +\beta \frac{1}{T}\sum{x_{i,t}} + \delta FE + \frac{1}{T}\sum{\epsilon_{i,t}}\]</span></p>
<div class="fragment">
<p>If we subtract the mean of each variable, we have:</p>
<p><span class="math display">\[(y_{i,t} - \bar{y_i}) = \beta (x_{i,t} - \bar{x_i}) + (\epsilon_{i,t} - \bar{\epsilon_i})\]</span></p>
<p>Because the FE does not vary over time, each value is equal to the mean.</p>
<p>Thus, when you demean, you eliminate the FE from the equation. You also eliminate the intercept <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div class="fragment">
<p><strong>Takeaway</strong>: OLS will estimate unbiased coefficients if you demean the variables.</p>
<p>This is called <strong>within-transformation</strong> because you are demeaning “within” the group.</p>
</div>
</section>
<section id="demeaned-variables-2" class="slide level2 smaller" data-background="#fccad9">
<h2>Demeaned variables</h2>
<p>Let’s use the dataset WAGEPAN to estimate the following equation.</p>
<p><span class="math display">\[Ln(wage)=\alpha + \beta_1 exper^2 + \beta_2 married + \beta_3 union + \epsilon\]</span></p>
<p>Some variables in the dataset do not vary over time. These variables cannot be included in this equation.</p>
</section>
<section id="demeaned-variables-3" class="slide level2 smaller" data-background="#fccad9">
<h2>Demeaned variables</h2>
<p>See page 495 Wooldridge.</p>
<div class="panel-tabset">
<ul id="tabset-24" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-24-1">R</a></li><li><a href="#tabset-24-2">Python</a></li><li><a href="#tabset-24-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-24-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb153-1"><a></a><span class="fu">library</span>(foreign)</span>
<span id="cb153-2"><a></a><span class="fu">library</span>(stargazer)</span>
<span id="cb153-3"><a></a><span class="fu">library</span>(sandwich)</span>
<span id="cb153-4"><a></a></span>
<span id="cb153-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/WAGEPAN.dta"</span>)</span>
<span id="cb153-6"><a></a><span class="co"># Calculate mean by nr for lwage, expersq, married, and union</span></span>
<span id="cb153-7"><a></a>data <span class="ot">&lt;-</span> data[<span class="fu">order</span>(data<span class="sc">$</span>nr), ]  <span class="co"># Sort data by nr for by-group operations</span></span>
<span id="cb153-8"><a></a>data<span class="sc">$</span>lwage_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>lwage, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb153-9"><a></a>data<span class="sc">$</span>expersq_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>expersq, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb153-10"><a></a>data<span class="sc">$</span>married_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>married, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb153-11"><a></a>data<span class="sc">$</span>union_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>union, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb153-12"><a></a></span>
<span id="cb153-13"><a></a>data<span class="sc">$</span>lwage_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>lwage <span class="sc">-</span> data<span class="sc">$</span>lwage_mean</span>
<span id="cb153-14"><a></a>data<span class="sc">$</span>expersq_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>expersq <span class="sc">-</span> data<span class="sc">$</span>expersq_mean</span>
<span id="cb153-15"><a></a>data<span class="sc">$</span>married_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>married <span class="sc">-</span> data<span class="sc">$</span>married_mean</span>
<span id="cb153-16"><a></a>data<span class="sc">$</span>union_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>union <span class="sc">-</span> data<span class="sc">$</span>union_mean</span>
<span id="cb153-17"><a></a></span>
<span id="cb153-18"><a></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(lwage <span class="sc">~</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper <span class="sc">+</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> d81 <span class="sc">+</span> d82 <span class="sc">+</span> d83 <span class="sc">+</span> d84 <span class="sc">+</span> d85 <span class="sc">+</span> d86 <span class="sc">+</span> d87, <span class="at">data =</span> data)</span>
<span id="cb153-19"><a></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(lwage_demean <span class="sc">~</span> expersq_demean <span class="sc">+</span> married_demean <span class="sc">+</span> union_demean <span class="sc">+</span> d81 <span class="sc">+</span> d82 <span class="sc">+</span> d83 <span class="sc">+</span> d84 <span class="sc">+</span> d85 <span class="sc">+</span> d86 <span class="sc">+</span> d87, <span class="at">data =</span> data)</span>
<span id="cb153-20"><a></a></span>
<span id="cb153-21"><a></a><span class="fu">stargazer</span>(model1, model2 ,<span class="at">title =</span> <span class="st">"Regression Results"</span>, <span class="at">column.labels=</span><span class="fu">c</span>(<span class="st">"OLS"</span>,<span class="st">"Demean"</span>),  <span class="at">type =</span> <span class="st">"text"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression Results
=======================================================================
                                    Dependent variable:                
                    ---------------------------------------------------
                              lwage                 lwage_demean       
                               OLS                     Demean          
                               (1)                       (2)           
-----------------------------------------------------------------------
educ                        0.091***                                   
                             (0.005)                                   
                                                                       
black                       -0.139***                                  
                             (0.024)                                   
                                                                       
hisp                          0.016                                    
                             (0.021)                                   
                                                                       
exper                       0.067***                                   
                             (0.014)                                   
                                                                       
expersq                     -0.002***                                  
                             (0.001)                                   
                                                                       
married                     0.108***                                   
                             (0.016)                                   
                                                                       
union                       0.182***                                   
                             (0.017)                                   
                                                                       
expersq_demean                                        -0.005***        
                                                       (0.001)         
                                                                       
married_demean                                        0.047***         
                                                       (0.017)         
                                                                       
union_demean                                          0.080***         
                                                       (0.018)         
                                                                       
d81                          0.058*                   0.151***         
                             (0.030)                   (0.021)         
                                                                       
d82                          0.063*                   0.253***         
                             (0.033)                   (0.023)         
                                                                       
d83                          0.062*                   0.354***         
                             (0.037)                   (0.027)         
                                                                       
d84                          0.090**                  0.490***         
                             (0.040)                   (0.034)         
                                                                       
d85                          0.109**                  0.617***         
                             (0.043)                   (0.042)         
                                                                       
d86                         0.142***                  0.765***         
                             (0.046)                   (0.053)         
                                                                       
d87                         0.174***                  0.925***         
                             (0.049)                   (0.064)         
                                                                       
Constant                      0.092                   -0.445***        
                             (0.078)                   (0.030)         
                                                                       
-----------------------------------------------------------------------
Observations                  4,360                     4,360          
R2                            0.189                     0.181          
Adjusted R2                   0.187                     0.179          
Residual Std. Error     0.480 (df = 4345)         0.328 (df = 4349)    
F Statistic         72.459*** (df = 14; 4345) 95.840*** (df = 10; 4349)
=======================================================================
Note:                                       *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="tabset-24-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb155-2"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb155-3"><a></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb155-4"><a></a><span class="im">from</span> statsmodels.iolib.summary2 <span class="im">import</span> summary_col</span>
<span id="cb155-5"><a></a></span>
<span id="cb155-6"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/WAGEPAN.dta"</span>)</span>
<span id="cb155-7"><a></a></span>
<span id="cb155-8"><a></a>data <span class="op">=</span> data.sort_values(by<span class="op">=</span><span class="st">'nr'</span>)  <span class="co"># Sort data by nr for by-group operations</span></span>
<span id="cb155-9"><a></a>data[<span class="st">'lwage_mean'</span>] <span class="op">=</span> data.groupby(<span class="st">'nr'</span>)[<span class="st">'lwage'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb155-10"><a></a>data[<span class="st">'expersq_mean'</span>] <span class="op">=</span> data.groupby(<span class="st">'nr'</span>)[<span class="st">'expersq'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb155-11"><a></a>data[<span class="st">'married_mean'</span>] <span class="op">=</span> data.groupby(<span class="st">'nr'</span>)[<span class="st">'married'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb155-12"><a></a>data[<span class="st">'union_mean'</span>] <span class="op">=</span> data.groupby(<span class="st">'nr'</span>)[<span class="st">'union'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb155-13"><a></a></span>
<span id="cb155-14"><a></a>data[<span class="st">'lwage_demean'</span>] <span class="op">=</span> data[<span class="st">'lwage'</span>] <span class="op">-</span> data[<span class="st">'lwage_mean'</span>]</span>
<span id="cb155-15"><a></a>data[<span class="st">'expersq_demean'</span>] <span class="op">=</span> data[<span class="st">'expersq'</span>] <span class="op">-</span> data[<span class="st">'expersq_mean'</span>]</span>
<span id="cb155-16"><a></a>data[<span class="st">'married_demean'</span>] <span class="op">=</span> data[<span class="st">'married'</span>] <span class="op">-</span> data[<span class="st">'married_mean'</span>]</span>
<span id="cb155-17"><a></a>data[<span class="st">'union_demean'</span>] <span class="op">=</span> data[<span class="st">'union'</span>] <span class="op">-</span> data[<span class="st">'union_mean'</span>]</span>
<span id="cb155-18"><a></a></span>
<span id="cb155-19"><a></a>model1 <span class="op">=</span> sm.OLS(data[<span class="st">'lwage'</span>], sm.add_constant(data[[<span class="st">'educ'</span>, <span class="st">'black'</span>, <span class="st">'hisp'</span>, <span class="st">'exper'</span>, <span class="st">'expersq'</span>, <span class="st">'married'</span>, <span class="st">'union'</span>, <span class="st">'d81'</span>, <span class="st">'d82'</span>, <span class="st">'d83'</span>, <span class="st">'d84'</span>, <span class="st">'d85'</span>, <span class="st">'d86'</span>, <span class="st">'d87'</span>]])).fit()</span>
<span id="cb155-20"><a></a>model2 <span class="op">=</span> sm.OLS(data[<span class="st">'lwage_demean'</span>], sm.add_constant(data[[<span class="st">'expersq_demean'</span>, <span class="st">'married_demean'</span>, <span class="st">'union_demean'</span>, <span class="st">'d81'</span>, <span class="st">'d82'</span>, <span class="st">'d83'</span>, <span class="st">'d84'</span>, <span class="st">'d85'</span>, <span class="st">'d86'</span>, <span class="st">'d87'</span>]])).fit()</span>
<span id="cb155-21"><a></a></span>
<span id="cb155-22"><a></a><span class="co"># Display regression results using stargazer</span></span>
<span id="cb155-23"><a></a>summary <span class="op">=</span> summary_col([model1, model2], stars<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb155-24"><a></a><span class="bu">print</span>(summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================
                 lwage    lwage_demean
--------------------------------------
R-squared      0.1893     0.1806      
R-squared Adj. 0.1867     0.1787      
black          -0.1392***             
               (0.0236)               
const          0.0921     -0.4446***  
               (0.0783)   (0.0297)    
d81            0.0583*    0.1512***   
               (0.0304)   (0.0205)    
d82            0.0628*    0.2530***   
               (0.0332)   (0.0228)    
d83            0.0620*    0.3544***   
               (0.0367)   (0.0274)    
d84            0.0905**   0.4901***   
               (0.0401)   (0.0339)    
d85            0.1092**   0.6175***   
               (0.0434)   (0.0423)    
d86            0.1420***  0.7655***   
               (0.0464)   (0.0525)    
d87            0.1738***  0.9250***   
               (0.0494)   (0.0643)    
educ           0.0913***              
               (0.0052)               
exper          0.0672***              
               (0.0137)               
expersq        -0.0024***             
               (0.0008)               
expersq_demean            -0.0052***  
                          (0.0007)    
hisp           0.0160                 
               (0.0208)               
married        0.1083***              
               (0.0157)               
married_demean            0.0467***   
                          (0.0171)    
union          0.1825***              
               (0.0172)               
union_demean              0.0800***   
                          (0.0181)    
======================================
Standard errors in parentheses.
* p&lt;.1, ** p&lt;.05, ***p&lt;.01</code></pre>
</div>
</div>
</div>
<div id="tabset-24-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb157-1"><a></a><span class="kw">use</span> <span class="st">"files/WAGEPAN.dta"</span> , <span class="kw">clear</span></span>
<span id="cb157-2"><a></a></span>
<span id="cb157-3"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> lwage_mean = <span class="kw">mean</span>(lwage) </span>
<span id="cb157-4"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> expersq_mean = <span class="kw">mean</span>(expersq) </span>
<span id="cb157-5"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> married_mean = <span class="kw">mean</span>(married) </span>
<span id="cb157-6"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> union_mean = <span class="kw">mean</span>(<span class="kw">union</span>)</span>
<span id="cb157-7"><a></a></span>
<span id="cb157-8"><a></a><span class="kw">gen</span> lwage_demean = lwage - lwage_mean</span>
<span id="cb157-9"><a></a><span class="kw">gen</span> expersq_demean = expersq - expersq_mean</span>
<span id="cb157-10"><a></a><span class="kw">gen</span> married_demean = married - married_mean</span>
<span id="cb157-11"><a></a><span class="kw">gen</span> union_demean = <span class="kw">union</span> - union_mean</span>
<span id="cb157-12"><a></a></span>
<span id="cb157-13"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> lwage        educ <span class="bn">black</span> hisp exper expersq       married        <span class="kw">union</span> d81 d82 d83 d84 d85 d86 d87</span>
<span id="cb157-14"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> lwage_demean expersq_demean married_demean union_demean d81 d82 d83 d84 d85 d86 d87</span>
<span id="cb157-15"><a></a>esttab , mtitles(<span class="st">"OLS"</span> <span class="st">"Demean"</span>) <span class="kw">compress</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(est1 stored)

(est2 stored)


------------------------------------
                 (1)          (2)   
                 OLS       Demean   
------------------------------------
educ          0.0913***             
             (17.44)                

black         -0.139***             
             (-5.90)                

hisp          0.0160                
              (0.77)                

exper         0.0672***             
              (4.91)                

expersq     -0.00241**              
             (-2.94)                

married        0.108***             
              (6.90)                

union          0.182***             
             (10.63)                

d81           0.0583        0.151***
              (1.92)       (7.36)   

d82           0.0628        0.253***
              (1.89)      (11.08)   

d83           0.0620        0.354***
              (1.69)      (12.96)   

d84           0.0905*       0.490***
              (2.26)      (14.46)   

d85            0.109*       0.617***
              (2.52)      (14.59)   

d86            0.142**      0.765***
              (3.06)      (14.58)   

d87            0.174***     0.925***
              (3.52)      (14.38)   

expe~emean               -0.00519***
                          (-7.87)   

marr~emean                 0.0467** 
                           (2.73)   

union_de~n                 0.0800***
                           (4.43)   

_cons         0.0921       -0.445***
              (1.18)     (-14.96)   
------------------------------------
N               4360         4360   
------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="practical-tips" class="title-slide slide level1 smaller center" data-background="#fce0cc">
<h1>Practical Tips</h1>

</section>
<section id="practical-tips-1" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>You will not need to demean the variables every time you want to estimate a fixed effect models.</p>
<p>The statistical softwares have packages that do that.</p>
<p>You only need to know that <strong>Fixed effects model</strong> is a <strong>demeaned model</strong>, i.e., a <strong>within-transformation model</strong>.</p>
<p>But notice that you will have many different Fixed Effects together:</p>
<ul>
<li>Firm Fixed Effects</li>
<li>Year Fixed Effects</li>
<li>Individual Fixed Effects (if individuals change between firms)</li>
</ul>
<div class="fragment">
<p>I am calling a <strong>multidimensional fixed effects design</strong> if you expand the FE to interactions of FE. Most common:</p>
<ul>
<li>Year-Industry Fixed Effects.</li>
<li>CEO-Firm Fixed Effects.</li>
</ul>
</div>
</section>
<section id="practical-tips-2" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>Notice the number of dummies in the last two columns.</p>
<div class="panel-tabset">
<ul id="tabset-25" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-25-1">R</a></li><li><a href="#tabset-25-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-25-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb159-1"><a></a><span class="fu">library</span>(foreign)</span>
<span id="cb159-2"><a></a><span class="fu">library</span>(stargazer)</span>
<span id="cb159-3"><a></a><span class="fu">library</span>(sandwich)</span>
<span id="cb159-4"><a></a><span class="fu">library</span>(plm)</span>
<span id="cb159-5"><a></a></span>
<span id="cb159-6"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/WAGEPAN.dta"</span>)</span>
<span id="cb159-7"><a></a><span class="co"># Calculate mean by nr for lwage, expersq, married, and union</span></span>
<span id="cb159-8"><a></a>data <span class="ot">&lt;-</span> data[<span class="fu">order</span>(data<span class="sc">$</span>nr), ]  <span class="co"># Sort data by nr for by-group operations</span></span>
<span id="cb159-9"><a></a>data<span class="sc">$</span>lwage_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>lwage, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb159-10"><a></a>data<span class="sc">$</span>expersq_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>expersq, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb159-11"><a></a>data<span class="sc">$</span>married_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>married, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb159-12"><a></a>data<span class="sc">$</span>union_mean <span class="ot">&lt;-</span> <span class="fu">ave</span>(data<span class="sc">$</span>union, data<span class="sc">$</span>nr, <span class="at">FUN =</span> mean)</span>
<span id="cb159-13"><a></a></span>
<span id="cb159-14"><a></a>data<span class="sc">$</span>lwage_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>lwage <span class="sc">-</span> data<span class="sc">$</span>lwage_mean</span>
<span id="cb159-15"><a></a>data<span class="sc">$</span>expersq_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>expersq <span class="sc">-</span> data<span class="sc">$</span>expersq_mean</span>
<span id="cb159-16"><a></a>data<span class="sc">$</span>married_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>married <span class="sc">-</span> data<span class="sc">$</span>married_mean</span>
<span id="cb159-17"><a></a>data<span class="sc">$</span>union_demean <span class="ot">&lt;-</span> data<span class="sc">$</span>union <span class="sc">-</span> data<span class="sc">$</span>union_mean</span>
<span id="cb159-18"><a></a></span>
<span id="cb159-19"><a></a><span class="co"># set panel data</span></span>
<span id="cb159-20"><a></a>pdata <span class="ot">&lt;-</span> <span class="fu">pdata.frame</span>(data, <span class="at">index =</span> <span class="fu">c</span>(<span class="st">"nr"</span>, <span class="st">"year"</span>))</span>
<span id="cb159-21"><a></a></span>
<span id="cb159-22"><a></a><span class="co"># Random effects regression using plm</span></span>
<span id="cb159-23"><a></a>model_de <span class="ot">&lt;-</span> <span class="fu">lm</span>(lwage_demean <span class="sc">~</span>  expersq_demean <span class="sc">+</span> married_demean <span class="sc">+</span> union_demean <span class="sc">+</span>  d81 <span class="sc">+</span>d82<span class="sc">+</span> d83<span class="sc">+</span> d84<span class="sc">+</span> d85 <span class="sc">+</span>d86 <span class="sc">+</span>d87 , <span class="at">data =</span> data)</span>
<span id="cb159-24"><a></a>model_fe <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span>  expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year)              <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"within"</span>)</span>
<span id="cb159-25"><a></a>model_du <span class="ot">&lt;-</span> <span class="fu">lm</span>( lwage <span class="sc">~</span>  expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year) <span class="sc">+</span> <span class="fu">factor</span>(nr) <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> data)</span>
<span id="cb159-26"><a></a></span>
<span id="cb159-27"><a></a><span class="co"># Display regression results using stargazer</span></span>
<span id="cb159-28"><a></a><span class="co">#summary(model_de)</span></span>
<span id="cb159-29"><a></a><span class="co">#summary(model_fe)</span></span>
<span id="cb159-30"><a></a><span class="co">#summary(model_du)</span></span>
<span id="cb159-31"><a></a><span class="fu">stargazer</span>(model_de, model_fe, model_du ,<span class="at">title =</span> <span class="st">"Regression Results"</span>,  <span class="at">type =</span> <span class="st">"text"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression Results
==================================================================================================
                                                 Dependent variable:                              
                    ------------------------------------------------------------------------------
                          lwage_demean                               lwage                        
                               OLS                      panel                      OLS            
                                                       linear                                     
                               (1)                       (2)                       (3)            
--------------------------------------------------------------------------------------------------
expersq_demean              -0.005***                                                             
                             (0.001)                                                              
                                                                                                  
married_demean              0.047***                                                              
                             (0.017)                                                              
                                                                                                  
union_demean                0.080***                                                              
                             (0.018)                                                              
                                                                                                  
d81                         0.151***                                                              
                             (0.021)                                                              
                                                                                                  
d82                         0.253***                                                              
                             (0.023)                                                              
                                                                                                  
d83                         0.354***                                                              
                             (0.027)                                                              
                                                                                                  
d84                         0.490***                                                              
                             (0.034)                                                              
                                                                                                  
d85                         0.617***                                                              
                             (0.042)                                                              
                                                                                                  
d86                         0.765***                                                              
                             (0.053)                                                              
                                                                                                  
d87                         0.925***                                                              
                             (0.064)                                                              
                                                                                                  
expersq                                               -0.005***                 -0.005***         
                                                       (0.001)                   (0.001)          
                                                                                                  
married                                                0.047**                   0.047**          
                                                       (0.018)                   (0.018)          
                                                                                                  
union                                                 0.080***                   0.080***         
                                                       (0.019)                   (0.019)          
                                                                                                  
factor(year)1981                                      0.151***                   0.151***         
                                                       (0.022)                   (0.022)          
                                                                                                  
factor(year)1982                                      0.253***                   0.253***         
                                                       (0.024)                   (0.024)          
                                                                                                  
factor(year)1983                                      0.354***                   0.354***         
                                                       (0.029)                   (0.029)          
                                                                                                  
factor(year)1984                                      0.490***                   0.490***         
                                                       (0.036)                   (0.036)          
                                                                                                  
factor(year)1985                                      0.617***                   0.617***         
                                                       (0.045)                   (0.045)          
                                                                                                  
factor(year)1986                                      0.765***                   0.765***         
                                                       (0.056)                   (0.056)          
                                                                                                  
factor(year)1987                                      0.925***                   0.925***         
                                                       (0.069)                   (0.069)          
                                                                                                  
factor(nr)17                                                                     0.579***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)18                                                                     0.929***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)45                                                                     0.554***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)110                                                                    1.046***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)120                                                                     0.239           
                                                                                 (0.176)          
                                                                                                  
factor(nr)126                                                                    0.783***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)150                                                                     -0.140          
                                                                                 (0.176)          
                                                                                                  
factor(nr)162                                                                     0.269           
                                                                                 (0.176)          
                                                                                                  
factor(nr)166                                                                     0.138           
                                                                                 (0.176)          
                                                                                                  
factor(nr)189                                                                     0.191           
                                                                                 (0.176)          
                                                                                                  
factor(nr)193                                                                    0.981***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)209                                                                    0.707***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)212                                                                    0.833***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)218                                                                    1.231***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)243                                                                    0.586***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)259                                                                    0.478***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)260                                                                    0.789***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)309                                                                    1.052***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)351                                                                    0.358**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)353                                                                    0.583***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)383                                                                    0.564***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)408                                                                    0.801***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)424                                                                    1.345***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)464                                                                     0.080           
                                                                                 (0.176)          
                                                                                                  
factor(nr)483                                                                    0.713***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)556                                                                    1.089***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)560                                                                     0.205           
                                                                                 (0.176)          
                                                                                                  
factor(nr)569                                                                    -0.431**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)583                                                                    0.852***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)647                                                                    0.360**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)658                                                                    0.838***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)684                                                                    1.132***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)711                                                                     -0.097          
                                                                                 (0.176)          
                                                                                                  
factor(nr)729                                                                    0.837***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)731                                                                    0.574***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)732                                                                    0.531***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)793                                                                    0.498***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)797                                                                    0.841***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)800                                                                    0.380**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)813                                                                   -0.657***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)823                                                                    -0.393**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)827                                                                    0.507***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)847                                                                    0.489***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)851                                                                    0.735***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)863                                                                    0.550***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)873                                                                     -0.127          
                                                                                 (0.176)          
                                                                                                  
factor(nr)891                                                                    0.735***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)908                                                                    -0.405**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)910                                                                    0.679***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)916                                                                    0.564***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)919                                                                     0.238           
                                                                                 (0.178)          
                                                                                                  
factor(nr)922                                                                    1.011***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)924                                                                     -0.071          
                                                                                 (0.176)          
                                                                                                  
factor(nr)925                                                                    0.809***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)944                                                                     0.106           
                                                                                 (0.176)          
                                                                                                  
factor(nr)945                                                                     0.106           
                                                                                 (0.176)          
                                                                                                  
factor(nr)947                                                                    1.154***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)955                                                                    1.006***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)965                                                                    0.434**          
                                                                                 (0.180)          
                                                                                                  
factor(nr)996                                                                     0.007           
                                                                                 (0.177)          
                                                                                                  
factor(nr)1007                                                                   0.996***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)1054                                                                    0.133           
                                                                                 (0.177)          
                                                                                                  
factor(nr)1064                                                                   0.858***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)1081                                                                    0.179           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1085                                                                    0.114           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1091                                                                    0.226           
                                                                                 (0.183)          
                                                                                                  
factor(nr)1094                                                                   0.600***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)1096                                                                    0.251           
                                                                                 (0.182)          
                                                                                                  
factor(nr)1098                                                                   0.837***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1102                                                                   0.948***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1107                                                                   0.762***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)1142                                                                   0.715***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1156                                                                   0.569***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)1180                                                                   0.636***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1190                                                                    0.119           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1204                                                                   0.888***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)1249                                                                   0.468***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)1272                                                                   0.612***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1311                                                                   0.481***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1316                                                                   0.921***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)1318                                                                   0.625***         
                                                                                 (0.192)          
                                                                                                  
factor(nr)1345                                                                   0.549***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)1397                                                                   0.653***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)1434                                                                    -0.082          
                                                                                 (0.177)          
                                                                                                  
factor(nr)1492                                                                   0.408**          
                                                                                 (0.178)          
                                                                                                  
factor(nr)1496                                                                    -0.219          
                                                                                 (0.176)          
                                                                                                  
factor(nr)1506                                                                    0.082           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1515                                                                    0.281           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1520                                                                   0.375**          
                                                                                 (0.181)          
                                                                                                  
factor(nr)1528                                                                    0.136           
                                                                                 (0.177)          
                                                                                                  
factor(nr)1554                                                                    0.312*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)1575                                                                   0.577***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)1576                                                                   0.504***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1628                                                                   0.440**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)1641                                                                   0.974***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)1644                                                                    0.263           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1653                                                                   0.629***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1654                                                                   0.663***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)1721                                                                   1.160***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)1742                                                                   0.861***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1744                                                                   0.557***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1763                                                                    -0.194          
                                                                                 (0.176)          
                                                                                                  
factor(nr)1777                                                                    0.115           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1843                                                                   1.310***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)1891                                                                    -0.090          
                                                                                 (0.176)          
                                                                                                  
factor(nr)1895                                                                   0.604***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)1899                                                                    0.171           
                                                                                 (0.177)          
                                                                                                  
factor(nr)1925                                                                   0.488***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1930                                                                    0.251           
                                                                                 (0.176)          
                                                                                                  
factor(nr)1961                                                                   0.745***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)1963                                                                   0.470***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)1979                                                                   0.828***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)1988                                                                    -0.062          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2000                                                                   0.637***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2014                                                                    0.310*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2025                                                                   0.432**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2038                                                                    0.180           
                                                                                 (0.176)          
                                                                                                  
factor(nr)2075                                                                   0.928***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)2101                                                                   1.158***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2106                                                                   0.595***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)2107                                                                   0.460***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2108                                                                   0.816***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2147                                                                  -0.860***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2157                                                                    0.055           
                                                                                 (0.180)          
                                                                                                  
factor(nr)2163                                                                   1.092***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)2173                                                                    0.148           
                                                                                 (0.176)          
                                                                                                  
factor(nr)2180                                                                   0.411**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2183                                                                   0.392**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2216                                                                   0.540***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2220                                                                   0.991***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2227                                                                    0.255           
                                                                                 (0.177)          
                                                                                                  
factor(nr)2264                                                                    -0.093          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2306                                                                    -0.052          
                                                                                 (0.177)          
                                                                                                  
factor(nr)2312                                                                   0.816***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2314                                                                   0.969***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)2329                                                                   0.545***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2335                                                                   0.506***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)2341                                                                   0.471***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2351                                                                    0.046           
                                                                                 (0.176)          
                                                                                                  
factor(nr)2386                                                                    -0.154          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2401                                                                   0.644***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)2413                                                                   0.999***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)2421                                                                    0.036           
                                                                                 (0.177)          
                                                                                                  
factor(nr)2445                                                                   0.463***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)2451                                                                   0.592***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2494                                                                    0.168           
                                                                                 (0.179)          
                                                                                                  
factor(nr)2508                                                                   0.848***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2535                                                                   0.486***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)2540                                                                    -0.059          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2685                                                                   1.031***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2711                                                                    0.052           
                                                                                 (0.176)          
                                                                                                  
factor(nr)2718                                                                   1.059***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2721                                                                    0.157           
                                                                                 (0.184)          
                                                                                                  
factor(nr)2733                                                                    -0.146          
                                                                                 (0.178)          
                                                                                                  
factor(nr)2741                                                                   0.419**          
                                                                                 (0.181)          
                                                                                                  
factor(nr)2745                                                                   0.556***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2751                                                                   0.456**          
                                                                                 (0.179)          
                                                                                                  
factor(nr)2774                                                                   0.903***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2801                                                                    0.050           
                                                                                 (0.176)          
                                                                                                  
factor(nr)2813                                                                    0.222           
                                                                                 (0.177)          
                                                                                                  
factor(nr)2833                                                                   0.621***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2839                                                                   0.646***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)2842                                                                   0.942***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2866                                                                   0.707***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2868                                                                   0.978***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2874                                                                    0.007           
                                                                                 (0.177)          
                                                                                                  
factor(nr)2916                                                                   0.345**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)2951                                                                    0.313*          
                                                                                 (0.182)          
                                                                                                  
factor(nr)2980                                                                    0.327*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)2994                                                                   0.506***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)2997                                                                   0.601***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3017                                                                   0.936***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3037                                                                   1.040***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)3059                                                                   0.694***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)3062                                                                   1.166***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3100                                                                   0.637***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)3102                                                                    -0.259          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3127                                                                   -0.407**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3136                                                                   0.698***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3137                                                                   0.892***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3138                                                                   0.665***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3140                                                                   0.843***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3193                                                                   0.686***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3196                                                                   0.681***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3200                                                                   0.771***         
                                                                                 (0.187)          
                                                                                                  
factor(nr)3202                                                                   0.593***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3207                                                                   0.471***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)3208                                                                   0.855***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3210                                                                   0.708***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3215                                                                    0.324*          
                                                                                 (0.178)          
                                                                                                  
factor(nr)3219                                                                    0.237           
                                                                                 (0.176)          
                                                                                                  
factor(nr)3226                                                                   0.642***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3235                                                                    0.144           
                                                                                 (0.176)          
                                                                                                  
factor(nr)3239                                                                   -0.375**         
                                                                                 (0.175)          
                                                                                                  
factor(nr)3271                                                                   0.756***         
                                                                                 (0.182)          
                                                                                                  
factor(nr)3275                                                                   0.542***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3282                                                                   0.660***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3289                                                                   0.454***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3290                                                                   0.456***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3307                                                                   1.321***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3333                                                                    -0.078          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3353                                                                    0.083           
                                                                                 (0.176)          
                                                                                                  
factor(nr)3380                                                                   0.522***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3381                                                                   0.587***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3389                                                                   0.672***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3394                                                                   0.656***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3401                                                                   0.397**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3414                                                                   0.701***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3420                                                                    0.301*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3440                                                                    -0.211          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3461                                                                   0.711***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3468                                                                    0.195           
                                                                                 (0.176)          
                                                                                                  
factor(nr)3482                                                                   1.056***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3495                                                                   0.538***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)3503                                                                   0.965***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3525                                                                   1.040***         
                                                                                 (0.175)          
                                                                                                  
factor(nr)3526                                                                   0.594***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3538                                                                   0.962***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)3563                                                                   0.636***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3575                                                                   0.997***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3580                                                                   0.361**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)3581                                                                   0.671***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3589                                                                    0.287           
                                                                                 (0.177)          
                                                                                                  
factor(nr)3591                                                                   0.674***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3598                                                                   0.864***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3602                                                                   1.082***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)3607                                                                    -0.019          
                                                                                 (0.187)          
                                                                                                  
factor(nr)3621                                                                   0.528***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3628                                                                   0.984***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3653                                                                   0.723***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3706                                                                   0.650***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3707                                                                   0.556***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3708                                                                   0.617***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3743                                                                   0.607***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3777                                                                   0.732***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)3831                                                                    0.227           
                                                                                 (0.176)          
                                                                                                  
factor(nr)3844                                                                   0.510***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3847                                                                   1.104***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)3848                                                                   0.651***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)3882                                                                    0.047           
                                                                                 (0.175)          
                                                                                                  
factor(nr)3937                                                                   0.520***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4000                                                                   1.072***         
                                                                                 (0.201)          
                                                                                                  
factor(nr)4004                                                                   0.976***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4025                                                                    0.135           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4032                                                                    0.157           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4046                                                                   0.564***         
                                                                                 (0.184)          
                                                                                                  
factor(nr)4088                                                                   1.447***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4091                                                                   1.271***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)4122                                                                   0.713***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4127                                                                    0.093           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4128                                                                    0.297*          
                                                                                 (0.178)          
                                                                                                  
factor(nr)4159                                                                   0.605***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4204                                                                    0.324*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)4229                                                                    0.314*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)4258                                                                   0.718***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4261                                                                   1.342***         
                                                                                 (0.200)          
                                                                                                  
factor(nr)4264                                                                    0.073           
                                                                                 (0.178)          
                                                                                                  
factor(nr)4278                                                                   0.594***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4297                                                                   0.538***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4302                                                                    -0.129          
                                                                                 (0.176)          
                                                                                                  
factor(nr)4321                                                                   0.473***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4328                                                                    0.239           
                                                                                 (0.177)          
                                                                                                  
factor(nr)4332                                                                   -0.371**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4335                                                                    0.342*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)4357                                                                   0.527***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4365                                                                    -0.039          
                                                                                 (0.176)          
                                                                                                  
factor(nr)4380                                                                   0.880***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)4394                                                                   0.724***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4510                                                                   0.643***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4559                                                                   0.374**          
                                                                                 (0.180)          
                                                                                                  
factor(nr)4563                                                                    0.019           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4569                                                                   0.791***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4603                                                                   0.734***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4607                                                                    0.166           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4633                                                                   0.505***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4676                                                                    0.125           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4701                                                                   0.952***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4716                                                                    0.122           
                                                                                 (0.178)          
                                                                                                  
factor(nr)4720                                                                   1.137***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)4759                                                                   0.596***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)4791                                                                   0.678***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)4811                                                                    0.096           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4828                                                                    0.108           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4857                                                                    -0.098          
                                                                                 (0.176)          
                                                                                                  
factor(nr)4858                                                                   0.976***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)4859                                                                    0.031           
                                                                                 (0.176)          
                                                                                                  
factor(nr)4866                                                                   0.818***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)4881                                                                   0.358**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)4884                                                                   0.522***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)4888                                                                    0.096           
                                                                                 (0.177)          
                                                                                                  
factor(nr)4901                                                                    0.218           
                                                                                 (0.179)          
                                                                                                  
factor(nr)4917                                                                    0.059           
                                                                                 (0.177)          
                                                                                                  
factor(nr)4926                                                                   0.440**          
                                                                                 (0.178)          
                                                                                                  
factor(nr)4982                                                                    0.102           
                                                                                 (0.178)          
                                                                                                  
factor(nr)5017                                                                   1.088***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5033                                                                   1.061***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5048                                                                    0.315*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)5122                                                                   0.657***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)5141                                                                   0.711***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)5147                                                                   1.045***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)5158                                                                   0.700***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5221                                                                   0.538***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)5223                                                                   0.486***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5227                                                                   0.652***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)5248                                                                    0.179           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5252                                                                    0.088           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5263                                                                   0.494***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)5274                                                                   0.756***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5335                                                                    0.318*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)5345                                                                    0.233           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5359                                                                    -0.082          
                                                                                 (0.177)          
                                                                                                  
factor(nr)5368                                                                    0.060           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5377                                                                   0.382**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)5390                                                                    0.288           
                                                                                 (0.177)          
                                                                                                  
factor(nr)5419                                                                    0.125           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5435                                                                    0.033           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5437                                                                    0.265           
                                                                                 (0.177)          
                                                                                                  
factor(nr)5497                                                                    0.195           
                                                                                 (0.177)          
                                                                                                  
factor(nr)5525                                                                    0.315*          
                                                                                 (0.180)          
                                                                                                  
factor(nr)5529                                                                   0.573***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)5531                                                                   0.927***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)5579                                                                    0.229           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5588                                                                   0.936***         
                                                                                 (0.194)          
                                                                                                  
factor(nr)5599                                                                   0.569***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5650                                                                    0.330*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)5660                                                                   0.724***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5665                                                                    0.155           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5666                                                                   0.495***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5698                                                                   0.686***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)5699                                                                   0.679***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)5731                                                                    0.318*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)5750                                                                   0.661***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)5755                                                                   0.546***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)5772                                                                    0.126           
                                                                                 (0.179)          
                                                                                                  
factor(nr)5816                                                                    0.211           
                                                                                 (0.177)          
                                                                                                  
factor(nr)5823                                                                    0.107           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5851                                                                    0.061           
                                                                                 (0.176)          
                                                                                                  
factor(nr)5857                                                                   0.438**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)5859                                                                   0.427**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)6016                                                                   0.794***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6020                                                                    -0.282          
                                                                                 (0.177)          
                                                                                                  
factor(nr)6025                                                                   -0.425**         
                                                                                 (0.177)          
                                                                                                  
factor(nr)6056                                                                    -0.104          
                                                                                 (0.176)          
                                                                                                  
factor(nr)6094                                                                   0.484***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)6186                                                                   0.487***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6395                                                                   0.979***         
                                                                                 (0.188)          
                                                                                                  
factor(nr)6430                                                                   0.403**          
                                                                                 (0.180)          
                                                                                                  
factor(nr)6446                                                                   0.555***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)6463                                                                    0.352*          
                                                                                 (0.187)          
                                                                                                  
factor(nr)6558                                                                   0.807***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6559                                                                   0.581***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6561                                                                   0.953***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6574                                                                    0.098           
                                                                                 (0.178)          
                                                                                                  
factor(nr)6648                                                                   0.774***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6813                                                                    0.274           
                                                                                 (0.177)          
                                                                                                  
factor(nr)6824                                                                   0.419**          
                                                                                 (0.179)          
                                                                                                  
factor(nr)6888                                                                   0.494***         
                                                                                 (0.187)          
                                                                                                  
factor(nr)6942                                                                   0.549***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6954                                                                   0.565***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)6955                                                                   0.678***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)6964                                                                   0.473***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)6987                                                                   1.456***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7025                                                                   0.906***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)7043                                                                   0.498***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7060                                                                   0.460***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7087                                                                    -0.207          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7238                                                                   0.680***         
                                                                                 (0.193)          
                                                                                                  
factor(nr)7279                                                                    0.270           
                                                                                 (0.178)          
                                                                                                  
factor(nr)7342                                                                   0.432**          
                                                                                 (0.179)          
                                                                                                  
factor(nr)7343                                                                   0.350**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7411                                                                    -0.038          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7424                                                                   0.651***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7429                                                                   0.515***         
                                                                                 (0.182)          
                                                                                                  
factor(nr)7454                                                                   0.730***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7472                                                                   0.402**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)7474                                                                    0.303*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7509                                                                   0.689***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)7539                                                                    -0.012          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7769                                                                   0.655***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)7783                                                                   0.449**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7784                                                                   1.929***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7801                                                                    -0.048          
                                                                                 (0.176)          
                                                                                                  
factor(nr)7824                                                                   0.546***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7874                                                                   1.107***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)7887                                                                   0.639***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)7923                                                                   1.238***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)7926                                                                   0.708***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)8021                                                                   0.824***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8087                                                                   0.460***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8089                                                                    0.222           
                                                                                 (0.177)          
                                                                                                  
factor(nr)8090                                                                   1.226***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8096                                                                   1.299***         
                                                                                 (0.221)          
                                                                                                  
factor(nr)8106                                                                   0.948***         
                                                                                 (0.200)          
                                                                                                  
factor(nr)8107                                                                   1.186***         
                                                                                 (0.221)          
                                                                                                  
factor(nr)8142                                                                    0.182           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8168                                                                   0.551***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8173                                                                   0.909***         
                                                                                 (0.202)          
                                                                                                  
factor(nr)8203                                                                   1.072***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8211                                                                    0.294           
                                                                                 (0.183)          
                                                                                                  
factor(nr)8224                                                                   0.807***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)8272                                                                   0.959***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)8300                                                                   0.386**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8304                                                                   0.470***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8364                                                                   0.348**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)8370                                                                   0.845***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8381                                                                    0.218           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8388                                                                   0.743***         
                                                                                 (0.194)          
                                                                                                  
factor(nr)8406                                                                   0.626***         
                                                                                 (0.184)          
                                                                                                  
factor(nr)8415                                                                    0.054           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8496                                                                    -0.112          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8501                                                                    -0.070          
                                                                                 (0.179)          
                                                                                                  
factor(nr)8518                                                                   1.243***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)8520                                                                   -0.353**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8524                                                                    -0.118          
                                                                                 (0.177)          
                                                                                                  
factor(nr)8548                                                                    0.115           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8556                                                                   0.625***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8564                                                                    0.106           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8581                                                                    -0.249          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8586                                                                    0.258           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8587                                                                   -0.370**         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8597                                                                   0.771***         
                                                                                 (0.183)          
                                                                                                  
factor(nr)8656                                                                    0.153           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8722                                                                   0.637***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8743                                                                   0.515***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8749                                                                   0.940***         
                                                                                 (0.202)          
                                                                                                  
factor(nr)8758                                                                   0.535***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)8796                                                                   0.780***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8838                                                                   0.406**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8842                                                                    0.145           
                                                                                 (0.176)          
                                                                                                  
factor(nr)8846                                                                    0.112           
                                                                                 (0.177)          
                                                                                                  
factor(nr)8860                                                                    0.124           
                                                                                 (0.178)          
                                                                                                  
factor(nr)8862                                                                   0.399**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8880                                                                   1.219***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)8886                                                                   0.631***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)8903                                                                    -0.239          
                                                                                 (0.176)          
                                                                                                  
factor(nr)8908                                                                    -0.023          
                                                                                 (0.177)          
                                                                                                  
factor(nr)8911                                                                    -0.034          
                                                                                 (0.177)          
                                                                                                  
factor(nr)8917                                                                   0.796***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)8991                                                                   0.913***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)8997                                                                   0.898***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9014                                                                   0.540***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9015                                                                   0.697***         
                                                                                 (0.187)          
                                                                                                  
factor(nr)9027                                                                   1.002***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9066                                                                    -0.153          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9082                                                                    0.274           
                                                                                 (0.178)          
                                                                                                  
factor(nr)9131                                                                   0.758***         
                                                                                 (0.201)          
                                                                                                  
factor(nr)9132                                                                   0.709***         
                                                                                 (0.188)          
                                                                                                  
factor(nr)9154                                                                   1.113***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9158                                                                    0.086           
                                                                                 (0.179)          
                                                                                                  
factor(nr)9184                                                                    0.164           
                                                                                 (0.177)          
                                                                                                  
factor(nr)9230                                                                    0.158           
                                                                                 (0.176)          
                                                                                                  
factor(nr)9265                                                                   0.437**          
                                                                                 (0.175)          
                                                                                                  
factor(nr)9367                                                                    0.207           
                                                                                 (0.176)          
                                                                                                  
factor(nr)9390                                                                   0.745***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9391                                                                   0.370**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9418                                                                   1.133***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9424                                                                   0.806***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9447                                                                   0.503***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9449                                                                    0.318*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9453                                                                   0.745***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9468                                                                   0.493***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9502                                                                   0.895***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)9505                                                                    0.046           
                                                                                 (0.179)          
                                                                                                  
factor(nr)9603                                                                    0.310*          
                                                                                 (0.188)          
                                                                                                  
factor(nr)9643                                                                   0.433**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9667                                                                   1.067***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9683                                                                    0.128           
                                                                                 (0.180)          
                                                                                                  
factor(nr)9694                                                                   0.847***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9710                                                                    0.280           
                                                                                 (0.177)          
                                                                                                  
factor(nr)9718                                                                   0.938***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9725                                                                    0.322*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9744                                                                   0.689***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9752                                                                   1.390***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9776                                                                   0.953***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)9786                                                                   0.624***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9791                                                                    0.328*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9794                                                                   0.473***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9810                                                                    -0.144          
                                                                                 (0.176)          
                                                                                                  
factor(nr)9846                                                                   0.825***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9859                                                                    0.148           
                                                                                 (0.178)          
                                                                                                  
factor(nr)9868                                                                    0.029           
                                                                                 (0.176)          
                                                                                                  
factor(nr)9876                                                                   0.853***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)9883                                                                   0.714***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)9889                                                                   0.988***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9901                                                                   0.689***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9936                                                                   0.895***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)9964                                                                   0.412**          
                                                                                 (0.177)          
                                                                                                  
factor(nr)10043                                                                   -0.172          
                                                                                 (0.178)          
                                                                                                  
factor(nr)10067                                                                  0.510***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)10091                                                                  0.697***         
                                                                                 (0.181)          
                                                                                                  
factor(nr)10120                                                                   -0.118          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10121                                                                   0.325*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10167                                                                  0.567***         
                                                                                 (0.178)          
                                                                                                  
factor(nr)10209                                                                   0.112           
                                                                                 (0.176)          
                                                                                                  
factor(nr)10230                                                                  0.724***         
                                                                                 (0.180)          
                                                                                                  
factor(nr)10265                                                                  0.993***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)10274                                                                   0.237           
                                                                                 (0.176)          
                                                                                                  
factor(nr)10311                                                                   0.301*          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10392                                                                   0.108           
                                                                                 (0.177)          
                                                                                                  
factor(nr)10425                                                                  0.945***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)10441                                                                   0.176           
                                                                                 (0.176)          
                                                                                                  
factor(nr)10457                                                                  0.446**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10469                                                                  0.447**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10524                                                                   0.088           
                                                                                 (0.177)          
                                                                                                  
factor(nr)10552                                                                   -0.185          
                                                                                 (0.176)          
                                                                                                  
factor(nr)10553                                                                  0.706***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)10570                                                                 -0.747***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)10593                                                                   0.284           
                                                                                 (0.184)          
                                                                                                  
factor(nr)10666                                                                  -0.324*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)11275                                                                   0.146           
                                                                                 (0.176)          
                                                                                                  
factor(nr)11328                                                                  0.495***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)11750                                                                  0.384**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)11821                                                                  0.808***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)11857                                                                  0.934***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)11887                                                                  0.396**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)11890                                                                  1.093***         
                                                                                 (0.211)          
                                                                                                  
factor(nr)11892                                                                  1.132***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)11924                                                                  0.354**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)11925                                                                  0.408**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)11957                                                                   0.004           
                                                                                 (0.177)          
                                                                                                  
factor(nr)11973                                                                  0.578***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)11990                                                                  1.010***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)12012                                                                   0.224           
                                                                                 (0.176)          
                                                                                                  
factor(nr)12013                                                                  0.568***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)12045                                                                   0.200           
                                                                                 (0.176)          
                                                                                                  
factor(nr)12055                                                                  0.674***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)12084                                                                  0.450**          
                                                                                 (0.179)          
                                                                                                  
factor(nr)12088                                                                   0.117           
                                                                                 (0.176)          
                                                                                                  
factor(nr)12122                                                                  0.586***         
                                                                                 (0.202)          
                                                                                                  
factor(nr)12179                                                                   0.301*          
                                                                                 (0.177)          
                                                                                                  
factor(nr)12182                                                                  0.515***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)12220                                                                  0.673***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)12221                                                                   -0.121          
                                                                                 (0.183)          
                                                                                                  
factor(nr)12245                                                                   -0.110          
                                                                                 (0.176)          
                                                                                                  
factor(nr)12276                                                                  0.655***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)12385                                                                  0.819***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)12410                                                                   0.040           
                                                                                 (0.178)          
                                                                                                  
factor(nr)12420                                                                  0.840***         
                                                                                 (0.177)          
                                                                                                  
factor(nr)12433                                                                  0.393**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)12451                                                                  0.431**          
                                                                                 (0.176)          
                                                                                                  
factor(nr)12477                                                                  1.004***         
                                                                                 (0.179)          
                                                                                                  
factor(nr)12500                                                                   0.222           
                                                                                 (0.178)          
                                                                                                  
factor(nr)12534                                                                  0.942***         
                                                                                 (0.176)          
                                                                                                  
factor(nr)12548                                                                   0.347*          
                                                                                 (0.180)          
                                                                                                  
educ                                                                                              
                                                                                                  
                                                                                                  
black                                                                                             
                                                                                                  
                                                                                                  
hisp                                                                                              
                                                                                                  
                                                                                                  
exper                                                                                             
                                                                                                  
                                                                                                  
Constant                    -0.445***                                            0.933***         
                             (0.030)                                             (0.125)          
                                                                                                  
--------------------------------------------------------------------------------------------------
Observations                  4,360                     4,360                     4,360           
R2                            0.181                     0.181                     0.621           
Adjusted R2                   0.179                     0.061                     0.566           
Residual Std. Error     0.328 (df = 4349)                                   0.351 (df = 3805)     
F Statistic         95.840*** (df = 10; 4349) 83.851*** (df = 10; 3805) 11.250*** (df = 554; 3805)
==================================================================================================
Note:                                                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="tabset-25-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb161-1"><a></a><span class="kw">use</span> <span class="st">"files/WAGEPAN.dta"</span> , <span class="kw">clear</span></span>
<span id="cb161-2"><a></a></span>
<span id="cb161-3"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> lwage_mean = <span class="kw">mean</span>(lwage) </span>
<span id="cb161-4"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> expersq_mean = <span class="kw">mean</span>(expersq) </span>
<span id="cb161-5"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> married_mean = <span class="kw">mean</span>(married) </span>
<span id="cb161-6"><a></a><span class="kw">bys</span> <span class="kw">nr</span>:  <span class="kw">egen</span> union_mean = <span class="kw">mean</span>(<span class="kw">union</span>)</span>
<span id="cb161-7"><a></a></span>
<span id="cb161-8"><a></a><span class="kw">gen</span> lwage_demean = lwage - lwage_mean</span>
<span id="cb161-9"><a></a><span class="kw">gen</span> expersq_demean = expersq - expersq_mean</span>
<span id="cb161-10"><a></a><span class="kw">gen</span> married_demean = married - married_mean</span>
<span id="cb161-11"><a></a><span class="kw">gen</span> union_demean = <span class="kw">union</span> - union_mean</span>
<span id="cb161-12"><a></a></span>
<span id="cb161-13"><a></a>xtset <span class="kw">nr</span> <span class="fu">year</span> </span>
<span id="cb161-14"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> lwage_demean expersq_demean married_demean union_demean i.<span class="fu">year</span></span>
<span id="cb161-15"><a></a>eststo: <span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper , <span class="kw">fe</span></span>
<span id="cb161-16"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span> i.<span class="kw">nr</span>  educ <span class="bn">black</span> hisp exper </span>
<span id="cb161-17"><a></a>esttab , mtitles(<span class="st">"Demean"</span> <span class="st">"FE"</span> <span class="st">"LSDV"</span>) <span class="kw">compress</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Panel variable: nr (strongly balanced)
 Time variable: year, 1980 to 1987
         Delta: 1 unit

(est1 stored)

(est2 stored)

(est3 stored)


-------------------------------------------------
                 (1)          (2)          (3)   
              Demean           FE         LSDV   
-------------------------------------------------
expe~emean  -0.00519***                          
             (-7.87)                             

marr~emean    0.0467**                           
              (2.73)                             

union_de~n    0.0800***                          
              (4.43)                             

1980.year          0            0            0   
                 (.)          (.)          (.)   

1981.year      0.151***     0.151***     0.151***
              (7.36)       (6.89)       (6.89)   

1982.year      0.253***     0.253***     0.253***
             (11.08)      (10.36)      (10.36)   

1983.year      0.354***     0.354***     0.354***
             (12.96)      (12.12)      (12.12)   

1984.year      0.490***     0.490***     0.490***
             (14.46)      (13.53)      (13.53)   

1985.year      0.617***     0.617***     0.617***
             (14.59)      (13.65)      (13.65)   

1986.year      0.765***     0.765***     0.765***
             (14.58)      (13.64)      (13.64)   

1987.year      0.925***     0.925***     0.925***
             (14.38)      (13.45)      (13.45)   

expersq                  -0.00519***  -0.00519***
                          (-7.36)      (-7.36)   

married                    0.0467*      0.0467*  
                           (2.55)       (2.55)   

union                      0.0800***    0.0800***
                           (4.14)       (4.14)   

educ                            0            0   
                              (.)          (.)   

black                           0            0   
                              (.)          (.)   

hisp                            0            0   
                              (.)          (.)   

exper                           0            0   
                              (.)          (.)   

13.nr                                        0   
                                           (.)   

17.nr                                    0.579** 
                                        (3.26)   

18.nr                                    0.929***
                                        (5.20)   

45.nr                                    0.554** 
                                        (3.15)   

110.nr                                   1.046***
                                        (5.82)   

120.nr                                   0.239   
                                        (1.36)   

126.nr                                   0.783***
                                        (4.45)   

150.nr                                  -0.140   
                                       (-0.80)   

162.nr                                   0.269   
                                        (1.53)   

166.nr                                   0.138   
                                        (0.78)   

189.nr                                   0.191   
                                        (1.09)   

193.nr                                   0.981***
                                        (5.58)   

209.nr                                   0.707***
                                        (4.01)   

212.nr                                   0.833***
                                        (4.74)   

218.nr                                   1.231***
                                        (6.99)   

243.nr                                   0.586***
                                        (3.29)   

259.nr                                   0.478** 
                                        (2.69)   

260.nr                                   0.789***
                                        (4.48)   

309.nr                                   1.052***
                                        (5.95)   

351.nr                                   0.358*  
                                        (2.02)   

353.nr                                   0.583***
                                        (3.31)   

383.nr                                   0.564** 
                                        (3.21)   

408.nr                                   0.801***
                                        (4.54)   

424.nr                                   1.345***
                                        (7.45)   

464.nr                                  0.0803   
                                        (0.46)   

483.nr                                   0.713***
                                        (3.98)   

556.nr                                   1.089***
                                        (6.20)   

560.nr                                   0.205   
                                        (1.17)   

569.nr                                  -0.431*  
                                       (-2.45)   

583.nr                                   0.852***
                                        (4.80)   

647.nr                                   0.360*  
                                        (2.04)   

658.nr                                   0.838***
                                        (4.73)   

684.nr                                   1.132***
                                        (6.42)   

711.nr                                 -0.0972   
                                       (-0.55)   

729.nr                                   0.837***
                                        (4.74)   

731.nr                                   0.574** 
                                        (3.23)   

732.nr                                   0.531** 
                                        (3.02)   

793.nr                                   0.498** 
                                        (2.84)   

797.nr                                   0.841***
                                        (4.75)   

800.nr                                   0.380*  
                                        (2.15)   

813.nr                                  -0.657***
                                       (-3.74)   

823.nr                                  -0.393*  
                                       (-2.23)   

827.nr                                   0.507** 
                                        (2.88)   

847.nr                                   0.489** 
                                        (2.79)   

851.nr                                   0.735***
                                        (4.17)   

863.nr                                   0.550** 
                                        (3.13)   

873.nr                                  -0.127   
                                       (-0.72)   

891.nr                                   0.735***
                                        (4.16)   

908.nr                                  -0.405*  
                                       (-2.30)   

910.nr                                   0.679***
                                        (3.87)   

916.nr                                   0.564** 
                                        (3.21)   

919.nr                                   0.238   
                                        (1.34)   

922.nr                                   1.011***
                                        (5.76)   

924.nr                                 -0.0709   
                                       (-0.40)   

925.nr                                   0.809***
                                        (4.60)   

944.nr                                   0.106   
                                        (0.60)   

945.nr                                   0.106   
                                        (0.60)   

947.nr                                   1.154***
                                        (6.52)   

955.nr                                   1.006***
                                        (5.64)   

965.nr                                   0.434*  
                                        (2.42)   

996.nr                                 0.00740   
                                        (0.04)   

1007.nr                                  0.996***
                                        (5.61)   

1054.nr                                  0.133   
                                        (0.75)   

1064.nr                                  0.858***
                                        (4.81)   

1081.nr                                  0.179   
                                        (1.02)   

1085.nr                                  0.114   
                                        (0.65)   

1091.nr                                  0.226   
                                        (1.23)   

1094.nr                                  0.600***
                                        (3.38)   

1096.nr                                  0.251   
                                        (1.37)   

1098.nr                                  0.837***
                                        (4.77)   

1102.nr                                  0.948***
                                        (5.38)   

1107.nr                                  0.762***
                                        (4.23)   

1142.nr                                  0.715***
                                        (4.07)   

1156.nr                                  0.569** 
                                        (3.17)   

1180.nr                                  0.636***
                                        (3.61)   

1190.nr                                  0.119   
                                        (0.68)   

1204.nr                                  0.888***
                                        (4.93)   

1249.nr                                  0.468** 
                                        (2.60)   

1272.nr                                  0.612***
                                        (3.47)   

1311.nr                                  0.481** 
                                        (2.74)   

1316.nr                                  0.921***
                                        (5.17)   

1318.nr                                  0.625** 
                                        (3.25)   

1345.nr                                  0.549** 
                                        (3.08)   

1397.nr                                  0.653***
                                        (3.62)   

1434.nr                                -0.0818   
                                       (-0.46)   

1492.nr                                  0.408*  
                                        (2.30)   

1496.nr                                 -0.219   
                                       (-1.24)   

1506.nr                                 0.0822   
                                        (0.47)   

1515.nr                                  0.281   
                                        (1.60)   

1520.nr                                  0.375*  
                                        (2.07)   

1528.nr                                  0.136   
                                        (0.77)   

1554.nr                                  0.312   
                                        (1.77)   

1575.nr                                  0.577** 
                                        (3.26)   

1576.nr                                  0.504** 
                                        (2.86)   

1628.nr                                  0.440*  
                                        (2.50)   

1641.nr                                  0.974***
                                        (5.46)   

1644.nr                                  0.263   
                                        (1.50)   

1653.nr                                  0.629***
                                        (3.58)   

1654.nr                                  0.663***
                                        (3.73)   

1721.nr                                  1.160***
                                        (6.47)   

1742.nr                                  0.861***
                                        (4.90)   

1744.nr                                  0.557** 
                                        (3.16)   

1763.nr                                 -0.194   
                                       (-1.11)   

1777.nr                                  0.115   
                                        (0.65)   

1843.nr                                  1.310***
                                        (7.41)   

1891.nr                                -0.0896   
                                       (-0.51)   

1895.nr                                  0.604***
                                        (3.41)   

1899.nr                                  0.171   
                                        (0.97)   

1925.nr                                  0.488** 
                                        (2.78)   

1930.nr                                  0.251   
                                        (1.43)   

1961.nr                                  0.745***
                                        (4.18)   

1963.nr                                  0.470** 
                                        (2.66)   

1979.nr                                  0.828***
                                        (4.63)   

1988.nr                                -0.0621   
                                       (-0.35)   

2000.nr                                  0.637***
                                        (3.60)   

2014.nr                                  0.310   
                                        (1.77)   

2025.nr                                  0.432*  
                                        (2.45)   

2038.nr                                  0.180   
                                        (1.02)   

2075.nr                                  0.928***
                                        (5.14)   

2101.nr                                  1.158***
                                        (6.57)   

2106.nr                                  0.595***
                                        (3.33)   

2107.nr                                  0.460** 
                                        (2.62)   

2108.nr                                  0.816***
                                        (4.61)   

2147.nr                                 -0.860***
                                       (-4.90)   

2157.nr                                 0.0546   
                                        (0.30)   

2163.nr                                  1.092***
                                        (6.09)   

2173.nr                                  0.148   
                                        (0.84)   

2180.nr                                  0.411*  
                                        (2.34)   

2183.nr                                  0.392*  
                                        (2.23)   

2216.nr                                  0.540** 
                                        (3.07)   

2220.nr                                  0.991***
                                        (5.63)   

2227.nr                                  0.255   
                                        (1.44)   

2264.nr                                -0.0930   
                                       (-0.53)   

2306.nr                                -0.0521   
                                       (-0.29)   

2312.nr                                  0.816***
                                        (4.64)   

2314.nr                                  0.969***
                                        (5.39)   

2329.nr                                  0.545** 
                                        (3.09)   

2335.nr                                  0.506** 
                                        (2.82)   

2341.nr                                  0.471** 
                                        (2.68)   

2351.nr                                 0.0458   
                                        (0.26)   

2386.nr                                 -0.154   
                                       (-0.87)   

2401.nr                                  0.644***
                                        (3.57)   

2413.nr                                  0.999***
                                        (5.59)   

2421.nr                                 0.0360   
                                        (0.20)   

2445.nr                                  0.463** 
                                        (2.60)   

2451.nr                                  0.592***
                                        (3.35)   

2494.nr                                  0.168   
                                        (0.94)   

2508.nr                                  0.848***
                                        (4.79)   

2535.nr                                  0.486** 
                                        (2.72)   

2540.nr                                -0.0591   
                                       (-0.34)   

2685.nr                                  1.031***
                                        (5.87)   

2711.nr                                 0.0516   
                                        (0.29)   

2718.nr                                  1.059***
                                        (5.98)   

2721.nr                                  0.157   
                                        (0.86)   

2733.nr                                 -0.146   
                                       (-0.82)   

2741.nr                                  0.419*  
                                        (2.32)   

2745.nr                                  0.556** 
                                        (3.15)   

2751.nr                                  0.456*  
                                        (2.55)   

2774.nr                                  0.903***
                                        (5.09)   

2801.nr                                 0.0497   
                                        (0.28)   

2813.nr                                  0.222   
                                        (1.26)   

2833.nr                                  0.621***
                                        (3.52)   

2839.nr                                  0.646***
                                        (3.66)   

2842.nr                                  0.942***
                                        (5.31)   

2866.nr                                  0.707***
                                        (3.99)   

2868.nr                                  0.978***
                                        (5.54)   

2874.nr                                0.00693   
                                        (0.04)   

2916.nr                                  0.345*  
                                        (1.96)   

2951.nr                                  0.313   
                                        (1.71)   

2980.nr                                  0.327   
                                        (1.85)   

2994.nr                                  0.506** 
                                        (2.86)   

2997.nr                                  0.601***
                                        (3.41)   

3017.nr                                  0.936***
                                        (5.31)   

3037.nr                                  1.040***
                                        (5.81)   

3059.nr                                  0.694***
                                        (3.84)   

3062.nr                                  1.166***
                                        (6.64)   

3100.nr                                  0.637***
                                        (3.57)   

3102.nr                                 -0.259   
                                       (-1.48)   

3127.nr                                 -0.407*  
                                       (-2.31)   

3136.nr                                  0.698***
                                        (3.94)   

3137.nr                                  0.892***
                                        (5.08)   

3138.nr                                  0.665***
                                        (3.75)   

3140.nr                                  0.843***
                                        (4.77)   

3193.nr                                  0.686***
                                        (3.90)   

3196.nr                                  0.681***
                                        (3.85)   

3200.nr                                  0.771***
                                        (4.12)   

3202.nr                                  0.593***
                                        (3.34)   

3207.nr                                  0.471** 
                                        (2.64)   

3208.nr                                  0.855***
                                        (4.82)   

3210.nr                                  0.708***
                                        (4.02)   

3215.nr                                  0.324   
                                        (1.82)   

3219.nr                                  0.237   
                                        (1.35)   

3226.nr                                  0.642***
                                        (3.64)   

3235.nr                                  0.144   
                                        (0.81)   

3239.nr                                 -0.375*  
                                       (-2.14)   

3271.nr                                  0.756***
                                        (4.15)   

3275.nr                                  0.542** 
                                        (3.09)   

3282.nr                                  0.660***
                                        (3.75)   

3289.nr                                  0.454** 
                                        (2.58)   

3290.nr                                  0.456** 
                                        (2.60)   

3307.nr                                  1.321***
                                        (7.47)   

3333.nr                                -0.0781   
                                       (-0.44)   

3353.nr                                 0.0825   
                                        (0.47)   

3380.nr                                  0.522** 
                                        (2.96)   

3381.nr                                  0.587***
                                        (3.34)   

3389.nr                                  0.672***
                                        (3.81)   

3394.nr                                  0.656***
                                        (3.73)   

3401.nr                                  0.397*  
                                        (2.25)   

3414.nr                                  0.701***
                                        (3.99)   

3420.nr                                  0.301   
                                        (1.71)   

3440.nr                                 -0.211   
                                       (-1.20)   

3461.nr                                  0.711***
                                        (4.05)   

3468.nr                                  0.195   
                                        (1.11)   

3482.nr                                  1.056***
                                        (5.99)   

3495.nr                                  0.538** 
                                        (2.99)   

3503.nr                                  0.965***
                                        (5.42)   

3525.nr                                  1.040***
                                        (5.93)   

3526.nr                                  0.594***
                                        (3.33)   

3538.nr                                  0.962***
                                        (5.33)   

3563.nr                                  0.636***
                                        (3.60)   

3575.nr                                  0.997***
                                        (5.59)   

3580.nr                                  0.361*  
                                        (2.06)   

3581.nr                                  0.671***
                                        (3.82)   

3589.nr                                  0.287   
                                        (1.62)   

3591.nr                                  0.674***
                                        (3.82)   

3598.nr                                  0.864***
                                        (4.90)   

3602.nr                                  1.082***
                                        (6.00)   

3607.nr                                -0.0189   
                                       (-0.10)   

3621.nr                                  0.528** 
                                        (2.97)   

3628.nr                                  0.984***
                                        (5.55)   

3653.nr                                  0.723***
                                        (4.10)   

3706.nr                                  0.650***
                                        (3.67)   

3707.nr                                  0.556** 
                                        (3.15)   

3708.nr                                  0.617***
                                        (3.51)   

3743.nr                                  0.607***
                                        (3.45)   

3777.nr                                  0.732***
                                        (4.13)   

3831.nr                                  0.227   
                                        (1.29)   

3844.nr                                  0.510** 
                                        (2.89)   

3847.nr                                  1.104***
                                        (6.22)   

3848.nr                                  0.651***
                                        (3.71)   

3882.nr                                 0.0468   
                                        (0.27)   

3937.nr                                  0.520** 
                                        (2.94)   

4000.nr                                  1.072***
                                        (5.34)   

4004.nr                                  0.976***
                                        (5.50)   

4025.nr                                  0.135   
                                        (0.77)   

4032.nr                                  0.157   
                                        (0.89)   

4046.nr                                  0.564** 
                                        (3.07)   

4088.nr                                  1.447***
                                        (8.16)   

4091.nr                                  1.271***
                                        (7.14)   

4122.nr                                  0.713***
                                        (4.04)   

4127.nr                                 0.0934   
                                        (0.53)   

4128.nr                                  0.297   
                                        (1.67)   

4159.nr                                  0.605***
                                        (3.43)   

4204.nr                                  0.324   
                                        (1.82)   

4229.nr                                  0.314   
                                        (1.79)   

4258.nr                                  0.718***
                                        (4.07)   

4261.nr                                  1.342***
                                        (6.70)   

4264.nr                                 0.0729   
                                        (0.41)   

4278.nr                                  0.594***
                                        (3.35)   

4297.nr                                  0.538** 
                                        (3.05)   

4302.nr                                 -0.129   
                                       (-0.74)   

4321.nr                                  0.473** 
                                        (2.68)   

4328.nr                                  0.239   
                                        (1.35)   

4332.nr                                 -0.371*  
                                       (-2.11)   

4335.nr                                  0.342   
                                        (1.93)   

4357.nr                                  0.527** 
                                        (2.98)   

4365.nr                                -0.0388   
                                       (-0.22)   

4380.nr                                  0.880***
                                        (4.94)   

4394.nr                                  0.724***
                                        (4.12)   

4510.nr                                  0.643***
                                        (3.66)   

4559.nr                                  0.374*  
                                        (2.08)   

4563.nr                                 0.0190   
                                        (0.11)   

4569.nr                                  0.791***
                                        (4.48)   

4603.nr                                  0.734***
                                        (4.16)   

4607.nr                                  0.166   
                                        (0.94)   

4633.nr                                  0.505** 
                                        (2.86)   

4676.nr                                  0.125   
                                        (0.71)   

4701.nr                                  0.952***
                                        (5.42)   

4716.nr                                  0.122   
                                        (0.69)   

4720.nr                                  1.137***
                                        (6.28)   

4759.nr                                  0.596***
                                        (3.33)   

4791.nr                                  0.678***
                                        (3.74)   

4811.nr                                 0.0962   
                                        (0.55)   

4828.nr                                  0.108   
                                        (0.61)   

4857.nr                                -0.0984   
                                       (-0.56)   

4858.nr                                  0.976***
                                        (5.54)   

4859.nr                                 0.0313   
                                        (0.18)   

4866.nr                                  0.818***
                                        (4.62)   

4881.nr                                  0.358*  
                                        (2.02)   

4884.nr                                  0.522** 
                                        (2.93)   

4888.nr                                 0.0963   
                                        (0.55)   

4901.nr                                  0.218   
                                        (1.22)   

4917.nr                                 0.0595   
                                        (0.34)   

4926.nr                                  0.440*  
                                        (2.47)   

4982.nr                                  0.102   
                                        (0.57)   

5017.nr                                  1.088***
                                        (6.19)   

5033.nr                                  1.061***
                                        (6.03)   

5048.nr                                  0.315   
                                        (1.79)   

5122.nr                                  0.657***
                                        (3.70)   

5141.nr                                  0.711***
                                        (4.03)   

5147.nr                                  1.045***
                                        (5.84)   

5158.nr                                  0.700***
                                        (3.97)   

5221.nr                                  0.538** 
                                        (3.04)   

5223.nr                                  0.486** 
                                        (2.76)   

5227.nr                                  0.652***
                                        (3.63)   

5248.nr                                  0.179   
                                        (1.02)   

5252.nr                                 0.0879   
                                        (0.50)   

5263.nr                                  0.494** 
                                        (2.79)   

5274.nr                                  0.756***
                                        (4.28)   

5335.nr                                  0.318   
                                        (1.80)   

5345.nr                                  0.233   
                                        (1.33)   

5359.nr                                -0.0821   
                                       (-0.46)   

5368.nr                                 0.0598   
                                        (0.34)   

5377.nr                                  0.382*  
                                        (2.18)   

5390.nr                                  0.288   
                                        (1.63)   

5419.nr                                  0.125   
                                        (0.71)   

5435.nr                                 0.0333   
                                        (0.19)   

5437.nr                                  0.265   
                                        (1.50)   

5497.nr                                  0.195   
                                        (1.10)   

5525.nr                                  0.315   
                                        (1.75)   

5529.nr                                  0.573** 
                                        (3.21)   

5531.nr                                  0.927***
                                        (5.16)   

5579.nr                                  0.229   
                                        (1.30)   

5588.nr                                  0.936***
                                        (4.83)   

5599.nr                                  0.569** 
                                        (3.23)   

5650.nr                                  0.330   
                                        (1.87)   

5660.nr                                  0.724***
                                        (4.11)   

5665.nr                                  0.155   
                                        (0.88)   

5666.nr                                  0.495** 
                                        (2.81)   

5698.nr                                  0.686***
                                        (3.84)   

5699.nr                                  0.679***
                                        (3.85)   

5731.nr                                  0.318   
                                        (1.80)   

5750.nr                                  0.661***
                                        (3.66)   

5755.nr                                  0.546** 
                                        (3.06)   

5772.nr                                  0.126   
                                        (0.71)   

5816.nr                                  0.211   
                                        (1.19)   

5823.nr                                  0.107   
                                        (0.61)   

5851.nr                                 0.0606   
                                        (0.35)   

5857.nr                                  0.438*  
                                        (2.49)   

5859.nr                                  0.427*  
                                        (2.42)   

6016.nr                                  0.794***
                                        (4.52)   

6020.nr                                 -0.282   
                                       (-1.59)   

6025.nr                                 -0.425*  
                                       (-2.41)   

6056.nr                                 -0.104   
                                       (-0.59)   

6094.nr                                  0.484** 
                                        (2.72)   

6186.nr                                  0.487** 
                                        (2.76)   

6395.nr                                  0.979***
                                        (5.21)   

6430.nr                                  0.403*  
                                        (2.24)   

6446.nr                                  0.555** 
                                        (3.14)   

6463.nr                                  0.352   
                                        (1.88)   

6558.nr                                  0.807***
                                        (4.58)   

6559.nr                                  0.581** 
                                        (3.29)   

6561.nr                                  0.953***
                                        (5.42)   

6574.nr                                 0.0977   
                                        (0.55)   

6648.nr                                  0.774***
                                        (4.40)   

6813.nr                                  0.274   
                                        (1.55)   

6824.nr                                  0.419*  
                                        (2.34)   

6888.nr                                  0.494** 
                                        (2.64)   

6942.nr                                  0.549** 
                                        (3.12)   

6954.nr                                  0.565** 
                                        (3.20)   

6955.nr                                  0.678***
                                        (3.85)   

6964.nr                                  0.473** 
                                        (2.64)   

6987.nr                                  1.456***
                                        (8.26)   

7025.nr                                  0.906***
                                        (5.07)   

7043.nr                                  0.498** 
                                        (2.82)   

7060.nr                                  0.460** 
                                        (2.61)   

7087.nr                                 -0.207   
                                       (-1.18)   

7238.nr                                  0.680***
                                        (3.52)   

7279.nr                                  0.270   
                                        (1.51)   

7342.nr                                  0.432*  
                                        (2.41)   

7343.nr                                  0.350*  
                                        (1.99)   

7411.nr                                -0.0378   
                                       (-0.21)   

7424.nr                                  0.651***
                                        (3.70)   

7429.nr                                  0.515** 
                                        (2.83)   

7454.nr                                  0.730***
                                        (4.16)   

7472.nr                                  0.402*  
                                        (2.27)   

7474.nr                                  0.303   
                                        (1.72)   

7509.nr                                  0.689***
                                        (3.80)   

7539.nr                                -0.0121   
                                       (-0.07)   

7769.nr                                  0.655***
                                        (3.71)   

7783.nr                                  0.449*  
                                        (2.55)   

7784.nr                                  1.929***
                                       (10.99)   

7801.nr                                -0.0478   
                                       (-0.27)   

7824.nr                                  0.546** 
                                        (3.11)   

7874.nr                                  1.107***
                                        (6.30)   

7887.nr                                  0.639***
                                        (3.59)   

7923.nr                                  1.238***
                                        (6.88)   

7926.nr                                  0.708***
                                        (3.91)   

8021.nr                                  0.824***
                                        (4.69)   

8087.nr                                  0.460** 
                                        (2.61)   

8089.nr                                  0.222   
                                        (1.26)   

8090.nr                                  1.226***
                                        (6.97)   

8096.nr                                  1.299***
                                        (5.89)   

8106.nr                                  0.948***
                                        (4.74)   

8107.nr                                  1.186***
                                        (5.38)   

8142.nr                                  0.182   
                                        (1.04)   

8168.nr                                  0.551** 
                                        (3.12)   

8173.nr                                  0.909***
                                        (4.51)   

8203.nr                                  1.072***
                                        (6.07)   

8211.nr                                  0.294   
                                        (1.61)   

8224.nr                                  0.807***
                                        (4.50)   

8272.nr                                  0.959***
                                        (5.40)   

8300.nr                                  0.386*  
                                        (2.20)   

8304.nr                                  0.470** 
                                        (2.67)   

8364.nr                                  0.348*  
                                        (1.96)   

8370.nr                                  0.845***
                                        (4.78)   

8381.nr                                  0.218   
                                        (1.24)   

8388.nr                                  0.743***
                                        (3.83)   

8406.nr                                  0.626***
                                        (3.41)   

8415.nr                                 0.0542   
                                        (0.31)   

8496.nr                                 -0.112   
                                       (-0.64)   

8501.nr                                -0.0699   
                                       (-0.39)   

8518.nr                                  1.243***
                                        (6.89)   

8520.nr                                 -0.353*  
                                       (-2.00)   

8524.nr                                 -0.118   
                                       (-0.67)   

8548.nr                                  0.115   
                                        (0.65)   

8556.nr                                  0.625***
                                        (3.55)   

8564.nr                                  0.106   
                                        (0.60)   

8581.nr                                 -0.249   
                                       (-1.41)   

8586.nr                                  0.258   
                                        (1.47)   

8587.nr                                 -0.370*  
                                       (-2.10)   

8597.nr                                  0.771***
                                        (4.21)   

8656.nr                                  0.153   
                                        (0.87)   

8722.nr                                  0.637***
                                        (3.59)   

8743.nr                                  0.515** 
                                        (2.90)   

8749.nr                                  0.940***
                                        (4.67)   

8758.nr                                  0.535** 
                                        (3.02)   

8796.nr                                  0.780***
                                        (4.42)   

8838.nr                                  0.406*  
                                        (2.30)   

8842.nr                                  0.145   
                                        (0.82)   

8846.nr                                  0.112   
                                        (0.63)   

8860.nr                                  0.124   
                                        (0.70)   

8862.nr                                  0.399*  
                                        (2.27)   

8880.nr                                  1.219***
                                        (6.85)   

8886.nr                                  0.631***
                                        (3.52)   

8903.nr                                 -0.239   
                                       (-1.35)   

8908.nr                                -0.0227   
                                       (-0.13)   

8911.nr                                -0.0340   
                                       (-0.19)   

8917.nr                                  0.796***
                                        (4.48)   

8991.nr                                  0.913***
                                        (5.18)   

8997.nr                                  0.898***
                                        (5.09)   

9014.nr                                  0.540** 
                                        (3.05)   

9015.nr                                  0.697***
                                        (3.72)   

9027.nr                                  1.002***
                                        (5.68)   

9066.nr                                 -0.153   
                                       (-0.87)   

9082.nr                                  0.274   
                                        (1.54)   

9131.nr                                  0.758***
                                        (3.77)   

9132.nr                                  0.709***
                                        (3.77)   

9154.nr                                  1.113***
                                        (6.32)   

9158.nr                                 0.0857   
                                        (0.48)   

9184.nr                                  0.164   
                                        (0.92)   

9230.nr                                  0.158   
                                        (0.90)   

9265.nr                                  0.437*  
                                        (2.49)   

9367.nr                                  0.207   
                                        (1.18)   

9390.nr                                  0.745***
                                        (4.20)   

9391.nr                                  0.370*  
                                        (2.10)   

9418.nr                                  1.133***
                                        (6.44)   

9424.nr                                  0.806***
                                        (4.56)   

9447.nr                                  0.503** 
                                        (2.85)   

9449.nr                                  0.318   
                                        (1.81)   

9453.nr                                  0.745***
                                        (4.22)   

9468.nr                                  0.493** 
                                        (2.81)   

9502.nr                                  0.895***
                                        (4.95)   

9505.nr                                 0.0464   
                                        (0.26)   

9603.nr                                  0.310   
                                        (1.65)   

9643.nr                                  0.433*  
                                        (2.46)   

9667.nr                                  1.067***
                                        (6.07)   

9683.nr                                  0.128   
                                        (0.71)   

9694.nr                                  0.847***
                                        (4.82)   

9710.nr                                  0.280   
                                        (1.58)   

9718.nr                                  0.938***
                                        (5.34)   

9725.nr                                  0.322   
                                        (1.84)   

9744.nr                                  0.689***
                                        (3.92)   

9752.nr                                  1.390***
                                        (7.88)   

9776.nr                                  0.953***
                                        (5.37)   

9786.nr                                  0.624***
                                        (3.55)   

9791.nr                                  0.328   
                                        (1.86)   

9794.nr                                  0.473** 
                                        (2.67)   

9810.nr                                 -0.144   
                                       (-0.82)   

9846.nr                                  0.825***
                                        (4.65)   

9859.nr                                  0.148   
                                        (0.83)   

9868.nr                                 0.0289   
                                        (0.16)   

9876.nr                                  0.853***
                                        (4.78)   

9883.nr                                  0.714***
                                        (4.05)   

9889.nr                                  0.988***
                                        (5.59)   

9901.nr                                  0.689***
                                        (3.88)   

9936.nr                                  0.895***
                                        (5.06)   

9964.nr                                  0.412*  
                                        (2.32)   

10043.nr                                -0.172   
                                       (-0.97)   

10067.nr                                 0.510** 
                                        (2.89)   

10091.nr                                 0.697***
                                        (3.86)   

10120.nr                                -0.118   
                                       (-0.67)   

10121.nr                                 0.325   
                                        (1.85)   

10167.nr                                 0.567** 
                                        (3.18)   

10209.nr                                 0.112   
                                        (0.63)   

10230.nr                                 0.724***
                                        (4.03)   

10265.nr                                 0.993***
                                        (5.63)   

10274.nr                                 0.237   
                                        (1.35)   

10311.nr                                 0.301   
                                        (1.71)   

10392.nr                                 0.108   
                                        (0.61)   

10425.nr                                 0.945***
                                        (5.34)   

10441.nr                                 0.176   
                                        (1.00)   

10457.nr                                 0.446*  
                                        (2.53)   

10469.nr                                 0.447*  
                                        (2.54)   

10524.nr                                0.0885   
                                        (0.50)   

10552.nr                                -0.185   
                                       (-1.05)   

10553.nr                                 0.706***
                                        (3.96)   

10570.nr                                -0.747***
                                       (-4.23)   

10593.nr                                 0.284   
                                        (1.54)   

10666.nr                                -0.324   
                                       (-1.83)   

11275.nr                                 0.146   
                                        (0.83)   

11328.nr                                 0.495** 
                                        (2.76)   

11750.nr                                 0.384*  
                                        (2.19)   

11821.nr                                 0.808***
                                        (4.60)   

11857.nr                                 0.934***
                                        (5.27)   

11887.nr                                 0.396*  
                                        (2.24)   

11890.nr                                 1.093***
                                        (5.18)   

11892.nr                                 1.132***
                                        (6.38)   

11924.nr                                 0.354*  
                                        (2.02)   

11925.nr                                 0.408*  
                                        (2.31)   

11957.nr                               0.00425   
                                        (0.02)   

11973.nr                                 0.578** 
                                        (3.26)   

11990.nr                                 1.010***
                                        (5.73)   

12012.nr                                 0.224   
                                        (1.27)   

12013.nr                                 0.568** 
                                        (3.24)   

12045.nr                                 0.200   
                                        (1.13)   

12055.nr                                 0.674***
                                        (3.81)   

12084.nr                                 0.450*  
                                        (2.51)   

12088.nr                                 0.117   
                                        (0.66)   

12122.nr                                 0.586** 
                                        (2.91)   

12179.nr                                 0.301   
                                        (1.70)   

12182.nr                                 0.515** 
                                        (2.93)   

12220.nr                                 0.673***
                                        (3.81)   

12221.nr                                -0.121   
                                       (-0.66)   

12245.nr                                -0.110   
                                       (-0.63)   

12276.nr                                 0.655***
                                        (3.69)   

12385.nr                                 0.819***
                                        (4.57)   

12410.nr                                0.0399   
                                        (0.22)   

12420.nr                                 0.840***
                                        (4.74)   

12433.nr                                 0.393*  
                                        (2.23)   

12451.nr                                 0.431*  
                                        (2.45)   

12477.nr                                 1.004***
                                        (5.62)   

12500.nr                                 0.222   
                                        (1.25)   

12534.nr                                 0.942***
                                        (5.35)   

12548.nr                                 0.347   
                                        (1.93)   

_cons         -0.445***     1.426***     0.933***
            (-14.96)      (77.75)       (7.44)   
-------------------------------------------------
N               4360         4360         4360   
-------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="practical-tips-3" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>Notice that the parameter <span class="math inline">\(\delta\)</span> does not have meaning.</p>
<p><span class="math display">\[y_{i,t} = \alpha + \beta_1 x_{i,t} + \delta FE +  \epsilon_{i,t}\]</span></p>
<p>In fact, the previous slides have shown that you will find the same results of a FE model if you include the dummies for the units in the panel (i.e., dummies for the firms or individuals, etc.).</p>
<p>This is called <strong>least squares dummy variable (LSDV) model</strong>.</p>
<ul>
<li><p>the SE are also identical to the within-transformation model.</p></li>
<li><p>But the R2 of the LSDV will be very high because you are including a lot of “explanatory variables”.</p></li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>At the end of the day, you will use the package for the unit’s FE (i.e., the firm), and will include the additional FE as dummies, just like a LSDV model.</p>
</div>
</div>
</div>
</section>
<section id="practical-tips-4" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>When you estimate a LSDV, the software will inform an <span class="math inline">\(\alpha\)</span>.</p>
<p>But this coefficient <strong>has no interpretation whatsoever.</strong></p>
<ul>
<li>it will be FE for the dropped unit of FE.</li>
</ul>
<p>You can simply ignore it, you even don’t need to include in your final table.</p>
<p>No problem if you do, just <strong>don’t make inferences from it</strong>.</p>
</section>
<section id="practical-tips-5" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>A FE model helps a lot, but it only does what it can do.</p>
<p>That is, FE models do not capture <strong>time-variant unobserved heterogeneity</strong>.</p>
<div class="fragment">
<p>Also, if you have constant Xs in your model, you will have to drop them.</p>
<ul>
<li><p>More technically, if there is no within-variation in a X, you cannot include it (the software will drop them).</p></li>
<li><p>For instance, the software will drop <span class="math inline">\(year_{birth}\)</span> below if you include CEO FE.</p></li>
</ul>
<p><span class="math display">\[Y_{i,t} = \alpha + \beta_1 year_{birth} + CEO \;FE + ... + \epsilon_{i,t}\]</span></p>
<p>If you attempt to include the CEO FE manually, the software will drop a random CEO FE or the variable <span class="math inline">\(year_{birth}\)</span>. If you get a beta for <span class="math inline">\(year_{birth}\)</span> it has no meaning.</p>
</div>
</section>
<section id="practical-tips-6" class="slide level2 smaller" data-background="#fce0cc">
<h2>Practical Tips</h2>
<p>Adding many FE can demand a lot of computational power.</p>
<p>Consider the multidimensional model as follows:</p>
<p><span class="math display">\[Y_{i,t} = \alpha + \beta_1 X_{i,t} + Firm \;FE + Year\; FE + Year.Industry \;FE + CEO \;FE + ... + \epsilon_{i,t}\]</span></p>
<p>It would take a while to estimate in an average computer.</p>
</section></section>
<section>
<section id="random-effects" class="title-slide slide level1 smaller center" data-background="#c6f7ec">
<h1>Random Effects</h1>

</section>
<section id="random-effects-1" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Random Effects</h2>
<p>Remember that:</p>
<p><span class="math display">\[\epsilon_{i,t} = c_i + \mu_{i,t}\]</span></p>
<p>The most important thing here is whether <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are correlated.</p>
<ul>
<li><p>If they are, you should estimate Fixed Effects</p></li>
<li><p>If <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are not correlated, then <span class="math inline">\(c_i\)</span> is referred to as a <strong>random effect</strong>.</p>
<ul>
<li>Endogeneity is not a concern; however, the computation of standard errors is affected.</li>
</ul></li>
</ul>
<p>But, if the <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are not correlated, there is <strong>no endogeneity concern</strong>.</p>
<p><span class="math inline">\(c_i\)</span> can be let as part of the <span class="math inline">\(\epsilon_{i,t}\)</span> without bias in the estimated betas.</p>
</section>
<section id="random-effects-2" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Random Effects</h2>
<p>Additionally, the assumption that <span class="math inline">\(x_{it}\)</span> and <span class="math inline">\(c_i\)</span> are not correlated is rather strong and not practical to most applications of corporate finance, economics or public policy.</p>
<p>RE is a model not used often. Cunningham does not even discuss it.</p>
<p><em>If the key explanatory variable is constant over time, we cannot use FE to estimate its effect on y.</em></p>
<p><em>Of course, we can only use RE because we are willing to assume the unobserved effect is uncorrelated with all explanatory variables.</em></p>
<p><em>Typically, if one uses RE, and as many time-constant controls as possible are included among the explanatory variables (with an FE analysis, it is not necessary to include such controls) RE is preferred to pooled OLS because RE is generally more efficient.</em></p>
<p>(Wooldridge, p.496)</p>
</section>
<section id="random-effects-3" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Random Effects</h2>
<div class="panel-tabset">
<ul id="tabset-26" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-26-1">R</a></li><li><a href="#tabset-26-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-26-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb163-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb163-2"><a></a><span class="fu">library</span>(plm)</span>
<span id="cb163-3"><a></a><span class="fu">library</span>(jtools)</span>
<span id="cb163-4"><a></a><span class="fu">library</span>(foreign)</span>
<span id="cb163-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/WAGEPAN.dta"</span>)</span>
<span id="cb163-6"><a></a>pdata <span class="ot">&lt;-</span> <span class="fu">pdata.frame</span>(data, <span class="at">index =</span> <span class="fu">c</span>(<span class="st">"nr"</span>, <span class="st">"year"</span>))</span>
<span id="cb163-7"><a></a></span>
<span id="cb163-8"><a></a>po_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year) <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> data)</span>
<span id="cb163-9"><a></a>fe_model <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year) <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"within"</span>)</span>
<span id="cb163-10"><a></a>re_model <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year) <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"random"</span>)</span>
<span id="cb163-11"><a></a></span>
<span id="cb163-12"><a></a><span class="fu">stargazer</span>(po_model, fe_model , re_model ,<span class="at">title =</span> <span class="st">"Regression Results"</span>, <span class="at">column.labels=</span><span class="fu">c</span>(<span class="st">"OLS"</span>,<span class="st">"FE"</span>,<span class="st">"RE"</span>),  <span class="at">type =</span> <span class="st">"text"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression Results
==================================================================================
                                         Dependent variable:                      
                    --------------------------------------------------------------
                                                lwage                             
                               OLS                           panel                
                                                             linear               
                               OLS                       FE                 RE    
                               (1)                       (2)               (3)    
----------------------------------------------------------------------------------
expersq                     -0.002***                 -0.005***         -0.005*** 
                             (0.001)                   (0.001)           (0.001)  
                                                                                  
married                     0.108***                   0.047**           0.064*** 
                             (0.016)                   (0.018)           (0.017)  
                                                                                  
union                       0.182***                  0.080***           0.106*** 
                             (0.017)                   (0.019)           (0.018)  
                                                                                  
factor(year)1981             0.058*                   0.151***            0.040   
                             (0.030)                   (0.022)           (0.025)  
                                                                                  
factor(year)1982             0.063*                   0.253***            0.031   
                             (0.033)                   (0.024)           (0.032)  
                                                                                  
factor(year)1983             0.062*                   0.354***            0.020   
                             (0.037)                   (0.029)           (0.042)  
                                                                                  
factor(year)1984             0.090**                  0.490***            0.043   
                             (0.040)                   (0.036)           (0.051)  
                                                                                  
factor(year)1985             0.109**                  0.617***            0.058   
                             (0.043)                   (0.045)           (0.061)  
                                                                                  
factor(year)1986            0.142***                  0.765***            0.092   
                             (0.046)                   (0.056)           (0.071)  
                                                                                  
factor(year)1987            0.174***                  0.925***            0.135*  
                             (0.049)                   (0.069)           (0.081)  
                                                                                  
educ                        0.091***                                     0.092*** 
                             (0.005)                                     (0.011)  
                                                                                  
black                       -0.139***                                   -0.139*** 
                             (0.024)                                     (0.048)  
                                                                                  
hisp                          0.016                                       0.022   
                             (0.021)                                     (0.043)  
                                                                                  
exper                       0.067***                                     0.106*** 
                             (0.014)                                     (0.015)  
                                                                                  
Constant                      0.092                                       0.024   
                             (0.078)                                     (0.151)  
                                                                                  
----------------------------------------------------------------------------------
Observations                  4,360                     4,360             4,360   
R2                            0.189                     0.181             0.181   
Adjusted R2                   0.187                     0.061             0.178   
Residual Std. Error     0.480 (df = 4345)                                         
F Statistic         72.459*** (df = 14; 4345) 83.851*** (df = 10; 3805) 957.774***
==================================================================================
Note:                                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="tabset-26-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb165-1"><a></a><span class="kw">use</span> <span class="st">"files/WAGEPAN.dta"</span> , <span class="kw">clear</span></span>
<span id="cb165-2"><a></a></span>
<span id="cb165-3"><a></a>xtset <span class="kw">nr</span> <span class="fu">year</span> </span>
<span id="cb165-4"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span>   lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper </span>
<span id="cb165-5"><a></a>eststo: <span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper , <span class="kw">fe</span></span>
<span id="cb165-6"><a></a>eststo: <span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper , re</span>
<span id="cb165-7"><a></a></span>
<span id="cb165-8"><a></a>esttab , mtitles(<span class="st">"OLS"</span> <span class="st">"FE"</span> <span class="st">"RE"</span>) <span class="kw">compress</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Panel variable: nr (strongly balanced)
 Time variable: year, 1980 to 1987
         Delta: 1 unit

(est1 stored)

(est2 stored)

(est3 stored)


-------------------------------------------------
                 (1)          (2)          (3)   
                 OLS           FE           RE   
-------------------------------------------------
expersq     -0.00241**   -0.00519***  -0.00472***
             (-2.94)      (-7.36)      (-6.85)   

married        0.108***    0.0467*      0.0640***
              (6.90)       (2.55)       (3.81)   

union          0.182***    0.0800***     0.106***
             (10.63)       (4.14)       (5.94)   

1980.year          0            0            0   
                 (.)          (.)          (.)   

1981.year     0.0583        0.151***    0.0405   
              (1.92)       (6.89)       (1.64)   

1982.year     0.0628        0.253***    0.0309   
              (1.89)      (10.36)       (0.96)   

1983.year     0.0620        0.354***    0.0203   
              (1.69)      (12.12)       (0.49)   

1984.year     0.0905*       0.490***    0.0431   
              (2.26)      (13.53)       (0.84)   

1985.year      0.109*       0.617***    0.0578   
              (2.52)      (13.65)       (0.94)   

1986.year      0.142**      0.765***    0.0919   
              (3.06)      (13.64)       (1.29)   

1987.year      0.174***     0.925***     0.135   
              (3.52)      (13.45)       (1.66)   

educ          0.0913***         0       0.0919***
             (17.44)          (.)       (8.62)   

black         -0.139***         0       -0.139** 
             (-5.90)          (.)      (-2.92)   

hisp          0.0160            0       0.0217   
              (0.77)          (.)       (0.51)   

exper         0.0672***         0        0.106***
              (4.91)          (.)       (6.88)   

_cons         0.0921        1.426***    0.0236   
              (1.18)      (77.75)       (0.16)   
-------------------------------------------------
N               4360         4360         4360   
-------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="fe-vs.-re" class="title-slide slide level1 smaller center" data-background="#5c97f7">
<h1>FE vs.&nbsp;RE</h1>

</section>
<section id="fe-vs.-re-1" class="slide level2 smaller" data-background="#5c97f7">
<h2>FE vs.&nbsp;RE</h2>
<p><em>The idea is that one uses the random effects estimates unless the Hausman test rejects.</em></p>
<p><em>In practice, a failure to reject means either that the RE and FE estimates are sufficiently close so that it does not matter which is used, or the sampling variation is so large in the FE estimates that one cannot conclude practically significant differences are statistically significant.</em> (Wooldridge)</p>
<p><strong>If the p-value of the Hausman test is significant then use FE, if not use RE.</strong></p>
</section>
<section id="fe-vs.-re-2" class="slide level2 smaller" data-background="#5c97f7">
<h2>FE vs.&nbsp;RE</h2>
<div class="panel-tabset">
<ul id="tabset-27" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-27-1">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-27-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb167-1"><a></a><span class="kw">use</span> <span class="st">"files/WAGEPAN.dta"</span>, <span class="kw">clear</span></span>
<span id="cb167-2"><a></a>xtset <span class="kw">nr</span> <span class="fu">year</span></span>
<span id="cb167-3"><a></a><span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span> educ <span class="bn">black</span> hisp exper, <span class="kw">fe</span></span>
<span id="cb167-4"><a></a><span class="kw">estimates</span> <span class="kw">store</span> fe_model</span>
<span id="cb167-5"><a></a><span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span> educ <span class="bn">black</span> hisp exper, re</span>
<span id="cb167-6"><a></a><span class="kw">estimates</span> <span class="kw">store</span> re_model</span>
<span id="cb167-7"><a></a><span class="kw">hausman</span> fe_model re_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Panel variable: nr (strongly balanced)
 Time variable: year, 1980 to 1987
         Delta: 1 unit

                 ---- Coefficients ----
             |      (b)          (B)            (b-B)     sqrt(diag(V_b-V_B))
             |    fe_model     re_model      Difference       Std. err.
-------------+----------------------------------------------------------------
     expersq |   -.0051855    -.0047239       -.0004616        .0001443
     married |    .0466804      .063986       -.0173057        .0073414
       union |    .0800019     .1061344       -.0261326        .0073572
        year |
       1981  |    .1511912      .040462        .1107292               .
       1982  |    .2529709     .0309212        .2220497               .
       1983  |    .3544437     .0202806        .3341631               .
       1984  |    .4901148     .0431187        .4469961               .
       1985  |    .6174822     .0578154        .5596668               .
       1986  |    .7654965     .0919475         .673549               .
       1987  |    .9250249     .1349289         .790096               .
------------------------------------------------------------------------------
                          b = Consistent under H0 and Ha; obtained from xtreg.
           B = Inconsistent under Ha, efficient under H0; obtained from xtreg.

Test of H0: Difference in coefficients not systematic

   chi2(10) = (b-B)'[(V_b-V_B)^(-1)](b-B)
            =  26.36
Prob &gt; chi2 = 0.0033
(V_b-V_B is not positive definite)</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="first-differences" class="title-slide slide level1 smaller center" data-background="#e3e2b8">
<h1>First differences</h1>

</section>
<section id="first-differences-1" class="slide level2 smaller" data-background="#e3e2b8">
<h2>First differences</h2>
<p>In most applications, the main reason for collecting panel data is <strong>to allow for the unobserved effect, <span class="math inline">\(c_i\)</span>, to be correlated with the explanatory variables</strong>.</p>
<p>For example, in the crime equation, we want to allow the unmeasured city factors in <span class="math inline">\(c_i\)</span> that affect the crime rate also to be correlated with the unemployment rate.</p>
<p>It turns out that this is simple to allow: <strong>because <span class="math inline">\(c_i\)</span> is constant over time, we can difference the data across the two years.</strong></p>
<p>More precisely, for a cross-sectional observation <span class="math inline">\(i\)</span>, write the two years as:</p>
<p><span class="math display">\[y_{i,1} = \beta_0 + \beta_1 x_{i,1} + c_i + \mu_{i,1}, t=1\]</span></p>
<p><span class="math display">\[y_{i,2} = (\beta_0 + \delta_0) + \beta_1 x_{i,2} + c_i + \mu_{i,2}, t=2\]</span></p>
<p>If we subtract the second equation from the first, we obtain</p>
<p><span class="math display">\[(y_{i,2} - y_{i,1}) = \delta_0 + \beta_1 (x_{i,2} - x_{i,1}) + (\mu_{i,2}-\mu_{i,1})\]</span></p>
<p><span class="math display">\[\Delta y_{i} = \delta_0 + \beta_1 \Delta x_{i} + \Delta \mu_{i}\]</span></p>
</section>
<section id="first-differences-2" class="slide level2 smaller" data-background="#e3e2b8">
<h2>First differences</h2>
<p><strong>So, rather than subtracting the group mean of each variable, you subtract the lagged observation.</strong></p>
<p>Not hard to see that, when t=2, FE and FD will give identical solutions</p>
<div class="fragment">
<ul>
<li><p>FE is more efficient if disturbances <span class="math inline">\(\mu_{i,t}\)</span> have low serial correlation</p></li>
<li><p>FD is more efficient if disturbance <span class="math inline">\(\mu_{i,t}\)</span> follow a random walk</p></li>
</ul>
<p>At the end of the day, you can estimate both.</p>
<p>Empirical research usually estimate FD only in specific circumstances, when they are interested in how changes of X affect changes of Y.</p>
<p>Things like stationarity or trends are often not concerns in panel data</p>
<ul>
<li>where N is 10 to 20</li>
</ul>
</div>
</section>
<section id="first-differences-3" class="slide level2 smaller" data-background="#e3e2b8">
<h2>First differences</h2>
<div class="panel-tabset">
<ul id="tabset-28" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-28-1">R</a></li><li><a href="#tabset-28-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-28-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb169-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb169-2"><a></a><span class="co"># Load necessary libraries</span></span>
<span id="cb169-3"><a></a><span class="fu">library</span>(plm)</span>
<span id="cb169-4"><a></a><span class="fu">library</span>(lmtest)</span>
<span id="cb169-5"><a></a><span class="fu">library</span>(stargazer)</span>
<span id="cb169-6"><a></a></span>
<span id="cb169-7"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="st">"files/WAGEPAN.dta"</span>)</span>
<span id="cb169-8"><a></a>pdata <span class="ot">&lt;-</span> <span class="fu">pdata.frame</span>(data, <span class="at">index =</span> <span class="fu">c</span>(<span class="st">"nr"</span>, <span class="st">"year"</span>))</span>
<span id="cb169-9"><a></a></span>
<span id="cb169-10"><a></a>ols_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> <span class="fu">factor</span>(year) <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata)</span>
<span id="cb169-11"><a></a>fe_model <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"within"</span>)</span>
<span id="cb169-12"><a></a>re_model <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"random"</span>)</span>
<span id="cb169-13"><a></a>fd_model <span class="ot">&lt;-</span> <span class="fu">plm</span>(lwage <span class="sc">~</span> expersq <span class="sc">+</span> married <span class="sc">+</span> union <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> exper, <span class="at">data =</span> pdata, <span class="at">model =</span> <span class="st">"fd"</span>)</span>
<span id="cb169-14"><a></a></span>
<span id="cb169-15"><a></a><span class="fu">stargazer</span>(ols_model, fe_model ,re_model, fd_model,<span class="at">title =</span> <span class="st">"Regression Results"</span>,   <span class="at">type =</span> <span class="st">"text"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression Results
==========================================================================================================
                                                     Dependent variable:                                  
                    --------------------------------------------------------------------------------------
                                                            lwage                                         
                               OLS                                       panel                            
                                                                         linear                           
                               (1)                       (2)               (3)               (4)          
----------------------------------------------------------------------------------------------------------
expersq                     -0.002***                 -0.004***         -0.004***         -0.004***       
                             (0.001)                   (0.001)           (0.001)           (0.001)        
                                                                                                          
married                     0.108***                   0.045**           0.063***          0.038*         
                             (0.016)                   (0.018)           (0.017)           (0.023)        
                                                                                                          
union                       0.182***                  0.082***           0.107***          0.043**        
                             (0.017)                   (0.019)           (0.018)           (0.020)        
                                                                                                          
factor(year)1981             0.058*                                                                       
                             (0.030)                                                                      
                                                                                                          
factor(year)1982             0.063*                                                                       
                             (0.033)                                                                      
                                                                                                          
factor(year)1983             0.062*                                                                       
                             (0.037)                                                                      
                                                                                                          
factor(year)1984             0.090**                                                                      
                             (0.040)                                                                      
                                                                                                          
factor(year)1985             0.109**                                                                      
                             (0.043)                                                                      
                                                                                                          
factor(year)1986            0.142***                                                                      
                             (0.046)                                                                      
                                                                                                          
factor(year)1987            0.174***                                                                      
                             (0.049)                                                                      
                                                                                                          
educ                        0.091***                                     0.101***                         
                             (0.005)                                     (0.009)                          
                                                                                                          
black                       -0.139***                                   -0.144***                         
                             (0.024)                                     (0.048)                          
                                                                                                          
hisp                          0.016                                       0.020                           
                             (0.021)                                     (0.043)                          
                                                                                                          
exper                       0.067***                  0.117***           0.112***                         
                             (0.014)                   (0.008)           (0.008)                          
                                                                                                          
Constant                      0.092                                       -0.107          0.116***        
                             (0.078)                                     (0.111)           (0.020)        
                                                                                                          
----------------------------------------------------------------------------------------------------------
Observations                  4,360                     4,360             4,360             3,815         
R2                            0.189                     0.178             0.178             0.004         
Adjusted R2                   0.187                     0.060             0.177             0.003         
Residual Std. Error     0.480 (df = 4345)                                                                 
F Statistic         72.459*** (df = 14; 4345) 206.375*** (df = 4; 3811) 943.951*** 5.362*** (df = 3; 3811)
==========================================================================================================
Note:                                                                          *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="tabset-28-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb171-1"><a></a><span class="kw">use</span> <span class="st">"files/WAGEPAN.dta"</span> , <span class="kw">clear</span></span>
<span id="cb171-2"><a></a></span>
<span id="cb171-3"><a></a>xtset <span class="kw">nr</span> <span class="fu">year</span> </span>
<span id="cb171-4"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span>   lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper </span>
<span id="cb171-5"><a></a>eststo: <span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper , <span class="kw">fe</span></span>
<span id="cb171-6"><a></a>eststo: <span class="kw">qui</span> <span class="kw">xtreg</span> lwage expersq married <span class="kw">union</span> i.<span class="fu">year</span>  educ <span class="bn">black</span> hisp exper , re</span>
<span id="cb171-7"><a></a>eststo: <span class="kw">qui</span> <span class="kw">reg</span> D.lwage D.expersq D.married D.<span class="kw">union</span> i.<span class="fu">year</span>  D.educ D.<span class="bn">black</span> D.hisp D.exper </span>
<span id="cb171-8"><a></a></span>
<span id="cb171-9"><a></a>esttab , mtitles(<span class="st">"OLS"</span> <span class="st">"FE"</span> <span class="st">"RE"</span> <span class="st">"FD"</span>) <span class="kw">compress</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Panel variable: nr (strongly balanced)
 Time variable: year, 1980 to 1987
         Delta: 1 unit

(est1 stored)

(est2 stored)

(est3 stored)

(est4 stored)


--------------------------------------------------------------
                 (1)          (2)          (3)          (4)   
                 OLS           FE           RE           FD   
--------------------------------------------------------------
expersq     -0.00241**   -0.00519***  -0.00472***             
             (-2.94)      (-7.36)      (-6.85)                

married        0.108***    0.0467*      0.0640***             
              (6.90)       (2.55)       (3.81)                

union          0.182***    0.0800***     0.106***             
             (10.63)       (4.14)       (5.94)                

1980.year          0            0            0                
                 (.)          (.)          (.)                

1981.year     0.0583        0.151***    0.0405            0   
              (1.92)       (6.89)       (1.64)          (.)   

1982.year     0.0628        0.253***    0.0309      -0.0482   
              (1.89)      (10.36)       (0.96)      (-1.77)   

1983.year     0.0620        0.354***    0.0203      -0.0479   
              (1.69)      (12.12)       (0.49)      (-1.70)   

1984.year     0.0905*       0.490***    0.0431      -0.0122   
              (2.26)      (13.53)       (0.84)      (-0.41)   

1985.year      0.109*       0.617***    0.0578      -0.0208   
              (2.52)      (13.65)       (0.94)      (-0.65)   

1986.year      0.142**      0.765***    0.0919      0.00151   
              (3.06)      (13.64)       (1.29)       (0.04)   

1987.year      0.174***     0.925***     0.135       0.0167   
              (3.52)      (13.45)       (1.66)       (0.45)   

educ          0.0913***         0       0.0919***             
             (17.44)          (.)       (8.62)                

black         -0.139***         0       -0.139**              
             (-5.90)          (.)      (-2.92)                

hisp          0.0160            0       0.0217                
              (0.77)          (.)       (0.51)                

exper         0.0672***         0        0.106***             
              (4.91)          (.)       (6.88)                

D.expersq                                          -0.00575** 
                                                    (-2.65)   

D.married                                            0.0381   
                                                     (1.66)   

D.union                                              0.0411*  
                                                     (2.09)   

oD.educ                                                   0   
                                                        (.)   

oD.black                                                  0   
                                                        (.)   

oD.hisp                                                   0   
                                                        (.)   

oD.exper                                                  0   
                                                        (.)   

_cons         0.0921        1.426***    0.0236        0.156***
              (1.18)      (77.75)       (0.16)       (6.36)   
--------------------------------------------------------------
N               4360         4360         4360         3815   
--------------------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="lagged-independent-variables" class="title-slide slide level1 smaller center" data-background="#e3bfc3">
<h1>Lagged independent variables</h1>

</section>
<section id="lagged-independent-variables-1" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Lagged independent variables</h2>
<p>When you have a panel data and are concerned with simultaneity between Y and X, you can endeavor in lagging the Xs.</p>
<p><span class="math display">\[y_{i,t} = \beta_0 + \beta_1 x_{i,t-1} + c_i + \mu_{i,t}\]</span></p>
<p>As a matter of fact, this is often expected in finance research.</p>
<div class="fragment">
<p>There is a limitation, however.</p>
<p>The usual proxy of corporate finance research is highly autocorrelated.</p>
<ul>
<li>e.g., total assets do not vary much throughout time.</li>
</ul>
<p>Thus, lagging the X often does not make much of a difference.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>Always do it. Otherwise, you will have to explain why you didn’t do it.</p>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="lagged-dependent-variables" class="title-slide slide level1 smaller center" data-background="#d6cbf5">
<h1>Lagged dependent variables</h1>

</section>
<section id="lagged-dependent-variables-1" class="slide level2 smaller" data-background="#d6cbf5">
<h2>Lagged dependent variables</h2>
<p>Sometimes you may have something like</p>
<p><span class="math display">\[y_{i,t} = \beta_0 + \beta_1 y_{i,t-1}+ \beta_2 x_{i,t} + c_i + \mu_{i,t}\]</span></p>
<p>This is called a <strong>Dynamic Panel Model</strong>. It includes <span class="math inline">\(y_{i,t-1}\)</span> as X.</p>
<div class="fragment">
<p>Consider a FE model.</p>
<p><span class="math display">\[y_{i,t} - \bar{y_i} = \beta_0 + \gamma_1 (y_{i,t-1} - \bar{y}_{i,t-1}) + \omega_2 (x_{i,t-1} - \bar{x_i} )   + (FE_i - \bar{FE}_i)  + (\mu_{i,t} - \bar{\mu}_i )\]</span></p>
<p>The within transformation removes the time-invariant unobserved heterogeneity from the model.</p>
<p>However, it introduces a correlation between the transformed lag <span class="math inline">\((y_{i,t−1}−\bar{y}_{i,t-1})\)</span> and the transformed error <span class="math inline">\((\mu_{i,t−1}−\bar{\mu}_{i,t-1})\)</span> because the average error (<span class="math inline">\(\bar{\mu} = \sum_{i=1}^{T} \mu_{i,t}\)</span>) includes <span class="math inline">\(\mu_{i,t-1}\)</span>, which is also “included” in <span class="math inline">\(y_{i,t−1}\)</span></p>
<ul>
<li><span class="math inline">\(y_{i,t-1} = \beta_0 + \beta_1 y_{i,t-2}+ \beta_2 x_{i,t-1} + c_i + \mu_{i,t-1}\)</span></li>
</ul>
</div>
</section>
<section id="lagged-dependent-variables-2" class="slide level2 smaller" data-background="#d6cbf5">
<h2>Lagged dependent variables</h2>
<p>The bias declines with panel length because <span class="math inline">\(\epsilon_{i,t−1}\)</span> becomes a smaller component of the average error term as T increases.</p>
<p>In other words, with higher T the correlation between the lagged dependent variable and the regression errors becomes smaller.</p>
<p><strong><a href="https://doi.org/10.1016/j.jcorpfin.2012.09.004">Flannery and Hankins (2013)</a></strong> have a good review with applications in corporate finance.</p>
<p>They conclude that FE is biased when estimating these models.</p>
<p>They suggest to estimate <strong>Sys-GMM</strong> or <strong>Least Squares Dummy Variable Correction</strong>. We do not discuss these models in the course.</p>
</section></section>
<section>
<section id="selection-bias" class="title-slide slide level1 smaller center" data-background="#e3e2b8">
<h1>Selection Bias</h1>

</section>
<section id="selection-bias-1" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>Back to the selection bias example of before.</p>
<ul>
<li><p>Imagine that John and Mary are moving to the north of Canada.</p></li>
<li><p>John has a history of respiratory disease and decide to buy insurance.</p></li>
<li><p>Mary does not have a history of respiratory disease and decide not to buy insurance.</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th>Default</th>
<th style="text-align: left;">John</th>
<th style="text-align: right;">Mary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>State of insurance</td>
<td style="text-align: left;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td>Situation without insurance</td>
<td style="text-align: left;"><code>3</code></td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Situation with insurance</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;"><code>5</code></td>
</tr>
<tr class="even">
<td>Observed</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;">5</td>
</tr>
<tr class="odd">
<td>Effect</td>
<td style="text-align: left;">?</td>
<td style="text-align: right;">?</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5\]</span></p>
</section>
<section id="selection-bias-2" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>Rearranging the terms:</p>
<p><span class="math display">\[(Y_{1,john} - Y_{0,Mary})   + (Y_{1,Mary}  - Y_{0,john})  = (4 - 5) + (5 - 3)  = 0.5\]</span> <span class="math display">\[We\;see   + We\;do\;not\;see  = (4 - 5) + (5 - 3)  = 0.5\]</span></p>
<p>The term <span class="math inline">\((Y_{1,Mary}  - Y_{0,john}) =  (5 - 3) = 2\)</span> is the <strong>selection bias</strong>.</p>
<p>It exists because we are comparing two people that should not be compared.</p>
</section>
<section id="selection-bias-3" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>Some notation:</p>
<p><span class="math inline">\(d=1\)</span> for the treated units (treatment group)</p>
<p><span class="math inline">\(d=0\)</span> for the treated units (control group)</p>
<div class="fragment">
<p><span class="math inline">\(Y_{i}\)</span> = Potential outcome of individual <em>i</em>.</p>
<p><span class="math inline">\(Y_{i,1}\)</span> or <span class="math inline">\(Y(1)\)</span> = Potential outcome of individual <em>i</em>, treatement group.</p>
<p><span class="math inline">\(Y_{i,0}\)</span> or <span class="math inline">\(Y(0)\)</span> = Potential outcome of individual <em>i</em>, control group.</p>
</div>
</section>
<section id="selection-bias-4" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>Some notation:</p>
<p>These are the representations of the <strong>causal effect</strong> we often want to estimate.</p>
<p><strong>Average Treatment Effect:</strong></p>
<p>ATE = <span class="math inline">\(\frac{1}{N} (E[Y_{i,1}] - E[Y_{i,0}])\)</span></p>
<div class="fragment">
<p><strong>Average Treatment Effect on the treated:</strong></p>
<p>ATET = <span class="math inline">\(\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])\)</span></p>
</div>
<div class="fragment">
<p><strong>Average Treatment Effect on the untreated:</strong></p>
<p>ATEU = <span class="math inline">\(\frac{1}{N} (E[Y_{i,1}|D_i=0] - E[Y_{i,0}|D_i=0])\)</span></p>
</div>
<div class="fragment">
<p>Of course, again, we cannot observe both potential outcomes of the same unit <em>i</em>.</p>
</div>
</section>
<section id="selection-bias-5" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>When dealing with <strong>causal inference</strong>, we have to find ways to approximate what the hidden potential outcome of the treated units is.</p>
<p>That is, the challenge in identifying causal effects is that the untreated potential outcomes, <span class="math inline">\(Y_{i,0}\)</span>, are never observed for the treated group (<span class="math inline">\(D_i= 1\)</span>). The “second” term in the following equation:</p>
<p>ATET = <span class="math inline">\(\frac{1}{N} (E[Y_{i,1}|D_i=1] - E[Y_{i,0}|D_i=1])\)</span></p>
<p>We need an empirical design to <strong>“observe”</strong> what we do not really observe (i.e., the counterfactual).</p>
</section>
<section id="selection-bias-6" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>Many options:</p>
<ul>
<li>Matching/Balancing</li>
<li>Difference-in-differences (DiD)</li>
<li>Instrumental variables</li>
<li>Regression discontinuity design (RDD)</li>
<li>Synthetic control (Synth)</li>
</ul>
</section>
<section id="selection-bias-7" class="slide level2 smaller" data-background="#e3e2b8">
<h2>Selection Bias</h2>
<p>The process of finding units that are comparable is called <strong>matching</strong>.</p>
<div class="fragment">
<p><strong>Before we continue…</strong></p>
<p><strong>We will match on observables. We cannot be on unobservables.</strong></p>
<p>Thus, you may want to write in your article “selection bias due to observables”.</p>
</div>
<div class="fragment">
<p><strong>Cunningham:</strong></p>
<p><em>Propensity score matching has not seen as wide adoption among economists as in other nonexperimental methods like regression discontinuity or difference-in-differences. The most common reason given for this is that economists are oftentimes skeptical that CIA can be achieved in any dataset almost as an article of faith. This is because for many applications, economists as a group are usually more concerned about selection on unobservables than they are selection on observables, and as such, they reach for matching methods less often.</em></p>
<p>CIA = CMI</p>
</div>
</section></section>
<section>
<section id="matching" class="title-slide slide level1 smaller center" data-background="#e0cafc">
<h1>Matching</h1>

</section>
<section id="matching-1" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<p><strong>Matching</strong> aims to compare the outcomes between observations that have the same values of all control variables, except that one unit is treated and the other is not.</p>
<div class="fragment">
<p>In this literature, the control variables used to matched are often called <strong>covariates</strong>.</p>
<p>That is, for each treated unit, the researcher finds an untreated unit that is similar in all covariates.</p>
<p>The implication is that the researcher can argue that “<em>units are comparable after matching</em>”.</p>
</div>
</section>
<section id="matching-2" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<p>The easiest to see is <strong>exact matching</strong>: <em>it matches observations that have the exact same values</em>.</p>
<ul>
<li><p>It might be doable if you have only one covariate.</p></li>
<li><p>Naturally, if you have only one covariate, you might still be left with some selection bias.</p>
<ul>
<li><p>In the previous example, health history is one important covariate that makes John and Mary different.</p></li>
<li><p>But what about life style? Nutrition? Etc.</p></li>
</ul></li>
</ul>
<p>As the number of covariates grow, you cannot pursue exact matching. That is the job of PSM.</p>
</section>
<section id="matching-3" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<p><strong>In exact matching, the causal effect estimator (ATET) is:</strong></p>
<p><span class="math display">\[ATET = \frac{1}{N} \sum (E[Y_{i}] - E[Y_{j(i)}] | D_i=1)\]</span></p>
<p>Where <span class="math inline">\(Y_{j(i)}\)</span> is the j-th unit matched to the i-th unit based on the j-th being “closest to” the i-th unit for some covariate.</p>
<p>For instance, let’s say that a unit in the treatment group has a covariate with a value of 2 and we find another unit in the control group (exactly one unit) with a covariate value of 2.</p>
<p>Then we will impute the treatment unit’s missing counterfactual with the matched unit’s, and take a difference.</p>
</section>
<section id="matching-4" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<p>Consider the following dataset from Cunningham:</p>

<img data-src="figs/scott.png" class="r-stretch"></section>
<section id="matching-5" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<div class="panel-tabset">
<ul id="tabset-29" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-29-1">R Averages</a></li><li><a href="#tabset-29-2">R Treated</a></li><li><a href="#tabset-29-3">R Control</a></li><li><a href="#tabset-29-4">R Matched</a></li></ul>
<div class="tab-content">
<div id="tabset-29-1">
<p>Average ages are very different. The salary of a 24 yrs old person is quite different than the salary of a 32 yrs person.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb173-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb173-2"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb173-3"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb173-4"><a></a><span class="fu">library</span>(knitr)</span>
<span id="cb173-5"><a></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb173-6"><a></a></span>
<span id="cb173-7"><a></a>read_data <span class="ot">&lt;-</span> <span class="cf">function</span>(df)</span>
<span id="cb173-8"><a></a>{</span>
<span id="cb173-9"><a></a>  full_path <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"https://github.com/scunning1975/mixtape/raw/master/"</span>,df, <span class="at">sep =</span> <span class="st">""</span>)</span>
<span id="cb173-10"><a></a>  df <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(full_path)</span>
<span id="cb173-11"><a></a>  <span class="fu">return</span>(df)</span>
<span id="cb173-12"><a></a>}</span>
<span id="cb173-13"><a></a>training_example <span class="ot">&lt;-</span> <span class="fu">read_data</span>(<span class="st">"training_example.dta"</span>) <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb173-14"><a></a><span class="fu">summary</span>(training_example<span class="sc">$</span>age_treat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
  18.00   20.25   23.00   24.30   28.50   33.00      10 </code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb175-1"><a></a><span class="fu">summary</span>(training_example<span class="sc">$</span>age_control)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  18.00   23.50   31.50   31.95   39.00   51.00 </code></pre>
</div>
</div>
</div>
<div id="tabset-29-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb177-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb177-2"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb177-3"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb177-4"><a></a><span class="fu">library</span>(knitr)</span>
<span id="cb177-5"><a></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb177-6"><a></a></span>
<span id="cb177-7"><a></a>read_data <span class="ot">&lt;-</span> <span class="cf">function</span>(df)</span>
<span id="cb177-8"><a></a>{</span>
<span id="cb177-9"><a></a>  full_path <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"https://github.com/scunning1975/mixtape/raw/master/"</span>,df, <span class="at">sep =</span> <span class="st">""</span>)</span>
<span id="cb177-10"><a></a>  df <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(full_path)</span>
<span id="cb177-11"><a></a>  <span class="fu">return</span>(df)</span>
<span id="cb177-12"><a></a>}</span>
<span id="cb177-13"><a></a></span>
<span id="cb177-14"><a></a>training_example <span class="ot">&lt;-</span> <span class="fu">read_data</span>(<span class="st">"training_example.dta"</span>) <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb177-15"><a></a></span>
<span id="cb177-16"><a></a><span class="fu">ggplot</span>(training_example, <span class="fu">aes</span>(<span class="at">x=</span>age_treat)) <span class="sc">+</span></span>
<span id="cb177-17"><a></a>  <span class="fu">stat_bin</span>(<span class="at">bins =</span> <span class="dv">10</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-80-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-29-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb178-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb178-2"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb178-3"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb178-4"><a></a><span class="fu">library</span>(knitr)</span>
<span id="cb178-5"><a></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb178-6"><a></a></span>
<span id="cb178-7"><a></a>read_data <span class="ot">&lt;-</span> <span class="cf">function</span>(df)</span>
<span id="cb178-8"><a></a>{</span>
<span id="cb178-9"><a></a>  full_path <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"https://github.com/scunning1975/mixtape/raw/master/"</span>,df, <span class="at">sep =</span> <span class="st">""</span>)</span>
<span id="cb178-10"><a></a>  df <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(full_path)</span>
<span id="cb178-11"><a></a>  <span class="fu">return</span>(df)</span>
<span id="cb178-12"><a></a>}</span>
<span id="cb178-13"><a></a></span>
<span id="cb178-14"><a></a>training_example <span class="ot">&lt;-</span> <span class="fu">read_data</span>(<span class="st">"training_example.dta"</span>) <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb178-15"><a></a></span>
<span id="cb178-16"><a></a><span class="fu">ggplot</span>(training_example, <span class="fu">aes</span>(<span class="at">x=</span>age_control)) <span class="sc">+</span></span>
<span id="cb178-17"><a></a>  <span class="fu">stat_bin</span>(<span class="at">bins =</span> <span class="dv">10</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-81-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-29-4">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb179-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb179-2"><a></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb179-3"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb179-4"><a></a><span class="fu">library</span>(knitr)</span>
<span id="cb179-5"><a></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb179-6"><a></a></span>
<span id="cb179-7"><a></a>read_data <span class="ot">&lt;-</span> <span class="cf">function</span>(df)</span>
<span id="cb179-8"><a></a>{</span>
<span id="cb179-9"><a></a>  full_path <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"https://github.com/scunning1975/mixtape/raw/master/"</span>,df, <span class="at">sep =</span> <span class="st">""</span>)</span>
<span id="cb179-10"><a></a>  df <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(full_path)</span>
<span id="cb179-11"><a></a>  <span class="fu">return</span>(df)</span>
<span id="cb179-12"><a></a>}</span>
<span id="cb179-13"><a></a></span>
<span id="cb179-14"><a></a>training_example <span class="ot">&lt;-</span> <span class="fu">read_data</span>(<span class="st">"training_example.dta"</span>) <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb179-15"><a></a></span>
<span id="cb179-16"><a></a><span class="fu">ggplot</span>(training_example, <span class="fu">aes</span>(<span class="at">x=</span>age_matched)) <span class="sc">+</span></span>
<span id="cb179-17"><a></a>  <span class="fu">stat_bin</span>(<span class="at">bins =</span> <span class="dv">10</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="part_3_files/figure-revealjs/unnamed-chunk-82-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="matching-6" class="slide level2 smaller" data-background="#e0cafc">
<h2>Matching</h2>
<p>In this example, you are literally finding the units in the control group that have the same age as the units in the treatment group.</p>
<p>You are exact matching 1-by-1 in this example.</p>
<p>You have only one covariate, i.e., age.</p>
</section></section>
<section>
<section id="distance-matching" class="title-slide slide level1 smaller center" data-background="#c6f7ec">
<h1>Distance Matching</h1>

</section>
<section id="distance-matching-1" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Distance Matching</h2>
<p>The last example was simple because you could <em>exact match</em>.</p>
<p>If you cannot find one exact match, you need an approximate match.</p>
<div class="fragment">
<p>In order to do that, you have to use distance matching.</p>
<p><strong>Distance matching</strong> minimizes the distance (i.e., how far the covariates are from each other) between the treatment and control groups.</p>
</div>
</section>
<section id="distance-matching-2" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Distance Matching</h2>
<p><strong>Euclidean distance</strong> = <span class="math inline">\(|X_i-X_j|=\sqrt{(X_i-X_j)'(X_i-X_j)}=\sqrt{\sum_{n=1}^k(X_{n,i}-X_{n,j})^2}\)</span></p>

<img data-src="figs/euclidian.png" class="r-stretch"></section>
<section id="distance-matching-3" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Distance Matching</h2>
<p><strong>Normalized Euclidean distance</strong> = <span class="math inline">\(|X_i-X_j|=\sqrt{(X_i-X_j)'\hat{V}^{-1}(X_i-X_j)}=\sqrt{\sum_{n=1}^k\frac{(X_{n,i}-X_{n,j})}{\sigma^2_n}}\)</span></p>
<p>The problem with this measure of distance is that the distance measure itself depends on the <strong>scale of the variables themselves</strong>.</p>
<p>For this reason, researchers typically will use some modification of the Euclidean distance, such as the <strong>normalized Euclidean distance</strong>, or they’ll use a wholly different alternative distance.</p>
<p>The normalized Euclidean distance is a commonly used distance, and what makes it different is that the distance of each variable is scaled by the variable’s variance.</p>
</section>
<section id="distance-matching-4" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Distance Matching</h2>
<p><strong>Mahalanobis distance</strong> = <span class="math inline">\(|X_i-X_j|=\sqrt{(X_i-X_j)'\hat{\sum_x}^{-1}(X_i-X_j)}\)</span></p>
<p>Where <span class="math inline">\(\hat{\sum_x}\)</span> is the sample covariance matrix of X.</p>
<div class="fragment">
<p><img data-src="figs/malahanobis_king_nielsen.png"></p>
</div>
</section>
<section id="distance-matching-5" class="slide level2 smaller" data-background="#c6f7ec">
<h2>Distance Matching</h2>
<p>Distance matching only goes so far…</p>
<p>… <strong>the larger the dimensionality, the harder is to use distance matching</strong>.</p>
<p>As sample size increases, for a given N of covariates, the matching discrepancies tend to zero.</p>
<p>But, the more covariates, the longer it takes.</p>
<div class="fragment">
<p>At the end of the day, it is preferable to have many covariates, but it is makes distance matching harder.</p>
</div>
</section></section>
<section>
<section id="coarsened-exact-matching-cer" class="title-slide slide level1 smaller center" data-background="#fce0cc">
<h1>Coarsened Exact Matching (CER)</h1>

</section>
<section id="coarsened-exact-matching-cer-1" class="slide level2 smaller" data-background="#fce0cc">
<h2>Coarsened Exact Matching (CER)</h2>
<p>In coarsened exact matching, something only counts as a match if it exactly matches on each matching variable.</p>
<p><strong>The “coarsened” part comes in because, if you have any continuous variables to match on, you need to “coarsen” them first by putting them into bins, rather than matching on exact values.</strong></p>
<p>Coarsening means creating bins. Fewer bins makes exact matches more likely.</p>
<div class="fragment">
<p>CER is not used much in empirical research in finance. It is used more in the big data realm when you have many variables to match.</p>
</div>
</section></section>
<section>
<section id="propensity-score-matching-psm" class="title-slide slide level1 smaller center" data-background="#e3bfc3">
<h1>Propensity-score matching (PSM)</h1>

</section>
<section id="propensity-score-matching-psm-1" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><strong>PSM is one way to matching using many covariates.</strong></p>
<p><strong>PSM aggregates all covariates into one score (propensity-score), which is the likelihood of receiving the treatment.</strong></p>
<p>The idea is to match units that, based on observables, have the same probability (called propensity-score) of being treated.</p>
<div class="fragment">
<p>The idea is to estimate a probit (default in stata) or logit model (fist stage):</p>
<p><span class="math display">\[P(D=1|X)\]</span></p>
<p><strong>The propensity-score is the predicted probability of a unit being treated given all covariates X</strong>. The p-score is just a single number.</p>
</div>
</section>
<section id="propensity-score-matching-psm-2" class="slide level2 smaller scrollable" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p>Considerations in PSM.</p>
<ol type="1">
<li>How many neighbors to match?</li>
</ol>
<ul>
<li>Nearest neighbor, radius or kernel?</li>
</ul>
<ol start="2" type="1">
<li><p>With or without replacement?</p></li>
<li><p>With or without common support?</p></li>
</ol>
<ul>
<li><em>Common support</em>: imposes a common support by dropping treatment observations whose pscore is higher than the maximum or less than the minimum pscore of the controls.</li>
</ul>
<ol start="4" type="1">
<li>It is expected that, after PSM, you show the overlap of propensity-scores.</li>
</ol>
</section>
<section id="propensity-score-matching-psm-3" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><a href="https://sites.google.com/site/econometricsacademy/home">Source</a></p>
<p><strong>The y-axis is the propensity-score</strong>.</p>

<img data-src="figs/ani_katchova1.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-4" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><a href="https://sites.google.com/site/econometricsacademy/home">Source</a></p>
<p><strong>Nearest matching:</strong> Find the observation closest to (<span class="math inline">\(min|p_i-p_j|\)</span>)</p>

<img data-src="figs/ani_katchova3.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-5" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><a href="https://sites.google.com/site/econometricsacademy/home">Source</a></p>
<p><strong>Kernel matching:</strong> Each treated observation i is matched with several control observations, with weights inversely proportional to the distance between treated and control observations.</p>

<img data-src="figs/ani_katchova2.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-6" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><a href="https://sites.google.com/site/econometricsacademy/home">Source</a></p>
<p><strong>Radius matching</strong>: Each treated observation i is matched with control observations j that fall within a specified radius.</p>
<p><span class="math display">\[|p_i-p_j| &lt;r\]</span></p>
</section>
<section id="propensity-score-matching-psm-7" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p><a href="https://sites.google.com/site/econometricsacademy/home">Source</a></p>
<p><strong>Common support:</strong> Restrict matching only based on the common range of propensity scores.</p>

<img data-src="figs/ani_katchova5.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-8" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p>Seems good overlap, but “good” is arbitrary.</p>

<img data-src="figs/psm1.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-9" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p>Seems bad overlap</p>

<img data-src="figs/psm2.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-10" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p>Seems good overlap, but “good” is arbitrary.</p>

<img data-src="figs/psm_graph1.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-11" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>
<p>Seems bad overlap</p>

<img data-src="figs/psm_graph2.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-12" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>

<img data-src="figs/psm_bias.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-13" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>

<img data-src="figs/psm_ttest1.png" class="r-stretch"></section>
<section id="propensity-score-matching-psm-14" class="slide level2 smaller" data-background="#e3bfc3">
<h2>Propensity-score matching (PSM)</h2>

<img data-src="figs/psm_ttest2.png" class="r-stretch"></section></section>
<section>
<section id="example" class="title-slide slide level1 smaller center" data-background="#dff5ce">
<h1>Example</h1>

</section>
<section id="example-1" class="slide level2 smaller" data-background="#dff5ce">
<h2>Example</h2>
<p>Let’s practice with an example. 185 treated units vs 15,992 control units.</p>
<div class="panel-tabset">
<ul id="tabset-30" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-30-1">R</a></li><li><a href="#tabset-30-2">Python</a></li><li><a href="#tabset-30-3">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-30-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb180-1"><a></a><span class="co"># Load necessary packages</span></span>
<span id="cb180-2"><a></a><span class="co"># Load necessary libraries</span></span>
<span id="cb180-3"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb180-4"><a></a><span class="fu">library</span>(psych)</span>
<span id="cb180-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb180-6"><a></a>summary_stats <span class="ot">&lt;-</span> <span class="fu">by</span>(data, data<span class="sc">$</span>treat, <span class="at">FUN =</span> <span class="cf">function</span>(group) {</span>
<span id="cb180-7"><a></a>  <span class="fu">c</span>(</span>
<span id="cb180-8"><a></a>    <span class="at">mean =</span> <span class="fu">mean</span>(group<span class="sc">$</span>age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb180-9"><a></a>    <span class="at">variance =</span> <span class="fu">var</span>(group<span class="sc">$</span>age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb180-10"><a></a>    <span class="at">skewness =</span> <span class="fu">skew</span>(group<span class="sc">$</span>age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb180-11"><a></a>    <span class="at">count =</span> <span class="fu">length</span>(group<span class="sc">$</span>age)</span>
<span id="cb180-12"><a></a>  )</span>
<span id="cb180-13"><a></a>})</span>
<span id="cb180-14"><a></a>summary_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">do.call</span>(rbind, summary_stats))</span>
<span id="cb180-15"><a></a><span class="fu">colnames</span>(summary_df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"mean"</span>, <span class="st">"variance"</span>, <span class="st">"skewness"</span>, <span class="st">"count"</span>)</span>
<span id="cb180-16"><a></a><span class="fu">print</span>(summary_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      mean variance  skewness count
0 33.22524 121.9968 0.3477684 15992
1 25.81622  51.1943 1.1063375   185</code></pre>
</div>
</div>
</div>
<div id="tabset-30-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Python</summary>
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb182-2"><a></a><span class="im">from</span> scipy.stats <span class="im">import</span> skew</span>
<span id="cb182-3"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb182-4"><a></a>data <span class="op">=</span> pd.read_stata(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb182-5"><a></a>grouped_data <span class="op">=</span> data.groupby(<span class="st">'treat'</span>)[<span class="st">'age'</span>].agg([<span class="st">'mean'</span>, <span class="st">'var'</span>, <span class="kw">lambda</span> x: skew(x, nan_policy<span class="op">=</span><span class="st">'omit'</span>), <span class="st">'count'</span>]).reset_index()</span>
<span id="cb182-6"><a></a>grouped_data.columns <span class="op">=</span> [<span class="st">'treat'</span>, <span class="st">'mean'</span>, <span class="st">'variance'</span>, <span class="st">'skewness'</span>, <span class="st">'count'</span>]</span>
<span id="cb182-7"><a></a><span class="bu">print</span>(grouped_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   treat       mean    variance  skewness  count
0      0  33.225238  121.996792  0.347801  15992
1      1  25.816216   51.194301  1.115369    185</code></pre>
</div>
</div>
</div>
<div id="tabset-30-3">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb184-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb184-2"><a></a><span class="kw">qui</span> estpost <span class="kw">tabstat</span> age <span class="bn">black</span> educ , <span class="kw">by</span>(treat) c(<span class="fu">s</span>) <span class="fu">s</span>(me v sk n) <span class="kw">nototal</span></span>
<span id="cb184-3"><a></a>esttab .    ,varwidth(20) cells(<span class="st">"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))"</span>) <span class="kw">noobs</span> nonumber <span class="kw">compress</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)



------------------------------------------------------------
                                                            
                          mean  variance  skewness     count
------------------------------------------------------------
0                                                           
age                     33.225   121.997     0.348     15992
black                    0.074     0.068     3.268     15992
educ                    12.028     8.242    -0.423     15992
------------------------------------------------------------
1                                                           
age                     25.816    51.194     1.115       185
black                    0.843     0.133    -1.888       185
educ                    10.346     4.043    -0.721       185
------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="example-2" class="slide level2 smaller" data-background="#dff5ce">
<h2>Example</h2>
<p>Clearly, the treated group is younger, mainly black, and less educated.</p>
<p>Also note that the <strong>variance and skewness</strong> of the two subsamples are <strong>different</strong>.</p>
<p>If we were to use these two subsamples in any econometric analysis <strong>without preprocessing to make them comparable</strong>, we would likely have coefficients biased by <strong>selection bias</strong>.</p>
<p>Therefore, it is important to perform some matching method.</p>
<p>Let’s start with Propensity Score Matching (PSM). We will use the simplest matching, that is, without using any additional functions.</p>
</section>
<section id="example-3" class="slide level2 smaller" data-background="#dff5ce">
<h2>Example</h2>
<p><strong>Nearest with noreplacement.</strong></p>
<div class="panel-tabset">
<ul id="tabset-31" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-31-1">R</a></li><li><a href="#tabset-31-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-31-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb186-1"><a></a><span class="co"># install.packages("MatchIt")</span></span>
<span id="cb186-2"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb186-3"><a></a><span class="fu">library</span>(psych)</span>
<span id="cb186-4"><a></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb186-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb186-6"><a></a>model <span class="ot">&lt;-</span> <span class="fu">matchit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> black <span class="sc">+</span> educ, <span class="at">data =</span> data, <span class="at">method =</span> <span class="st">"nearest"</span>)</span>
<span id="cb186-7"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
matchit(formula = treat ~ age + black + educ, data = data, method = "nearest")

Summary of Balance for All Data:
         Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
distance        0.1445        0.0099          1.3615     7.5662    0.4987
age            25.8162       33.2252         -1.0355     0.4196    0.1863
black           0.8432        0.0735          2.1171          .    0.7697
educ           10.3459       12.0275         -0.8363     0.4905    0.0908
         eCDF Max
distance   0.7741
age        0.3427
black      0.7697
educ       0.4123

Summary of Balance for Matched Data:
         Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
distance        0.1445        0.1443          0.0020     1.0039    0.0002
age            25.8162       25.7081          0.0151     0.9244    0.0073
black           0.8432        0.8432          0.0000          .    0.0000
educ           10.3459       10.4054         -0.0296     0.7190    0.0117
         eCDF Max Std. Pair Dist.
distance   0.0162          0.0029
age        0.0270          0.1481
black      0.0000          0.0000
educ       0.0432          0.2554

Sample Sizes:
          Control Treated
All         15992     185
Matched       185     185
Unmatched   15807       0
Discarded       0       0</code></pre>
</div>
</div>
</div>
<div id="tabset-31-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb188-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb188-2"><a></a>psmatch2 treat age <span class="bn">black</span> educ , n(1) noreplacement</span>
<span id="cb188-3"><a></a><span class="kw">sum</span> _weight , <span class="kw">d</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)


Probit regression                                       Number of obs = 16,177
                                                        LR chi2(3)    = 752.47
                                                        Prob &gt; chi2   = 0.0000
Log likelihood = -634.83401                             Pseudo R2     = 0.3721

------------------------------------------------------------------------------
       treat | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
         age |  -.0379829   .0042976    -8.84   0.000     -.046406   -.0295598
       black |   1.700675   .0793898    21.42   0.000     1.545074    1.856277
        educ |  -.0806962   .0142167    -5.68   0.000    -.1085604    -.052832
       _cons |  -.9031083   .2123282    -4.25   0.000    -1.319264   -.4869526
------------------------------------------------------------------------------

            psmatch2: weight of matched controls
-------------------------------------------------------------
      Percentiles      Smallest
 1%            1              1
 5%            1              1
10%            1              1       Obs                 370
25%            1              1       Sum of wgt.         370

50%            1                      Mean                  1
                        Largest       Std. dev.             0
75%            1              1
90%            1              1       Variance              0
95%            1              1       Skewness              .
99%            1              1       Kurtosis              .</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="example-4" class="slide level2 smaller" data-background="#dff5ce">
<h2>Example</h2>
<p><strong>Notice that we are creating weights now</strong></p>
<div class="panel-tabset">
<ul id="tabset-32" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-32-1">R</a></li><li><a href="#tabset-32-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-32-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb190-1"><a></a><span class="co"># install.packages("MatchIt")</span></span>
<span id="cb190-2"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb190-3"><a></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb190-4"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb190-5"><a></a>model <span class="ot">&lt;-</span> <span class="fu">matchit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> black <span class="sc">+</span> educ, <span class="at">data =</span> data, <span class="at">method =</span> <span class="st">"exact"</span>)</span>
<span id="cb190-6"><a></a><span class="fu">summary</span>(model<span class="sc">$</span>weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.0000  0.0000  0.1457  0.0000 52.7952 </code></pre>
</div>
</div>
</div>
<div id="tabset-32-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb192-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb192-2"><a></a><span class="kw">qui</span> psmatch2 treat age <span class="bn">black</span> educ , kernel</span>
<span id="cb192-3"><a></a><span class="kw">sum</span> _weight , <span class="kw">d</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)

            psmatch2: weight of matched controls
-------------------------------------------------------------
      Percentiles      Smallest
 1%     .0024355       .0007862
 5%     .0024375       .0024348
10%       .00244       .0024348       Obs              16,177
25%     .0024517       .0024348       Sum of wgt.      16,177

50%     .0024919                      Mean            .022872
                        Largest       Std. dev.      .1130791
75%     .0026476              1
90%     .0038379              1       Variance       .0127869
95%     .0876547              1       Skewness       7.604874
99%            1              1       Kurtosis       64.26276</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="example-5" class="slide level2 smaller" data-background="#dff5ce">
<h2>Example</h2>
<p><strong>Now, the descriptive statistics are much closer</strong></p>
<div class="panel-tabset">
<ul id="tabset-33" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-33-1">R</a></li><li><a href="#tabset-33-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-33-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb194-1"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb194-2"><a></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb194-3"><a></a><span class="co">#install.packages("e1071")</span></span>
<span id="cb194-4"><a></a><span class="fu">library</span>(e1071)</span>
<span id="cb194-5"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb194-6"><a></a>model <span class="ot">&lt;-</span> <span class="fu">matchit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> black <span class="sc">+</span> educ, <span class="at">data =</span> data, <span class="at">method =</span> <span class="st">"exact"</span>)</span>
<span id="cb194-7"><a></a>matched_data <span class="ot">&lt;-</span> <span class="fu">match.data</span>(model)</span>
<span id="cb194-8"><a></a>summary_stats <span class="ot">&lt;-</span> <span class="fu">by</span>(matched_data, matched_data<span class="sc">$</span>treat, <span class="cf">function</span>(x) {</span>
<span id="cb194-9"><a></a>  <span class="fu">c</span>(<span class="fu">mean</span>(x<span class="sc">$</span>age), <span class="fu">var</span>(x<span class="sc">$</span>age), <span class="fu">skewness</span>(x<span class="sc">$</span>age), <span class="fu">length</span>(x<span class="sc">$</span>age))</span>
<span id="cb194-10"><a></a>})</span>
<span id="cb194-11"><a></a></span>
<span id="cb194-12"><a></a>result_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb194-13"><a></a>  <span class="at">Treatment =</span> <span class="fu">c</span>(<span class="st">"Control"</span>, <span class="st">"Treated"</span>),</span>
<span id="cb194-14"><a></a>  <span class="at">Mean_Age =</span> <span class="fu">sapply</span>(summary_stats, <span class="cf">function</span>(x) x[<span class="dv">1</span>]),</span>
<span id="cb194-15"><a></a>  <span class="at">Variance_Age =</span> <span class="fu">sapply</span>(summary_stats, <span class="cf">function</span>(x) x[<span class="dv">2</span>]),</span>
<span id="cb194-16"><a></a>  <span class="at">Skewness_Age =</span> <span class="fu">sapply</span>(summary_stats, <span class="cf">function</span>(x) x[<span class="dv">3</span>]),</span>
<span id="cb194-17"><a></a>  <span class="at">Count =</span> <span class="fu">sapply</span>(summary_stats, <span class="cf">function</span>(x) x[<span class="dv">4</span>])</span>
<span id="cb194-18"><a></a>)</span>
<span id="cb194-19"><a></a><span class="fu">print</span>(result_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Treatment Mean_Age Variance_Age Skewness_Age Count
0   Control 25.58786     39.16294    0.7826941  2191
1   Treated 25.51807     51.59664    1.1298334   166</code></pre>
</div>
</div>
</div>
<div id="tabset-33-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb196-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb196-2"><a></a><span class="kw">qui</span> psmatch2 treat age <span class="bn">black</span> educ , kernel</span>
<span id="cb196-3"><a></a><span class="kw">qui</span> estpost <span class="kw">tabstat</span> age <span class="bn">black</span> educ [<span class="kw">aweight</span> = _weight], <span class="kw">by</span>(treat) c(<span class="fu">s</span>) <span class="fu">s</span>(me v sk n) <span class="kw">nototal</span></span>
<span id="cb196-4"><a></a>esttab .    ,varwidth(20) cells(<span class="st">"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))"</span>) <span class="kw">noobs</span>  nonumber <span class="kw">compress</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)




------------------------------------------------------------
                                                            
                          mean  variance  skewness     count
------------------------------------------------------------
0                                                           
age                     27.033    85.548     1.077     15992
black                    0.791     0.165    -1.434     15992
educ                    10.710     8.146    -0.883     15992
------------------------------------------------------------
1                                                           
age                     25.816    51.194     1.115       185
black                    0.843     0.133    -1.888       185
educ                    10.346     4.043    -0.721       185
------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="entropy-balancing" class="title-slide slide level1 smaller center" data-background="#fccad9">
<h1>Entropy Balancing</h1>

</section>
<section id="entropy-balancing-1" class="slide level2 smaller" data-background="#fccad9">
<h2>Entropy Balancing</h2>
<p><strong>Here, instead of matching units, we reweight the observations such that the moments of the distributions (mean, variance, skewness) are similar.</strong></p>
<ul>
<li><p>The ebalance function implements a reweighting scheme. The user starts by choosing the covariates that should be included in the reweighting.</p></li>
<li><p>For each covariate, the user then specifies a set of balance constraints (in Equation 5) to equate the moments of the covariate distribution between the treatment and the reweighted control group.</p></li>
<li><p>The moment constraints may include the mean (first moment), the variance (second moment), and the skewness (third moment).</p></li>
</ul>
<p><strong>The outcome is a vector containing the weights to weight the observations, such that the weighted average, weighted variance, and weighted skewness of the covariates in control group are similar to those in the treatment group</strong></p>
</section>
<section id="entropy-balancing-2" class="slide level2 smaller" data-background="#fccad9">
<h2>Entropy Balancing</h2>
<div class="panel-tabset">
<ul id="tabset-34" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-34-1">R</a></li><li><a href="#tabset-34-2">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-34-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb198-1"><a></a><span class="fu">library</span>(haven)</span>
<span id="cb198-2"><a></a><span class="co">#install.packages("ebal")</span></span>
<span id="cb198-3"><a></a><span class="fu">library</span>(ebal)</span>
<span id="cb198-4"><a></a>data <span class="ot">&lt;-</span> <span class="fu">read_dta</span>(<span class="st">"files/cps1re74.dta"</span>)</span>
<span id="cb198-5"><a></a>treatment <span class="ot">&lt;-</span><span class="fu">cbind</span>(data<span class="sc">$</span>treat)</span>
<span id="cb198-6"><a></a>vars <span class="ot">&lt;-</span><span class="fu">cbind</span>(data<span class="sc">$</span>age, data<span class="sc">$</span>educ, data<span class="sc">$</span>black)</span>
<span id="cb198-7"><a></a>eb <span class="ot">&lt;-</span> <span class="fu">ebalance</span>(treatment, vars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Converged within tolerance </code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb200-1"><a></a><span class="co"># means in treatment group data</span></span>
<span id="cb200-2"><a></a><span class="fu">apply</span>(vars[treatment<span class="sc">==</span><span class="dv">1</span>,],<span class="dv">2</span>,mean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 25.8162162 10.3459459  0.8432432</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb202-1"><a></a><span class="co"># means in reweighted control group data</span></span>
<span id="cb202-2"><a></a><span class="fu">apply</span>(vars[treatment<span class="sc">==</span><span class="dv">0</span>,],<span class="dv">2</span>,weighted.mean,<span class="at">w=</span>eb<span class="sc">$</span>w)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 25.8163688 10.3460391  0.8431526</code></pre>
</div>
<details class="code-fold">
<summary>R</summary>
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb204-1"><a></a><span class="co"># means in raw data control group data</span></span>
<span id="cb204-2"><a></a><span class="fu">apply</span>(vars[treatment<span class="sc">==</span><span class="dv">0</span>,],<span class="dv">2</span>,mean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 33.22523762 12.02751376  0.07353677</code></pre>
</div>
</div>
</div>
<div id="tabset-34-2">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb206-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb206-2"><a></a>ebalance treat age <span class="bn">black</span> educ, targets(3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)



Data Setup
Treatment variable:   treat
Covariate adjustment: age black educ (1st order). age black educ (2nd order). a
&gt; ge black educ (3rd order).


Optimizing...
Iteration 1: Max Difference = 580799.347
Iteration 2: Max Difference = 213665.688
Iteration 3: Max Difference = 78604.7628
Iteration 4: Max Difference = 28918.6249
Iteration 5: Max Difference = 10640.1108
Iteration 6: Max Difference = 3915.82197
Iteration 7: Max Difference = 1442.09731
Iteration 8: Max Difference = 532.07826
Iteration 9: Max Difference = 197.376777
Iteration 10: Max Difference = 74.6380533
Iteration 11: Max Difference = 29.9524313
Iteration 12: Max Difference = 11.4337344
Iteration 13: Max Difference = 4.43722698
Iteration 14: Max Difference = 1.76899046
Iteration 15: Max Difference = .420548538
Iteration 16: Max Difference = .037814194
Iteration 17: Max Difference = .001164231
maximum difference smaller than the tolerance level; convergence achieved


Treated units: 185     total of weights: 185
Control units: 15992   total of weights: 185


Before: without weighting

             |              Treat              |        Control       
             |      mean   variance   skewness |      mean   variance 
-------------+---------------------------------+----------------------
         age |     25.82      51.19      1.115 |     33.23        122 
       black |     .8432      .1329     -1.888 |    .07354     .06813 
        educ |     10.35      4.043     -.7212 |     12.03      8.242 

             |  Control  
             |  skewness 
-------------+-----------
         age |     .3478 
       black |     3.268 
        educ |    -.4233 


After:  _webal as the weighting variable

             |              Treat              |        Control       
             |      mean   variance   skewness |      mean   variance 
-------------+---------------------------------+----------------------
         age |     25.82      51.19      1.115 |      25.8      51.17 
       black |     .8432      .1329     -1.888 |     .8421       .133 
        educ |     10.35      4.043     -.7212 |     10.34       4.04 

             |  Control  
             |  skewness 
-------------+-----------
         age |     1.122 
       black |    -1.877 
        educ |    -.7121 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="entropy-balancing-3" class="slide level2 smaller" data-background="#fccad9">
<h2>Entropy Balancing</h2>
<div class="panel-tabset">
<ul id="tabset-35" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-35-1">Stata</a></li></ul>
<div class="tab-content">
<div id="tabset-35-1">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Stata</summary>
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb208-1"><a></a><span class="kw">use</span> files/cps1re74.dta, <span class="kw">clear</span></span>
<span id="cb208-2"><a></a><span class="kw">qui</span> ebalance treat age <span class="bn">black</span> educ, targets(3)</span>
<span id="cb208-3"><a></a><span class="kw">qui</span> estpost <span class="kw">tabstat</span> age <span class="bn">black</span> educ [<span class="kw">aweight</span> = _webal], <span class="kw">by</span>(treat) c(<span class="fu">s</span>) <span class="fu">s</span>(me v sk n) <span class="kw">nototal</span></span>
<span id="cb208-4"><a></a>esttab .    ,varwidth(20) cells(<span class="st">"mean(fmt(3)) variance(fmt(3)) skewness(fmt(3)) count(fmt(0))"</span>) <span class="kw">noobs</span>  nonumber <span class="kw">compress</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(DW Subset of LaLonde Data)




------------------------------------------------------------
                                                            
                          mean  variance  skewness     count
------------------------------------------------------------
0                                                           
age                     25.801    51.167     1.122     15992
black                    0.842     0.133    -1.877     15992
educ                    10.340     4.040    -0.712     15992
------------------------------------------------------------
1                                                           
age                     25.816    51.194     1.115       185
black                    0.843     0.133    -1.888       185
educ                    10.346     4.043    -0.721       185
------------------------------------------------------------</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="thank-you" class="slide level2">
<h2>THANK YOU!</h2>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="figs/fgv.png" class="quarto-figure quarto-figure-right"></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<p><strong>Henrique Castro Martins</strong></p>
<ul>
<li><a href="henrique.martins@fgv.br">henrique.martins@fgv.br</a></li>
<li><a href="https://eaesp.fgv.br/en/people/henrique-castro-martins" class="uri">https://eaesp.fgv.br/en/people/henrique-castro-martins</a></li>
<li><a href="https://henriquemartins.net/">henriquemartins.net</a></li>
<li><a href="https://www.linkedin.com/in/henriquecastror/" class="uri">https://www.linkedin.com/in/henriquecastror/</a></li>
</ul>
</div>
</div>

<div class="quarto-auto-generated-content">
<p><img src="figs/background8.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><strong>[<strong>Henrique C. Martins</strong>] [<a href="mailto:henrique.martins@fgv.br">henrique.martins@fgv.br</a>][Do not use without permission]</strong></p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="../../site_libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'multiplex': {"secret":"17260825622775488760","id":"2fbb12cb4304c493","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script type="text/javascript">
      Reveal.on('ready', event => {
        if (event.indexh === 0) {
          document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        }
      });
      Reveal.addEventListener('slidechanged', (event) => {
        if (event.indexh === 0) {
          Reveal.configure({ slideNumber: null });
          document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        }
        if (event.indexh === 1) {
          Reveal.configure({ slideNumber: 'c' });
          document.querySelector("div.has-logo > img.slide-logo").style.display = null;
        }
      });
    </script>
    

</body></html>
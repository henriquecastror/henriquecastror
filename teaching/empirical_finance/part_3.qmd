---
title: 'Empirical Methods in Finance'
subtitle: 'Part 3'
author: 'Henrique C. Martins'
format:
  revealjs: 
    slide-number: true
    theme: simple
    chalkboard: true
    preview-links: auto
    logo: figs/background8.png
    css: logo.css
    footer: '**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  '
    multiplex: true
    scrollable: true 
title-slide-attributes:
    data-background-color: "#b1cafa"
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
    });
    Reveal.addEventListener('slidechanged', (event) => {
      if (event.indexh === 0) {
        Reveal.configure({ slideNumber: null });
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
      if (event.indexh === 1) { 
        Reveal.configure({ slideNumber: 'c' });
        document.querySelector("div.has-logo > img.slide-logo").style.display = null;
      }
    });
  </script>

---



```{r setup}
#| include: false
#| warning: false


# library(reticulate)
# use_python("C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe")
library(reticulate)
library(Statamarkdown)
#reticulate::py_install("matplotlib")
#reticulate::py_install("seaborn")
#reticulate::py_install("pyfinance")
#reticulate::py_install("xlrd")
#reticulate::py_install("quandl")

```



















# Conterfactuals {.smaller background="#b3eafc"}

## Conterfactuals {.smaller background="#b3eafc"}

-   Imagine that John and Mary are moving to the north of Canada.

-   John has a history of respiratory disease and decide to buy insurance.

-   Mary does not have a history of respiratory disease and decide not to buy insurance.

-   What is the causal effect of buying insurance?

| Default                     | John   |   Mary |
|-----------------------------|:-------|-------:|
| State of insurance          | 1      |      0 |
| Situation without insurance | `n.o.` |      5 |
| Situation with insurance    | 4      | `n.o.` |
| Observed                    | 4      |      5 |
| Effect                      | ?      |      ? |

[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)








## Conterfactuals {.smaller background="#b3eafc"}

**Na√Øve calculation: comparing John com Mary**

$$Y_{john} - Y_{Mary} = 4 - 5 = -1$$

Conclusion: buying insurance has a negative effect on health.

. . .

**This is wrong!**

[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)

## Conterfactuals {.smaller background="#b3eafc"}

| Default                     | John | Mary |
|-----------------------------|:-----|-----:|
| State of insurance          | 1    |    0 |
| Situation without insurance | `3`  |    5 |
| Situation with insurance    | 4    |  `5` |
| Observed                    | 4    |    5 |
| Effect                      | ?    |    ? |

$$(Y_{1,john} - Y_{0,john}) + (Y_{1,Mary}- Y_{0,Mary}) = 4 - 3 + 5 - 5 = 0.5$$

**Conclusion:** buying insurance has a positive effect of 1 in John's health and average effect of 0.5 in the sample's health (i.e. averages conditional on insurance status).

[Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845)














# Regressions {.smaller background="#dfe3f7"}

## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

**Let's see how a regression could solve the problem.** Imagine that you have the following data on students' application. (**Decisions in bold**)

| Student | Private   | Private   | Private   | Public    | Public    | Public    | Earnings |
|---------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
|         | Ivy       | Leafy     | Smart     | State     | Tall      | Altered   | 110,000  |
| 1       |           | Reject    | **Admit** |           | Admit     |           | 110,000  |
| 2       |           | Reject    | **Admit** |           | Admit     |           | 100,000  |
| 3       |           | Reject    | Admit     |           | **Admit** |           | 110,000  |
| 4       | **Admit** |           | Admit     |           | Admit     | Admit     | 60,000   |
| 5       | Admit     |           | Admit     |           | Admit     | **Admit** | 30,000   |
| 6       |           | **Admit** |           |           |           |           | 115,000  |
| 7       |           | **Admit** |           |           |           |           | 75,000   |
| 8       | Reject    |           |           | **Admit** | Admit     |           | 90,000   |
| 9       | Reject    |           |           | Admit     | **Admit** |           | 60,000   |








## Regression [Source: Mastering Metrics](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

**We can see from the table that:**

-   Some students earn high salary, in both situations

-   Some students earn low salary, in both situations

-   There are clusters of students that applied for the same universities

    -   How likely are they to be similar? Can we benefit from the fact they believe they are similar?

. . .

-   If we compare earnings from the first three individuals:

    -   ((110 + 100)/ 2 - 11000) = -5.000

-   If we compare earnings from individuals 4 and 5:

    -   (60 - 30) = 30.000

-   The average is:

    -   25.000/2 = 12.500











## Regression [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

Let's create a dataframe to run regressions with the previous student's data.

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
# Create the data frame
data <- data.frame(
  id = 1:9,
  earnings = c(110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000),
  school = c("private", "private", "public", "private", "public", "private", "private", "public", "public"),
  private = c(1, 1, 0, 1, 0, 1, 1, 0, 0),
  group = c(1, 1, 1, 2, 2, 3, 3, 4, 4)
)
print(data)

```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"

import pandas as pd
data = pd.DataFrame({
    'id': range(1, 10),
    'earnings': [110000, 100000, 110000, 60000, 30000, 115000, 75000, 90000, 60000],
    'school': ["private", "private", "public", "private", "public", "private", "private", "public", "public"],
    'private': [1, 1, 0, 1, 0, 1, 1, 0, 0],
    'group': [1, 1, 1, 2, 2, 3, 3, 4, 4]
})
print(data)

```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
input id earnings str7 school private group
1 110000 "private" 1 1
2 100000 "private" 1 1
3 110000 "public" 0 1
4 60000 "private" 1 2
5 30000 "public" 0 2
6 115000 "private" 1 3
7 75000 "private" 1 3
8 90000 "public" 0 4
9 60000 "public" 0 4
end
list
```
:::








## "Naive" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

$$earnings_i = \alpha + \beta_1 Private_i + \epsilon$$ **What is the benefit of private education here?**

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
# Create the data frame
model <- lm(earnings ~ private, data = data)
summary(model)
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
#pip install numpy scikit-learn statsmodels
import statsmodels.api as sm
X = sm.add_constant(data['private'])  
y = data['earnings']
model = sm.OLS(y, X).fit()
print(model.summary())
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
quiet input id earnings str7 school private group
1 110000 "private" 1 1
2 100000 "private" 1 1
3 110000 "public" 0 1
4 60000 "private" 1 2
5 30000 "public" 0 2
6 115000 "private" 1 3
7 75000 "private" 1 3
8 90000 "public" 0 4
9 60000 "public" 0 4
end

reg earnings private 
```
:::








## "Naive" regression all students [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

$$earnings_i = \alpha + \beta_1 Private_i + \epsilon$$ **What is the benefit of private education here?**

The coefficient of `private` is 19500, meaning that those that have private education earn 19500 more.

. . . 

The problem with this design is that 1) we are including all students, even those that do not bring any "information", and 2) we are not controlling for the differences in students' profiles. 


Let's fix the first problem first. 

**What students should we not include in the model?**





## Students id\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}


$$earnings_i = \alpha + \beta_1 Private_i + \epsilon \;,\; if\; i <=5$$ **What is the benefit of private education here?**

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true

model2 <- lm(earnings ~ private , data = subset(data,id<=5))
summary(model2)
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
#pip install numpy scikit-learn statsmodels

subset_data = data[data['id'] <= 5]
X = sm.add_constant(subset_data['private']) 
y = subset_data['earnings']
model2 = sm.OLS(y, X).fit()
print(model2.summary())
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
quiet input id earnings str7 school private group
1 110000 "private" 1 1
2 100000 "private" 1 1
3 110000 "public" 0 1
4 60000 "private" 1 2
5 30000 "public" 0 2
6 115000 "private" 1 3
7 75000 "private" 1 3
8 90000 "public" 0 4
9 60000 "public" 0 4
end
reg earnings private if id<=5
```
:::





## Students id\<=5 [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

$$earnings_i = \alpha + \beta_1 Private_i + \epsilon \;,\; if\; i <=5$$ **What is the benefit of private education here?**

Students 6 and 7 only applied to Private, while students 8 and 9 did not really had a choice. So we should exclude them.

. . .

The benefit of private is now 20000.

The coefficient did not change much, but the design improved partially.

. . .

We still have an uncontrolled "heterogeneity" in the groups of students. **Students 1 to 3 seem to earn more no matter their decisions**.







## Apples-to-Apples [Source](https://www.amazon.com.br/Mastering-Metrics-Path-Cause-Effect/dp/0691152845) {.smaller background="#dfe3f7"}

$$earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group+ \epsilon \;,\; if\; i <=5$$ **This is the best we can do.**

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true

data$dummy <- ifelse(data$group == 1, 1, 0)
data$dummy[data$group == 2] <- 0
model3 <- lm(earnings ~ private + dummy, data = subset(data,id<=5))
summary(model3)
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
#pip install numpy scikit-learn statsmodels

data['dummy'] = 1
data.loc[data['group'] == 2, 'dummy'] = 0
subset_data = data[data['id'] <= 5]
X = sm.add_constant(subset_data[['private', 'dummy']])
y = subset_data['earnings']
model3 = sm.OLS(y, X).fit()
print(model3.summary())
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
quiet input id earnings str7 school private group
1 110000 "private" 1 1
2 100000 "private" 1 1
3 110000 "public" 0 1
4 60000 "private" 1 2
5 30000 "public" 0 2
6 115000 "private" 1 3
7 75000 "private" 1 3
8 90000 "public" 0 4
9 60000 "public" 0 4
end
gen 	dummy = 1 if group == 1
replace dummy = 0 if group == 2
reg earnings private dummy if id<=5 
```
:::




## Regression {.smaller background="#dfe3f7"}

The previous regression assumes that students 1 to 3 are different that students 4 and 5. 

We will find many instances like that in empirical research. E.g., industry. 

. . .

The private school coefficient, in this case 10,000, implies a private-public earnings differential of this value.

. . .

::: callout-important
The Y above is used in monetary values.

Using a logged y, ln(Y) or ln(earnings), allows estimates to be interpreted as a percent change.

For instance if $\beta=0.05$, it means that the earnings differential is 5% for those studying in private schools (conditional on the controls included in the model). 
:::











# OVB again {.smaller background="#f5caae"}


## OVB again {.smaller background="#f5caae"}



Regression is a way to make other things equal (ceteris paribus), but equality  is generated only for variables included in the model as controls on the right-hand sided of the model.

Failure to include enough controls of the right controls still leave us with selection bias.

The regression version of the selection bias generated by the inadequate controls is called **Omitted Variable Bias (OVB)**. 

The inclusion of a control that should not be included is called "**Bad Controls**" problem.








## OVB again {.smaller background="#f5caae"}

**How could we calculate the OVB in this example?**


$$earnings_i = 70.000 + 20.000\times Private_i  \epsilon $$

$$earnings_i = 40.000 + 10.000 \times Private_i + 60.000 \times Group+ \epsilon$$ 


- $\beta$ (1st regression) - $\beta$ (second regression).
- The OVB here is 20.000 - 10.000 = 10.000.
- Meaning that the $\beta$ (1st regression) is 10.000 higher than what it should be.













## OVB again {.smaller background="#f5caae"}

**How could we calculate the OVB in this example?**


We could calculate the bias by estimating:

$$Private=\alpha + \beta_{omitted} \times Group + \epsilon$$

Then,

$$\beta_{omitted} \times \beta_{missing} = 0.1667 * 60.000 = 10.000$$

The OVB is 10.000, meaning that the first model (the one with the omitted variable) estimates a Beta that is 10.000 higher than it should be. 









## OVB again {.smaller background="#f5caae"}


::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
model4 <- lm(private ~ dummy , data = subset(data,id<=5))
summary(model4)
matrix2<- summary(model4)$coefficients
sum(0.1667 * 60000 )
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
subset_data = data[data['id'] <= 5]
model4 = sm.OLS(subset_data['private'], sm.add_constant(subset_data[['dummy']])).fit()
print(model4.summary())
bias = 0.1667 * 60000
print(bias)
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
quiet input id earnings str7 school private group
1 110000 "private" 1 1
2 100000 "private" 1 1
3 110000 "public" 0 1
4 60000 "private" 1 2
5 30000 "public" 0 2
6 115000 "private" 1 3
7 75000 "private" 1 3
8 90000 "public" 0 4
9 60000 "public" 0 4
end
gen 	dummy = 1 if group == 1
replace dummy = 0 if group == 2
reg private dummy if id<=5
di .1666667 *  60000 
```
:::













## OVB again {.smaller background="#f5caae"}

**So what?**

- Anticipating the effect of the omitted variable on the non-omitted variable can tell you the sign of the bias.

- Then you can know if the bias is attenuating or increasing the effect you are investigating.

- If attenuating, the problem is smaller than if it is increasing












## OVB again {.smaller background="#f5caae"}

**Regressions**

-   The previous examples show that we can run **regressions and find correlations** ...

-   ... And we can run regressions and find **causal effects**.

-   But we need to control for all relevant variables, otherwise we have the *OVB problem*.

-   Should you not look careful to your data, you'd miss the inclusion of the variable `group`.

-   The results show that you may estimate a spurious coefficient twice the size of the "true" coefficient.







# Bad Controls Problem {.smaller background="#dff2c7"}


## Bad Controls Problem {.smaller background="#dff2c7"}

**Bad controls** are variables that are **also outcome of the treatment** being studied.

A **Bad control** could very well be a **dependent variable** of the treatment as well. 

**Good controls** are variables that **you can think as being fixed** at the time of the treatment. 

. . .

Let's return to the model.

$$earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group+ \epsilon \;,\; if\; i <=5$$ 


Assuming you also have the occupation of the students at the time of earnings. Should you include `occupation` in the model?


$$earnings_i = \alpha + \beta_1 Private_i + \beta_2 Group + \beta_3 Occupation + \epsilon \;,\; if\; i <=5$$ 

Reasoning: "*We should use occupation as control because it would be wise to look at the effect of education on earnings only for those within an occupation*".

What is the problem with this reasoning?








## Bad Controls Problem {.smaller background="#dff2c7"}

The problem is that studying in private would increase the chances of getting a white-collar occupation, i.e., *private education (treatment) affects the occupation (bad control)*.

In this case, should you include occupation as control, the coefficient of interest no longer has a causal interpretation.


. . .

**This is a very common problem in empirical research**.

It is not hard to come up with stories of why a control is a bad control.






# Randomization {.smaller background="#ff9c6b"}

## Randomization {.smaller background="#ff9c6b"}

**Now I want to discuss the idea of randomization**

Suppose you have developed a treatment (e.g., a program) that you believe will increase the 'motivation' of employees of a factory.

You have 100 employees to use in an experiment to test your claim that the treatment will increase motivation.

. . .

- You randomly allocate 50 employees to receive the treatment. The other 50 are part of the control group.

. . .

- You treat all employees in the same manner, except for the treatment.



. . .

Using the data available, this is the **difference in motivation between the treatment and control groups (next slide):**





## Randomization {.smaller background="#ff9c6b"}

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true

library(readxl)
library(ggplot2)
library(tidyverse)
library(dplyr)
data  <- read_excel("files/part_3_data.xlsx", range = "A1:C101")
# Box plot control vs treatment groups
ggplot(data, aes(y=motivation, fill=group)) +   
  geom_boxplot()+
  theme(plot.title = element_text(color="black", size=30, face="bold"),
        panel.background = element_rect(fill = "grey95", colour = "grey95"),
        axis.text.y = element_text(face="bold", color="black", size = 18),
        axis.text.x = element_blank(),
        legend.title = element_blank(),
        legend.key.size = unit(3, "cm"))
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Read data from Excel file
data = pd.read_excel("files/part_3_data.xlsx")

# Create a box plot of control vs treatment groups using seaborn
plt.figure(figsize=(7, 5))
sns.set(style='whitegrid')
sns.boxplot(x='group', y='motivation', data=data, palette='Set2')
plt.title("Box Plot of Control vs Treatment Groups", fontsize=18)
plt.xlabel("Group", fontsize=14)
plt.ylabel("Motivation", fontsize=14)
plt.show()
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"

import excel "files/part_3_data.xlsx", cellrange(A1:C101) firstrow clear
graph box motivation , over(group) box(1, color(black)) 	ytitle("Motivation")  

quietly graph export "files/graph3_5.svg", replace
```       

![](files/graph3_5.svg)

:::












## Randomization {.smaller background="#ff9c6b"}

The calculated means are below. And they are statistically different.

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
data  <- read_excel("files/part_3_data.xlsx", range = "A1:C101")
tapply(data$motivation, data$group, summary)
t.test(motivation ~ group, data = data)
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
data = pd.read_excel("files/part_3_data.xlsx")
group_summary = data.groupby('group')['motivation'].describe()
print(group_summary)
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
import excel "files/part_3_data.xlsx", cellrange(A1:C101) firstrow clear
bys group  : sum motivation
estpost ttest motivation , by(group)
```
:::





## Randomization {.smaller background="#ff9c6b"}

**Is there evidence that the program has increased motivation?**

. . .

- well, if you randomly split a group of 100 people into two groups of 50, you certainly wouldn't get the same mean motivation in both groups even if you treated them exactly alike. 

- Maybe the difference that we see is just such a difference?

**How can we test this hypothesis?**




## Randomization {.smaller background="#ff9c6b"}

**Solution**: 

- Suppose the treatment had no effect, and the employees developed their motivation  independently of the treatment. 

- What is the chance that the 50 employees randomly assigned to the treatment group would have an average at least 1.47 (22.27 - 20.80)  points higher than the average motivation of the employees randomly assigned to the control group?








## Randomization {.smaller background="#ff9c6b"}

**Steps**

1) Randomly split the 100 employees that we observed in this experiment into two groups of 50.

2) Note the difference in the mean motivation  between the two groups.

3) Repeat 1 and 2 a total of 10,000 times.

4) Note the proportion of times the difference is at least 1.47 (22.27 - 20.80).









## Randomization {.smaller background="#ff9c6b"}

::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
# Load necessary libraries
data <- read_excel("files/part_3_data.xlsx", range = "A1:C101")
comb <- 10000
df <- data.frame(matrix(ncol = 2, nrow = comb))
colnames(df) <- c("order" ,"diff")
# Create the loop for randomization:
for (i in seq(from = 1, to = comb)) {
  set.seed(i)                               
  data$temp <- runif(100, min = 0, max = 1)  # Creating 100 random numbers 0 to 1
  data <- data[order(data$temp),]            # Sorting data by the random numbers generated in the previous row
  data$rank <- rank(data$temp)               # Ranking by the random numbers
# The row below defines the treatment group based on the random numbers generated. This is where we guarantee randomization
data$status_rank <- case_when(data$rank <= 50 ~ "Control_rand", data$rank > 50 ~ "Treated_rand")
# Calculate the new means of the new groups. Need to transpose data.
means <- t(as.data.frame(tapply(data$motivation, data$status_rank, mean)))
# Moving the new means to df. Each row is the difference of means
df[i, 1] <- i
df[i, 2] <- means[1, 2] - means[1, 1]
rm(means) # Deleting value
data = subset(data, select = -c(temp, rank, status_rank)) # Deleting variables
}
# Calculate a suitable binwidth for the histogram
binwidth <- (max(df$diff) - min(df$diff)) / sqrt(length(df$diff))
# Create a histogram of the differences with the calculated binwidth
ggplot(df, aes(x = diff)) +
  geom_histogram(binwidth = binwidth, fill = "blue", color = "black") +
  labs(title = "Distribution of Differences", x = "Difference", y = "Frequency")
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: false
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
import excel "files/part_3_data.xlsx", cellrange(A1:C101) firstrow clear
set seed 472195 		
sort group		 
set obs 10000 				 
egen fin_order = seq() 
sort fin_order 				 
summarize 					
gen av_diff=.

local i = 1
while `i'<=10000 {

	sort fin_order
	gen rand_num`i' = uniform() if !missing(motivation)
	egen ordering`i' = rank(rand_num`i')
	sort ordering`i'

	gen group`i' = ""
	replace group`i' = "T" if ordering <= 50
	replace group`i' = "C" if ordering > 50 & ordering<=100
	
	qui summ motivation if group`i'=="T"
	scalar avT = `r(mean)'
	qui summ motivation if group`i'=="C"
	scalar avC = `r(mean)'
	
	sort fin_order
	replace av_diff = avT-avC in `i'
	
	drop rand_num`i' ordering`i' group`i'
	local i = `i' + 1
}
histogram av_diff, frequency kdensity  
graph export "files/graph3_6.png" , replace

```       

![](files/graph3_6.png){ width=800px height=450px }
:::






## Randomization {.smaller background="#ff9c6b"}

The mean difference was as far from 0 as 1.5 for only a few out of the 10,000 random divisions of the data into two groups of 50.

- Thus, **the difference between the mean motivation would almost always be less than the observed difference of 1.47 (22.27 - 20.80) if the treatment had no effect.**

- It seems reasonable to believe that the treatment caused the difference in motivation.









# Measurement Error problem  {.smaller background="#f2e9b6"}


## Measurement Error problem  {.smaller background="#f2e9b6"}

The measurement error problem has a similar statistical structure to the omitted variable bias (OVB).

- "Classical" random measurement error for the $y$ will inflate standard errors but will not lead to biased coefficients. 

    - $y^{*} = y + \sigma_{1}$
    - If you estimante $y^{*} = f(x)$, you have $y + \sigma_{1} = x + \epsilon$ 
    - $y = x + u$ 
        - where $u = \epsilon - \sigma_{1}$ 




## Measurement Error problem  {.smaller background="#f2e9b6"}

- "Classical‚Äù random measurement error in x‚Äôs will bias coefficient estimates toward zero.

- $x^*=x+\sigma_2$

- Imagine that $x^*$ is a bunch of noise. It would not explain anything. Thus, your results are biased toward zero.





## Measurement Error problem  {.smaller background="#f2e9b6"}

A example using one of the Wooldridge's datasets.


::: panel-tabset
### R

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
library(foreign) 
library(jtools)
data <- read.dta("files/CEOSAL1.dta")
set.seed(2)
data$salary_noise <- data$salary + runif(length((data$salary)), min=-100, max= 100)
data$roe_noise <- data$roe + runif(length((data$roe)), min=-100, max= 100)
# OLS model 
model1 <- lm(data$salary ~ data$roe)
model2 <- lm(data$salary ~ data$roe_noise)
model3 <- lm(data$salary_noise ~ data$roe)
#summary(model1)
#summary(model2)
#summary(model3)
export_summs(model1, model2, model3, digits = 3 , model.names = c("Roe", "Roe (X) with noise", "Salary (y) with noise") )
```

### Python

```{python}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Python"
import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.iolib.summary2 import summary_col

data = pd.read_stata("files/CEOSAL1.dta")
np.random.seed(2)
# Add noise to the 'salary' and 'roe' columns
data['salary_noise'] = data['salary'] + np.random.uniform(-100, 100, len(data))
data['roe_noise'] = data['roe'] + np.random.uniform(-100, 100, len(data))
# OLS model
model1 = smf.ols(formula='salary ~ roe', data=data).fit()
model2 = smf.ols(formula='salary ~ roe_noise', data=data).fit()
model3 = smf.ols(formula='salary_noise ~ roe', data=data).fit()
# Create a summary table for all regressions
results = summary_col([model1, model2, model3], 
                      model_names=['Reg 1', 'Reg 2', 'Reg 3'],
                      stars=True,
                      float_format='%0.2f')
# Print the summary table
print(results)
```

### Stata

```{stata}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output: true
#| output-location: default
#| code-fold: true
#| code-line-numbers: true
#| eval: true
#| code-summary: "Stata"
use "files/CEOSAL1.dta", clear
set seed 2
gen salary_noise = salary + runiform() * 200 - 100
gen roe_noise = roe + runiform() * 200 - 100
eststo: qui reg salary roe
eststo: qui reg salary roe_noise
eststo: qui reg salary_noise roe
esttab
```  

:::


























## **THANK YOU!** {background="#b1cafa"}

::: columns
::: {.column width="60%"}
**QUESTIONS?**

![](figs/qa2.png){width="150%" heigth="150%"}
:::

::: {.column width="40%"}
**Henrique C. Martins**

-   [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)
-   [Personal Website](https://henriquemartins.net/)
-   [LinkedIn](https://www.linkedin.com/in/henriquecastror/)
-   [Lattes](http://lattes.cnpq.br/6076997472159785)
-   [Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)\
:::
:::

::: footer
:::

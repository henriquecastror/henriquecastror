---
title: 'Empirical Methods in Finance'
subtitle: 'Practicing 1'
author: 'Henrique C. Martins'
format:
  revealjs: 
    slide-number: true
    theme: simple
    chalkboard: true
    preview-links: auto
    logo: figs/background8.png
    css: logo.css
    footer: '**[**Henrique C. Martins**] [[henrique.martins@fgv.br](mailto:henrique.martins@fgv.br)][Do not use without permission]**  '
    multiplex: true
    scrollable: true 
title-slide-attributes:
    data-background-color: "#b1cafa"
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
    });
    Reveal.addEventListener('slidechanged', (event) => {
      if (event.indexh === 0) {
        Reveal.configure({ slideNumber: null });
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
      if (event.indexh === 1) { 
        Reveal.configure({ slideNumber: 'c' });
        document.querySelector("div.has-logo > img.slide-logo").style.display = null;
      }
    });
  </script>

---

```{r setup}
#| include: false
#| warning: false

# library(reticulate)
# use_python("C:/Users/hcmrt/AppData/Local/Programs/Python/Python310/python.exe")
library(reticulate)
library(Statamarkdown)
#reticulate::py_install("matplotlib")
#reticulate::py_install("seaborn")
#reticulate::py_install("pyfinance")
#reticulate::py_install("xlrd")
#reticulate::py_install("quandl")
#reticulate::py_install("linearmodels")
#reticulate::py_install("causalml")

```








# Basic Statistics {.smaller}

## Basic stats {.smaller }

The following are simple examples of how to compute basic statistics using R. We will start importing the data. Let's use the free dataset `iris`, available in R.


```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
iris <- iris 
```


First, explore the dataset.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
str(iris) 
```


- We have 5 variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width e Species. The first four are numeric while the last is a string with three groups: setosa, versicolor, and virginica. The dataset contains 150 observations







## Basic stats {.smaller }

Let's take a look at the first 10 observations in the dataset.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
head(iris, 10) 
```


## Basic stats {.smaller }


Now, let's take a look at the first 5 observations of each species.


```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
by(iris,iris["Species"],head,n=5)
```







## Mean and Median {.smaller }

Now, let's find the means and the medians of the four numeric variables. The most intuitive way is as follows.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
mean(iris$Sepal.Length)
mean(iris$Sepal.Width)
mean(iris$Petal.Length)
mean(iris$Petal.Width)
 
median(iris$Sepal.Length)
median(iris$Sepal.Width)
median(iris$Petal.Length)
median(iris$Petal.Width)
```



## Mean and Median {.smaller }

But this is the easiest way.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
summary(iris)
```



## Mean and Median {.smaller }

See that in the code above you also have the number of observations of each species. If you wanted to know how many observations you have in the dataset, you could use the following line. This might be important in the future.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
length(iris$Species)
```


## Mean and Median {.smaller }

If you want the same thing by group, do as follows:

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
by(iris, iris$Species, summary)
```







## Minimum and maximum  {.smaller }

The function `summary`already gives you the minimum and maximum of all variables. But sometimes you need to find only these values. You could use the following lines.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
min(iris$Sepal.Length)
max(iris$Sepal.Length)
```
      
You could also find the range of values to find the extreme values of a variable.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
range(iris$Sepal.Length)
```





## Minimum and maximum  {.smaller }

If you need the distance between the extreme values, you can use:

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: true
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
max(iris$Sepal.Length) - min(iris$Sepal.Length)
```












## Standard-deviation and Variance {.smaller }

Finally, you can also compute the Standard-deviation and Variance of one variable as follows.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
sd(iris$Sepal.Length)
var(iris$Sepal.Length) 
```

If you want the standard deviation of all variables:

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
lapply(iris[, 1:4], sd)
```










 
## Correlation {.smaller }

The following lines will show you a correlation table. First, you need to create a new dataframe with only the numeric variables. This is an extremely important table to your academic paper.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
library(dplyr)
iris_num <- select(iris,-Species)
cor(iris_num)
```







## Frequence table {.smaller }

Here is another important table you might use in your paper: the frequency of observations by group.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
table(iris$Species)
```






## T-test {.smaller }

Let's create now a t-test of the difference in means. For that, we will use another dataset: `mtcars`. The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles. You can find the description of the variables [here](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars).

You will find that there is one variable that is binary: either the cars are automatic (1) or are manual (0).

When you have binary variables, it is always a good idea to test if the means of the variables are different between the two groups of the binary variable.

This is a big thing and you will use a lot in your academic research. In fact, in many articles, the authors explore and compare two groups. So, be ready to create such an analysis.  







## T-test {.smaller }

First, import the new dataset. Then, repeat the first steps and inspect this dataset (I will not inspect the dataset here, but you should inspect as a way to practice it). 

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
mtcars <- mtcars
```



## T-test {.smaller }

Then, use the binary variable to see if other variables have similar means. The following case compares the average of `mpg` (miles p/ gas) of automatic vs. manual car.


```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| output-location: default
#| code-fold: false
#| code-summary: "R"
#| code-line-numbers: true
#| eval: true
t.test(mpg ~ am, data=mtcars)
```

- We see that the average in the automatic car is around 17.1 while the average of manual cars is 24.3.
- These averages are statistically different, since the t-stat is high (-3.76).
- So, we can learn that automatic cars consume more gas than manual cars.
- This type of test will be very  important in your research.







## Dispersion {.smaller}

These measures show how *spread out* the data are around the mean.  

The coefficient of variation (CV) compares variability relative to the mean ‚Äî useful in finance for comparing volatility across assets.

Interquartile Range = $Q_3 - Q_1$

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| echo: true
#| code-line-numbers: true
#| eval: true
x <- iris$Sepal.Length
range_x <- range(x)
iqr_x   <- IQR(x)
cv_x    <- sd(x) / mean(x)

list(
  range = diff(range_x),
  IQR = iqr_x,
  CV = cv_x
)
```







## Quantiles & Percentiles {.smaller}

Quantiles divide the data into equal parts (e.g., quartiles, percentiles).

They are often used to identify thresholds or outliers.

```{r}
#| warning: false
#| message: false
#| echo: true
#| code-line-numbers: true
#| eval: true
quantile(iris$Sepal.Length, probs = c(.01,.05,.25,.50,.75,.95,.99))
```





## Distributions {.smaller}

Visualizing the distribution helps you see its shape ‚Äî whether symmetric, skewed, or concentrated.

Empirical Cumulative Distribution Function (ECDF) = y-axis shows the accumulated proportion of observations below the x-value.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| fig-height: 4
#| echo: true
#| code-line-numbers: true
#| eval: true
par(mfrow = c(1,3))
hist(iris$Sepal.Length, breaks = 10, main = "Histogram", xlab = "Sepal.Length")
plot(density(iris$Sepal.Length), main = "Kernel Density", xlab = "Sepal.Length")
plot(ecdf(iris$Sepal.Length), main = "ECDF", xlab = "Sepal.Length")
par(mfrow = c(1,1))
```





## Shape: Skewness & Kurtosis {.smaller}

These measures describe the *shape* of a distribution.  
- **Skewness:** measures symmetry (right- or left-tailed).  
- **Kurtosis:** measures tail heaviness (fat tails ‚Üí more extreme events).  


```{r}
#| warning: false
#| message: false
#| fig-align: center
#| fig-height: 4
#| echo: true
#| code-line-numbers: true
#| eval: true
set.seed(123)
x_sym  <- rnorm(1000, mean = 0, sd = 1)        # symmetric (normal)
x_right <- rexp(1000, rate = 1) - 1            # right-skewed
x_fat  <- rt(1000, df = 3)                     # heavy tails (t-distribution)

par(mfrow = c(1,3))
hist(x_sym, breaks = 25, main = "Symmetric (Normal)", col = "lightgray", xlab = "")
hist(x_right, breaks = 25, main = "Right-Skewed (Exponential)", col = "lightgray", xlab = "")
hist(x_fat, breaks = 25, main = "Fat Tails (t, df=3)", col = "lightgray", xlab = "")
par(mfrow = c(1,1))
```


## Shape: Skewness & Kurtosis {.smaller}

Now, let's compute skewness and kurtosis for our actual data.


- Skewness > 0 ‚Üí right tail longer (positive skew).
- Skewness < 0 ‚Üí left tail longer (negative skew).
- Kurtosis > 0 ‚Üí heavier tails than normal (leptokurtic).
- Kurtosis < 0 ‚Üí lighter tails than normal (platykurtic).

```{r}
#| warning: false
#| message: false
#| echo: true
#| code-line-numbers: true
#| eval: true
skewness <- function(v){
  m <- mean(v); s <- sd(v)
  mean(((v - m)/s)^3)
}
kurtosis_excess <- function(v){
  m <- mean(v); s <- sd(v)
  mean(((v - m)/s)^4) - 3
}
c(
  skewness = skewness(iris$Sepal.Length),
  excess_kurtosis = kurtosis_excess(iris$Sepal.Length)
)
```



## Outliers via IQR Rule {.smaller}

Outliers are points far from most observations. The IQR rule defines them as values beyond 1.5 √ó IQR from the quartiles.

```{r}
#| warning: false
#| message: false
#| echo: true
#| code-line-numbers: true
#| eval: true
x <- iris$Sepal.Length
Q1 <- quantile(x, .25); Q3 <- quantile(x, .75); I <- IQR(x)
lower <- Q1 - 1.5*I; upper <- Q3 + 1.5*I
out_idx <- which(x < lower | x > upper)
list(
  thresholds = c(lower = lower, upper = upper),
  n_outliers = length(out_idx),
  example_values  = head(x[out_idx], 5)
)

```




## Transformations: log & z-score {.smaller}

Transformations help stabilize variance and make variables comparable.

- log(x) reduces skewness.
- z-score standardizes scale.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| fig-height: 4
#| echo: true
#| code-line-numbers: true
#| eval: true
x     <- iris$Sepal.Length
x_log <- log(x)
x_z   <- as.numeric(scale(x))
par(mfrow = c(1,3))
hist(x, main="Original", xlab="Sepal.Length")
hist(x_log, main="log(x)", xlab="log(Sepal.Length)")
hist(x_z, main="z-score", xlab="Standardized")
par(mfrow = c(1,1))
```








# Confidence Intervals {.smaller}

## What is a Confidence Interval? {.smaller}

A confidence interval reflects the *uncertainty* around an estimate.  
If we repeat the experiment many times, most intervals will capture the true mean, but some will miss it just by chance.

Below, we simulate **100 random samples** (each with 30 observations from a true mean of 5).  
Each horizontal line shows a 95% confidence interval for one sample mean.  
The **red line** marks the *true mean (Œº = 5)*.  

- Gray dots: sample means  
- Gray bars: confidence intervals  
- Intervals that **miss** the red line show random sampling error  
- About **5 out of 100** intervals are expected to miss (‚âà5%)

üëâ A 95% CI means: *if we repeated the experiment many times, 95% of the intervals would contain the true mean.*





## Visual Intuition {.smaller}


```{r}
#| warning: false
#| message: false
#| fig-align: center
#| fig-height: 4.5
#| echo: true
#| code-line-numbers: true
#| eval: true
set.seed(123)
n <- 30
Nrep <- 100
mu <- 5; sigma <- 1
samples <- replicate(Nrep, rnorm(n, mu, sigma))
means <- colMeans(samples)
ses <- apply(samples, 2, sd) / sqrt(n)
lower <- means - qt(0.975, df = n-1) * ses
upper <- means + qt(0.975, df = n-1) * ses

plot(1:Nrep, means, ylim = c(4,6), pch = 19, col = "gray40",
     ylab = "Mean estimate", xlab = "Sample",
     main = "100 simulated 95% Confidence Intervals")
segments(1:Nrep, lower, 1:Nrep, upper, col = "gray60")
abline(h = mu, col = "red", lwd = 2)
legend("topright", legend="True mean", col="red", lwd=2, bty="n")
```









## Confidence Interval for Iris Data {.smaller}

Compute a real example for Sepal.Length.

```{r}
#| warning: false
#| message: false
#| echo: true
#| code-line-numbers: true
#| eval: true
t.test(iris$Sepal.Length)
```

üëâ The output shows:

- Sample mean
- Confidence limits
- t-statistic and p-value

You can visualize the result below.

```{r}
#| warning: false
#| message: false
#| fig-align: center
#| fig-height: 4
#| echo: true
#| code-line-numbers: true
#| eval: true
x <- iris$Sepal.Length
m <- mean(x)
se <- sd(x)/sqrt(length(x))
ci <- m + c(-1,1)*qt(0.975, df=length(x)-1)*se

hist(x, breaks = 15, col = "lightgray",
     main = "95% Confidence Interval for Sepal.Length",
     xlab = "Sepal.Length")
abline(v = m, col = "blue", lwd = 2)
abline(v = ci, col = "red", lty = 2, lwd = 2)
legend("topright", legend=c("Mean", "95% CI limits"), 
       col=c("blue","red"), lwd=2, lty=c(1,2), bty="n")

```











## üôãÔ∏è **Any Questions?**{ .smaller  background="#fdf6e3"}

::: columns
::: {.column width="50%"}
### Thank You!

![](figs/qa2.png){width="110%" style="box-shadow: none;"}

:::

::: {.column width="50%"}
<div style="text-align:right;">
  <img src="figs/avatar.jpg" width="120px" style="border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,.25);" />
</div>

### **Henrique C. Martins**

- üåê [FGV/EAESP](https://eaesp.fgv.br/en/people/henrique-castro-martins)  
- üíº [LinkedIn](https://www.linkedin.com/in/henriquecastror/)  
- üß† [Google Scholar](https://scholar.google.com.br/citations?user=7gIfkRMAAAAJ&hl=pt-BR&oi=ao)  
- üìÑ [Lattes CV](http://lattes.cnpq.br/6076997472159785)  
- üè† [Personal Website](https://henriquemartins.net/)  
:::
:::

